import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import io
import warnings
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.cluster import KMeans
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder
from sklearn.metrics import silhouette_score
from scipy.stats import linregress  # ç¡®ä¿æœ‰è¿™ä¸ªå¯¼å…¥
import re
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from statsmodels.tsa.arima.model import ARIMA
from xgboost import XGBRegressor
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False
# ============================================================================
# è‡ªå®šä¹‰CSSæ ·å¼ - ç°ä»£åŒ–ç•Œé¢
# ============================================================================
st.markdown("""
<style>
    /* ä¸»æ ‡é¢˜æ ·å¼ */
    .main-header {
        font-size: 2.8rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 1rem;
        font-weight: bold;
        padding: 1rem;
    }

    /* é¡¶éƒ¨å¯¼èˆªæ  */
    .top-nav {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }

    .nav-button {
        background: rgba(255,255,255,0.2) !important;
        color: white !important;
        border: 2px solid rgba(255,255,255,0.3) !important;
        border-radius: 25px !important;
        padding: 0.5rem 1.5rem !important;
        margin: 0 0.5rem !important;
        font-weight: 600 !important;
        transition: all 0.3s ease !important;
    }

    .nav-button:hover {
        background: rgba(255,255,255,0.3) !important;
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }

    .nav-button.active {
        background: white !important;
        color: #667eea !important;
        border-color: white !important;
    }

    /* ä»»åŠ¡çŠ¶æ€æŒ‡ç¤ºå™¨ */
    .status-indicator {
        display: flex;
        justify-content: center;
        margin: 1rem 0;
        gap: 2rem;
    }

    .status-item {
        text-align: center;
        padding: 1rem;
        border-radius: 15px;
        background: white;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        min-width: 120px;
        transition: all 0.3s ease;
    }

    .status-item.completed {
        background: linear-gradient(135deg, #28a745, #20c997);
        color: white;
    }

    .status-item.pending {
        background: linear-gradient(135deg, #ffc107, #fd7e14);
        color: white;
    }

    /* å¡ç‰‡æ ·å¼ */
    .feature-card {
        background: white;
        border-radius: 15px;
        padding: 2rem;
        margin: 1rem 0;
        box-shadow: 0 8px 25px rgba(0,0,0,0.1);
        border-left: 5px solid #667eea;
        transition: all 0.3s ease;
    }

    .feature-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 12px 35px rgba(0,0,0,0.15);
    }

    /* å·¥å…·æ æ ·å¼ */
    .toolbar {
        background: linear-gradient(135deg, #f8f9fa, #e9ecef);
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        border: 2px solid #e9ecef;
    }

    /* æŒ‰é’®æ ·å¼ */
    .stButton button {
        border-radius: 25px !important;
        padding: 0.5rem 2rem !important;
        font-weight: 600 !important;
        transition: all 0.3s ease !important;
    }

    .stButton button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }

    /* æŒ‡æ ‡å¡ç‰‡ */
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 15px;
        text-align: center;
        box-shadow: 0 6px 20px rgba(0,0,0,0.1);
    }

    /* æ ‡ç­¾é¡µæ ·å¼ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 2rem;
        background: linear-gradient(135deg, #f8f9fa, #e9ecef);
        padding: 1rem;
        border-radius: 15px;
    }

    .stTabs [data-baseweb="tab"] {
        height: 50px;
        border-radius: 25px;
        padding: 0 2rem;
        background: white;
        border: 2px solid #e9ecef;
    }

    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
    }
</style>
""", unsafe_allow_html=True)
# ============================================================================
# é¡µé¢é…ç½®
# ============================================================================
st.set_page_config(
    page_title="ç”µå•†é”€å”®åˆ†æä¸ç­–ç•¥ä¼˜åŒ–ç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# è‡ªå®šä¹‰CSSæ ·å¼
# ============================================================================
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .task-section {
        background-color: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #007bff;
        margin: 1rem 0;
    }
    .status-completed {
        background-color: #d4edda;
        padding: 0.5rem;
        border-radius: 5px;
        margin: 0.2rem 0;
        border-left: 4px solid #28a745;
    }
    .status-pending {
        background-color: #fff3cd;
        padding: 0.5rem;
        border-radius: 5px;
        margin: 0.2rem 0;
        border-left: 4px solid #ffc107;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
    }
    .fix-note {
        background-color: #e3f2fd;
        padding: 1rem;
        border-radius: 5px;
        border-left: 4px solid #1976d2;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)


# ============================================================================
# Session State åˆå§‹åŒ–
# ============================================================================
def initialize_session_state():
    default_states = {
        'raw_data': None,  # åŸå§‹æ•°æ®
        'task1_data': None,  # ä»»åŠ¡1ä¸“ç”¨æ•°æ®
        'task2_data': None,  # ä»»åŠ¡2ä¸“ç”¨æ•°æ®
        'task3_data': None,  # ä»»åŠ¡3ä¸“ç”¨æ•°æ®
        'task4_data': None,  # ä»»åŠ¡4ä¸“ç”¨æ•°æ®
        'step1_missing_data': None,
        'step2_price_data': None,
        'step3_profit_data': None,
        'step4_abnormal_data': None,
        'step5_minmax_data': None,
        'step5_zscore_data': None,
        'processed_data': None,
        'category_encoder': None,
        'current_file': None,
        'task1_completed': False,
        'task2_completed': False,
        'task3_completed': False,
        'task4_completed': False,
        'task2_visualizations': None,  # æ–°å¢ï¼šå¯è§†åŒ–ç»“æœ
        'column_types': None
    }

    for key, value in default_states.items():
        if key not in st.session_state:
            st.session_state[key] = value
initialize_session_state()


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================
def auto_detect_column_types(df):
    """è‡ªåŠ¨è¯†åˆ«å­—æ®µç±»å‹ï¼šæ•°å€¼å‹ã€æœ‰åºåˆ†ç±»ã€æ— åºåˆ†ç±»ã€æ ‡è¯†å‹"""
    column_types = {
        'numeric': [],  # æ•°å€¼å‹ï¼ˆéœ€æ ‡å‡†åŒ–ï¼‰
        'ordinal': [],  # æœ‰åºåˆ†ç±»
        'nominal': [],  # æ— åºåˆ†ç±»
        'identifier': []  # æ ‡è¯†å‹
    }

    # æ ‡è¯†å‹å­—æ®µè§„åˆ™ï¼šå”¯ä¸€å€¼å æ¯”>80% æˆ– å­—æ®µååŒ…å«"ID/è®¢å•å·/æ—¥æœŸ"
    id_keywords = ['id', 'è®¢å•å·', 'æ—¥æœŸ', 'ç¼–å·', 'åºå·']
    for col in df.columns:
        col_lower = col.lower()
        if any(keyword in col_lower for keyword in id_keywords) or (df[col].nunique() / len(df) > 0.8):
            column_types['identifier'].append(col)
            continue

    # æ•°å€¼å‹å­—æ®µ
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    column_types['numeric'] = [col for col in numeric_cols if col not in column_types['identifier']]

    # åˆ†ç±»å­—æ®µï¼ˆéæ•°å€¼ã€éæ ‡è¯†ï¼‰
    categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()
    categorical_cols = [col for col in categorical_cols if col not in column_types['identifier']]

    # åŒºåˆ†æœ‰åº/æ— åºåˆ†ç±»
    ordinal_keywords = ['ç­‰çº§', 'å¹´é¾„', 'è¯„åˆ†', 'æ®µä½', 'å±‚æ¬¡']
    for col in categorical_cols:
        if any(keyword in col for keyword in ordinal_keywords):
            column_types['ordinal'].append(col)
        else:
            column_types['nominal'].append(col)

    return column_types


def enhanced_data_import_component(task_name, required_columns=None, allow_processed_data=True):
    """å¢å¼ºç‰ˆé€šç”¨æ•°æ®å¯¼å…¥ç»„ä»¶ - æ”¯æŒé€‰æ‹©ä»»åŠ¡1çš„ä»»ä¸€è¾“å‡ºæ–‡ä»¶"""
    st.subheader("ğŸ“ æ•°æ®å¯¼å…¥")

    col1, col2 = st.columns(2)
    data_source = None
    current_data = None

    with col1:
        # æ•°æ®æºé€‰æ‹©
        data_source_option = st.radio(
            f"é€‰æ‹©{task_name}æ•°æ®æº:",
            ["ä½¿ç”¨åŸå§‹æ•°æ®", "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶", "ä¸Šä¼ æ–°æ–‡ä»¶"],
            key=f"data_source_{task_name}"
        )

    with col2:
        if data_source_option == "ä½¿ç”¨åŸå§‹æ•°æ®":
            if st.session_state.get('raw_data') is not None:
                current_data = st.session_state.raw_data
                data_source = "åŸå§‹æ•°æ®"
                st.success(f"ä½¿ç”¨åŸå§‹æ•°æ®ï¼Œå…± {len(current_data)} æ¡è®°å½•")
            else:
                st.error("æš‚æ— åŸå§‹æ•°æ®ï¼Œè¯·å…ˆä¸Šä¼ æ–‡ä»¶")
                return None, None

        elif data_source_option == "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶":
            # ä»»åŠ¡1ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨
            task1_files = {
                "æ­¥éª¤2_è¿›è´§ä»·æ ¼å¤„ç†åæ•°æ®": "step2_price_data",
                "æ­¥éª¤3_åˆ©æ¶¦ä¿®æ­£åæ•°æ®": "step3_profit_data",
                "æ­¥éª¤4_å¼‚å¸¸ä¿®æ­£åŠåˆ©æ¶¦é‡ç®—åæ•°æ®": "step4_abnormal_data",
                "æ­¥éª¤5_MinMaxæ ‡å‡†åŒ–åæ•°æ®": "step5_minmax_data",
                "æ­¥éª¤5_ZScoreæ ‡å‡†åŒ–åæ•°æ®": "step5_zscore_data"
            }

            selected_file = st.selectbox(
                "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶:",
                list(task1_files.keys()),
                key=f"task1_file_{task_name}"
            )

            if selected_file and st.session_state.get(task1_files[selected_file]) is not None:
                current_data = st.session_state[task1_files[selected_file]]
                data_source = f"ä»»åŠ¡1: {selected_file}"
                st.success(f"ä½¿ç”¨{selected_file}ï¼Œå…± {len(current_data)} æ¡è®°å½•")
            else:
                st.error("é€‰æ‹©çš„æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®Œæˆä»»åŠ¡1")
                return None, None

        else:  # ä¸Šä¼ æ–°æ–‡ä»¶
            uploaded_file = st.file_uploader(
                f"ä¸Šä¼ {task_name}æ•°æ®æ–‡ä»¶",
                type=["xlsx", "csv"],
                key=f"upload_{task_name}"
            )

            if uploaded_file:
                try:
                    if uploaded_file.name.endswith('.xlsx'):
                        current_data = pd.read_excel(uploaded_file)
                    else:
                        current_data = pd.read_csv(uploaded_file)

                    current_data = clean_numeric_columns(current_data)
                    data_source = f"è‡ªå®šä¹‰æ–‡ä»¶: {uploaded_file.name}"
                    st.success(f"æ•°æ®åŠ è½½æˆåŠŸï¼å…± {len(current_data)} æ¡è®°å½•")
                except Exception as e:
                    st.error(f"æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")
                    return None, None
            else:
                st.info("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶")
                return None, None

    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    if required_columns and current_data is not None:
        missing_columns = [col for col in required_columns if col not in current_data.columns]
        if missing_columns:
            st.error(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_columns)}")
            st.info(f"{task_name}éœ€è¦çš„å­—æ®µ: {', '.join(required_columns)}")
            return None, None

    return current_data, data_source

def clean_numeric_columns(df):
    """æ¸…æ´—æ•°å€¼åˆ—ä¸­çš„éæ•°å€¼å­—ç¬¦"""
    df_clean = df.copy()

    # å°è¯•è¯†åˆ«ä»·æ ¼ç›¸å…³å­—æ®µ
    price_keywords = ['ä»·æ ¼', 'å”®ä»·', 'é‡‘é¢', 'é”€å”®é¢', 'åˆ©æ¶¦', 'æˆæœ¬']
    price_cols = [col for col in df.columns if any(kw in col for kw in price_keywords)]

    # æ¸…æ´—ä»·æ ¼ç›¸å…³å­—æ®µ
    for col in price_cols:
        if df_clean[col].dtype == 'object':
            # å»é™¤å¸¸è§éæ•°å€¼å­—ç¬¦
            df_clean[col] = df_clean[col].astype(str) \
                .str.replace(r'[^\d.]', '', regex=True)
            # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')

    # å¤„ç†ç™¾åˆ†æ¯”å­—æ®µ
    percent_keywords = ['ç‡', 'ç™¾åˆ†æ¯”', 'å æ¯”']
    percent_cols = [col for col in df.columns if any(kw in col for kw in percent_keywords)]
    for col in percent_cols:
        if df_clean[col].dtype == 'object':
            df_clean[col] = df_clean[col].astype(str) \
                .str.replace(r'[%]', '', regex=True)
            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce') / 100

    return df_clean


def process_categorical_variables(df, column_types, fit_encoder=True):
    """å¤„ç†åˆ†ç±»å˜é‡ï¼šæœ‰åºâ†’åºæ•°ç¼–ç ï¼Œæ— åºâ†’ç‹¬çƒ­ç¼–ç """
    df_processed = df.copy()
    encoders = {}

    # 1. æœ‰åºåˆ†ç±»ï¼šåºæ•°ç¼–ç 
    if column_types['ordinal'] and fit_encoder:
        ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
        df_ordinal = ordinal_encoder.fit_transform(df_processed[column_types['ordinal']])
        df_ordinal = pd.DataFrame(
            df_ordinal,
            columns=[f"{col}_ç¼–ç " for col in column_types['ordinal']],
            index=df_processed.index
        )
        df_processed = pd.concat([df_processed, df_ordinal], axis=1)
        encoders['ordinal'] = ordinal_encoder

    # 2. æ— åºåˆ†ç±»ï¼šç‹¬çƒ­ç¼–ç 
    if column_types['nominal'] and fit_encoder:
        onehot_encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')
        df_onehot = onehot_encoder.fit_transform(df_processed[column_types['nominal']])
        # ç”Ÿæˆç‹¬çƒ­ç¼–ç å­—æ®µå
        feature_names = []
        for i, col in enumerate(column_types['nominal']):
            categories = onehot_encoder.categories_[i][1:]  # è·³è¿‡ç¬¬ä¸€ä¸ªç±»åˆ«
            feature_names.extend([f"{col}_{cat}" for cat in categories])
        df_onehot = pd.DataFrame(
            df_onehot,
            columns=feature_names,
            index=df_processed.index
        )
        df_processed = pd.concat([df_processed, df_onehot], axis=1)
        encoders['onehot'] = onehot_encoder
        encoders['onehot_features'] = feature_names

    # 3. éæ‹Ÿåˆæ¨¡å¼
    if not fit_encoder and st.session_state.category_encoder:
        encoders = st.session_state.category_encoder
        if column_types['ordinal']:
            df_ordinal = encoders['ordinal'].transform(df_processed[column_types['ordinal']])
            df_ordinal = pd.DataFrame(
                df_ordinal,
                columns=[f"{col}_ç¼–ç " for col in column_types['ordinal']],
                index=df_processed.index
            )
            df_processed = pd.concat([df_processed, df_ordinal], axis=1)
        if column_types['nominal']:
            df_onehot = encoders['onehot'].transform(df_processed[column_types['nominal']])
            df_onehot = pd.DataFrame(
                df_onehot,
                columns=encoders['onehot_features'],
                index=df_processed.index
            )
            df_processed = pd.concat([df_processed, df_onehot], axis=1)

    return df_processed, encoders


# ============================================================================
# ä»»åŠ¡1ï¼šæ•°æ®é¢„å¤„ç†ç±»ï¼ˆæŒ‰ç…§ç‹¬ç«‹è„šæœ¬é€»è¾‘é‡æ„ï¼‰
# ============================================================================
class Task1Preprocessor:
    def __init__(self, df):
        self.df = df.copy()
        self.results = {}
        self.column_types = None

    def step1_missing_value_analysis(self):
        """æ­¥éª¤1: ç¼ºå¤±å€¼ç»Ÿè®¡åˆ†æ"""
        # è®¡ç®—ç¼ºå¤±å€¼ç»Ÿè®¡
        missing_stats = pd.DataFrame({
            'å­—æ®µå': self.df.columns,
            'æ•°æ®ç±»å‹': self.df.dtypes.values,
            'æ€»è¡Œæ•°': len(self.df),
            'éç©ºå€¼æ•°é‡': self.df.notnull().sum(),
            'ç¼ºå¤±å€¼æ•°é‡': self.df.isnull().sum(),
            'ç¼ºå¤±æ¯”ä¾‹%': (self.df.isnull().sum() / len(self.df) * 100).round(2)
        })

        self.results['step1_missing_stats'] = missing_stats
        return missing_stats

    def step2_price_processing(self, missing_stats):
        """æ­¥éª¤2: è¿›è´§ä»·æ ¼å¤„ç†ï¼ˆæŒ‰ç…§ç‹¬ç«‹è„šæœ¬é€»è¾‘ï¼‰"""
        df_step2 = self.df.copy()

        # å¤„ç†è¿›è´§ä»·æ ¼å­—æ®µ - æŒ‰ç…§ç‹¬ç«‹è„šæœ¬é€»è¾‘
        if 'è¿›è´§ä»·æ ¼' in df_step2.columns:
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å»é™¤éæ•°å­—å’Œéå°æ•°ç‚¹å­—ç¬¦
            df_step2['è¿›è´§ä»·æ ¼'] = df_step2['è¿›è´§ä»·æ ¼'].apply(
                lambda x: float(re.sub(r'[^\d\.]', '', str(x))) if re.search(r'[\d\.]', str(x)) else None
            )
            # è½¬æ¢ä¸ºæ•´æ•°å‹ï¼ˆå››èˆäº”å…¥ï¼‰
            df_step2['è¿›è´§ä»·æ ¼'] = df_step2['è¿›è´§ä»·æ ¼'].round().astype('Int64')

            # å¤„ç†ç¼ºå¤±å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
            if df_step2['è¿›è´§ä»·æ ¼'].isnull().sum() > 0:
                if 'å•†å“å“ç±»' in df_step2.columns:
                    # ç”¨å“ç±»ä¸­ä½æ•°å¡«å……
                    category_price = df_step2.groupby('å•†å“å“ç±»')['è¿›è´§ä»·æ ¼'].transform('median')
                    df_step2['è¿›è´§ä»·æ ¼'] = df_step2['è¿›è´§ä»·æ ¼'].fillna(category_price)
                else:
                    # ç”¨æ•´ä½“ä¸­ä½æ•°å¡«å……
                    df_step2['è¿›è´§ä»·æ ¼'] = df_step2['è¿›è´§ä»·æ ¼'].fillna(df_step2['è¿›è´§ä»·æ ¼'].median())

        self.results['step2_processed'] = df_step2
        return df_step2

    def step3_profit_correction(self, df_step2):
        """æ­¥éª¤3: ä¿®æ­£åˆ©æ¶¦è®¡ç®—é”™è¯¯ï¼ˆä½¿ç”¨éšæœºæ£®æ—å’ŒKNNæ¨¡å‹ï¼‰"""
        df_step3 = df_step2.copy()

        # æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨
        required_cols = ['å®é™…å”®ä»·', 'è¿›è´§ä»·æ ¼', 'é”€å”®æ•°', 'åˆ©æ¶¦']
        missing_cols = [col for col in required_cols if col not in df_step3.columns]
        if missing_cols:
            st.warning(f"åˆ©æ¶¦ä¿®æ­£ç¼ºå°‘å­—æ®µ: {missing_cols}ï¼Œè·³è¿‡åˆ©æ¶¦ä¿®æ­£")
            return df_step3

        # è®¡ç®—ç†è®ºåˆ©æ¶¦
        df_step3['ç†è®ºåˆ©æ¶¦'] = (df_step3['å®é™…å”®ä»·'] - df_step3['è¿›è´§ä»·æ ¼']) * df_step3['é”€å”®æ•°']

        # ç­›é€‰é”™è¯¯å’Œæ­£ç¡®æ•°æ®
        error_data = df_step3[df_step3['åˆ©æ¶¦'] != df_step3['ç†è®ºåˆ©æ¶¦']].copy()
        correct_data = df_step3[df_step3['åˆ©æ¶¦'] == df_step3['ç†è®ºåˆ©æ¶¦']].copy()

        st.info(f"åˆ©æ¶¦è®¡ç®—é”™è¯¯æ•°æ®æ¡æ•°ï¼š{len(error_data)}")
        st.info(f"åˆ©æ¶¦è®¡ç®—æ­£ç¡®æ•°æ®æ¡æ•°ï¼ˆè®­ç»ƒæ•°æ®ï¼‰ï¼š{len(correct_data)}")

        if len(correct_data) == 0:
            st.warning("æ— åˆ©æ¶¦è®¡ç®—æ­£ç¡®çš„æ•°æ®ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹è¿›è¡Œè¡¥æ’")
            return df_step3

        if len(error_data) == 0:
            st.info("æ²¡æœ‰å‘ç°åˆ©æ¶¦è®¡ç®—é”™è¯¯çš„æ•°æ®")
            df_step3 = df_step3.drop(columns='ç†è®ºåˆ©æ¶¦')
            return df_step3

        # å‡†å¤‡æ¨¡å‹è®­ç»ƒæ•°æ®
        features = ['å®é™…å”®ä»·', 'è¿›è´§ä»·æ ¼', 'é”€å”®æ•°']
        X = correct_data[features]
        y = correct_data['åˆ©æ¶¦']

        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # 1. è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.neighbors import KNeighborsRegressor
        from sklearn.metrics import mean_squared_error

        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
        rf_model.fit(X_train, y_train)
        rf_pred_test = rf_model.predict(X_test)
        rf_mse = mean_squared_error(y_test, rf_pred_test)
        st.info(f"éšæœºæ£®æ—æ¨¡å‹æµ‹è¯•é›†å‡æ–¹è¯¯å·®ï¼š{round(rf_mse, 2)}")

        # 2. è®­ç»ƒKNNæ¨¡å‹
        knn_model = KNeighborsRegressor(n_neighbors=5)
        knn_model.fit(X_train, y_train)
        knn_pred_test = knn_model.predict(X_test)
        knn_mse = mean_squared_error(y_test, knn_pred_test)
        st.info(f"KNNæ¨¡å‹æµ‹è¯•é›†å‡æ–¹è¯¯å·®ï¼š{round(knn_mse, 2)}")

        # é€‰æ‹©MSEè¾ƒå°çš„æ¨¡å‹è¿›è¡Œåˆ©æ¶¦è¡¥æ’
        if rf_mse <= knn_mse:
            st.info("é€‰æ‹©éšæœºæ£®æ—æ¨¡å‹è¿›è¡Œåˆ©æ¶¦è¡¥æ’")
            error_X = error_data[features]
            pred_error = rf_model.predict(error_X)
            pred_error = pred_error.round().astype(df_step3['åˆ©æ¶¦'].dtype)
        else:
            st.info("é€‰æ‹©KNNæ¨¡å‹è¿›è¡Œåˆ©æ¶¦è¡¥æ’")
            error_X = error_data[features]
            pred_error = knn_model.predict(error_X)
            pred_error = pred_error.round().astype(df_step3['åˆ©æ¶¦'].dtype)

        # æ›´æ–°é”™è¯¯åˆ©æ¶¦å€¼
        df_step3 = df_step3.reset_index(drop=True)
        error_data = error_data.reset_index(drop=True)
        df_step3.loc[error_data.index, 'åˆ©æ¶¦'] = pred_error

        # åˆ é™¤ä¸´æ—¶çš„ç†è®ºåˆ©æ¶¦åˆ—
        df_step3 = df_step3.drop(columns='ç†è®ºåˆ©æ¶¦')

        self.results['step3_processed'] = df_step3
        return df_step3

    def step4_abnormal_correction(self, df_step3):
        """æ­¥éª¤4: ä¿®æ­£æˆæœ¬é«˜äºå”®ä»·å¼‚å¸¸ï¼ˆä½¿ç”¨æ¨¡å‹é¢„æµ‹åˆç†å”®ä»·ï¼‰"""
        df_step4 = df_step3.copy()

        # æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨
        required_cols = ['å®é™…å”®ä»·', 'è¿›è´§ä»·æ ¼', 'é”€å”®æ•°', 'å®¢æˆ·å¹´é¾„']
        missing_cols = [col for col in required_cols if col not in df_step4.columns]
        if missing_cols:
            st.warning(f"å¼‚å¸¸ä¿®æ­£ç¼ºå°‘å­—æ®µ: {missing_cols}ï¼Œè·³è¿‡å¼‚å¸¸ä¿®æ­£")
            return df_step4

        # æ ‡è®°å¼‚å¸¸æ•°æ®ï¼ˆå®é™…å”®ä»· < è¿›è´§ä»·æ ¼ï¼‰
        abnormal_mask = df_step4['å®é™…å”®ä»·'] < df_step4['è¿›è´§ä»·æ ¼']
        abnormal_data = df_step4[abnormal_mask].copy()
        normal_data = df_step4[~abnormal_mask].copy()

        st.info(f"æˆæœ¬é«˜äºå”®ä»·çš„å¼‚å¸¸æ•°æ®æ¡æ•°ï¼š{len(abnormal_data)}")
        st.info(f"æ­£å¸¸æ•°æ®æ¡æ•°ï¼ˆè®­ç»ƒæ•°æ®ï¼‰ï¼š{len(normal_data)}")

        if len(normal_data) == 0:
            st.warning("æ— æ­£å¸¸å”®ä»·æ•°æ®ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹è¿›è¡Œå¼‚å¸¸ä¿®æ­£")
            return df_step4

        if len(abnormal_data) == 0:
            st.info("æ²¡æœ‰å‘ç°æˆæœ¬é«˜äºå”®ä»·çš„å¼‚å¸¸æ•°æ®")
            # é‡æ–°è®¡ç®—åˆ©æ¶¦ç¡®ä¿æ­£ç¡®æ€§
            if all(col in df_step4.columns for col in ['å®é™…å”®ä»·', 'è¿›è´§ä»·æ ¼', 'é”€å”®æ•°']):
                df_step4['åˆ©æ¶¦'] = (df_step4['å®é™…å”®ä»·'] - df_step4['è¿›è´§ä»·æ ¼']) * df_step4['é”€å”®æ•°']
            return df_step4

        # å‡†å¤‡æ¨¡å‹è®­ç»ƒæ•°æ®ï¼ˆé¢„æµ‹åˆç†å®é™…å”®ä»·ï¼‰
        features = ['è¿›è´§ä»·æ ¼', 'é”€å”®æ•°', 'å®¢æˆ·å¹´é¾„']
        target = 'å®é™…å”®ä»·'
        X = normal_data[features]
        y = normal_data[target]

        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # 1. è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.neighbors import KNeighborsRegressor
        from sklearn.metrics import mean_squared_error

        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
        rf_model.fit(X_train, y_train)
        rf_pred_test = rf_model.predict(X_test)
        rf_mse = mean_squared_error(y_test, rf_pred_test)
        st.info(f"éšæœºæ£®æ—æ¨¡å‹ï¼ˆå”®ä»·é¢„æµ‹ï¼‰æµ‹è¯•é›†å‡æ–¹è¯¯å·®ï¼š{round(rf_mse, 2)}")

        # 2. è®­ç»ƒKNNæ¨¡å‹
        knn_model = KNeighborsRegressor(n_neighbors=5)
        knn_model.fit(X_train, y_train)
        knn_pred_test = knn_model.predict(X_test)
        knn_mse = mean_squared_error(y_test, knn_pred_test)
        st.info(f"KNNæ¨¡å‹ï¼ˆå”®ä»·é¢„æµ‹ï¼‰æµ‹è¯•é›†å‡æ–¹è¯¯å·®ï¼š{round(knn_mse, 2)}")

        # ç»¼åˆä¸¤ç§æ¨¡å‹ç»“æœè¿›è¡Œå”®ä»·è¡¥æ’ï¼ˆå–å¹³å‡å€¼ï¼‰
        abnormal_X = abnormal_data[features]
        rf_pred_abnormal = rf_model.predict(abnormal_X)
        knn_pred_abnormal = knn_model.predict(abnormal_X)
        combined_pred = (rf_pred_abnormal + knn_pred_abnormal) / 2
        combined_pred = combined_pred.round().astype(df_step4[target].dtype)

        # æ›´æ–°å¼‚å¸¸æ•°æ®çš„å”®ä»·
        df_step4.loc[abnormal_mask, target] = combined_pred

        # äºŒæ¬¡æ£€æŸ¥å‰©ä½™å¼‚å¸¸ï¼ˆè‹¥ä»æœ‰å”®ä»·<è¿›è´§ä»·ï¼Œå°†å”®ä»·è®¾ä¸ºè¿›è´§ä»·ï¼‰
        remaining_abnormal_mask = df_step4['å®é™…å”®ä»·'] < df_step4['è¿›è´§ä»·æ ¼']
        if remaining_abnormal_mask.sum() > 0:
            st.info(f"äºŒæ¬¡æ£€æŸ¥å‘ç°{remaining_abnormal_mask.sum()}æ¡å‰©ä½™å¼‚å¸¸æ•°æ®ï¼Œå°†å”®ä»·è®¾ä¸ºè¿›è´§ä»·")
            df_step4.loc[remaining_abnormal_mask, 'å®é™…å”®ä»·'] = df_step4.loc[remaining_abnormal_mask, 'è¿›è´§ä»·æ ¼']

        # é‡æ–°è®¡ç®—æ­£ç¡®åˆ©æ¶¦ï¼ˆæ›¿æ¢åŸåˆ©æ¶¦åˆ—ï¼‰
        df_step4['åˆ©æ¶¦'] = (df_step4['å®é™…å”®ä»·'] - df_step4['è¿›è´§ä»·æ ¼']) * df_step4['é”€å”®æ•°']

        self.results['step4_processed'] = df_step4
        return df_step4

    def step5_standardization(self, df_step4):
        """æ­¥éª¤5: æ ‡å‡†åŒ–å¤„ç†ï¼ˆæŒ‰ç…§ç‹¬ç«‹è„šæœ¬é€»è¾‘ï¼‰"""
        df_original = df_step4.copy()

        # å®šä¹‰éœ€æ ‡å‡†åŒ–çš„æ•°å€¼åˆ—ï¼ˆä¸ç‹¬ç«‹è„šæœ¬å®Œå…¨ä¸€è‡´ï¼‰
        required_cols = ["è¿›è´§ä»·æ ¼", "å®é™…å”®ä»·", "é”€å”®æ•°", "åˆ©æ¶¦"]
        # è‹¥å­˜åœ¨é”€å”®é¢åˆ—ï¼ŒåŠ å…¥æ ‡å‡†åŒ–èŒƒå›´
        if "é”€å”®é¢" in df_original.columns:
            required_cols.append("é”€å”®é¢")

        # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
        missing_cols = [col for col in required_cols if col not in df_original.columns]
        if missing_cols:
            st.warning(f"æ ‡å‡†åŒ–ç¼ºå°‘å­—æ®µ: {missing_cols}")

        # ç­›é€‰æ•°å€¼å‹åˆ—
        numeric_cols = [col for col in required_cols if col in df_original.columns and
                        pd.api.types.is_numeric_dtype(df_original[col])]

        if not numeric_cols:
            st.warning("æ— å¯ç”¨çš„æ•°å€¼å‹åˆ—è¿›è¡Œæ ‡å‡†åŒ–")
            # è¿”å›åŸå§‹æ•°æ®
            self.results['step5_minmax'] = df_original
            self.results['step5_zscore'] = df_original
            return df_original, df_original

        st.info(f"å¾…æ ‡å‡†åŒ–çš„æ•°å€¼åˆ—ï¼š{numeric_cols}")

        # 1. Z-Scoreæ ‡å‡†åŒ–
        df_zscore = df_original.copy()
        scaler_z = StandardScaler()
        df_zscore[numeric_cols] = scaler_z.fit_transform(df_zscore[numeric_cols])

        # 2. Min-Maxæ ‡å‡†åŒ–
        df_minmax = df_original.copy()
        scaler_mm = MinMaxScaler(feature_range=(0, 1))
        df_minmax[numeric_cols] = scaler_mm.fit_transform(df_minmax[numeric_cols])

        self.results['step5_minmax'] = df_minmax
        self.results['step5_zscore'] = df_zscore
        self.results['numeric_cols'] = numeric_cols

        # è¾“å‡ºæ ‡å‡†åŒ–ç»Ÿè®¡ä¿¡æ¯
        st.info("Z-Scoreæ ‡å‡†åŒ–åç»Ÿè®¡æè¿°ï¼š")
        st.dataframe(df_zscore[numeric_cols].describe().round(4))
        st.info("Min-Maxæ ‡å‡†åŒ–åç»Ÿè®¡æè¿°ï¼ˆ0-1åŒºé—´ï¼‰ï¼š")
        st.dataframe(df_minmax[numeric_cols].describe().round(4))

        return df_minmax, df_zscore

    def generate_all_results(self):
        """ç”Ÿæˆæ‰€æœ‰æ­¥éª¤çš„ç»“æœ"""
        try:
            # æ‰§è¡Œå…¨æµç¨‹æ­¥éª¤
            step1_missing = self.step1_missing_value_analysis()
            step2_price = self.step2_price_processing(step1_missing)
            step3_profit = self.step3_profit_correction(step2_price)
            step4_abnormal = self.step4_abnormal_correction(step3_profit)
            step5_minmax, step5_zscore = self.step5_standardization(step4_abnormal)

            # å­—æ®µç±»å‹è¯†åˆ«
            self.column_types = auto_detect_column_types(step4_abnormal)

            # å¤„ç†åˆ†ç±»å˜é‡
            final_data, encoders = process_categorical_variables(
                step4_abnormal, self.column_types, fit_encoder=True)

            # æ•´ç†ç»“æœæ–‡ä»¶
            result_files = {
                'ç”µå•† æ­¥éª¤1 ç¼ºå¤±å€¼ç»Ÿè®¡ç»“æœ.xlsx': step1_missing,
                'ç”µå•† æ­¥éª¤2 è¿›è´§ä»·æ ¼å¤„ç†åæ•°æ®.xlsx': step2_price,
                'ç”µå•† æ­¥éª¤3 åˆ©æ¶¦ä¿®æ­£åæ•°æ®.xlsx': step3_profit,
                'ç”µå•† æ­¥éª¤4 å¼‚å¸¸ä¿®æ­£åŠåˆ©æ¶¦é‡ç®—åæ•°æ®.xlsx': step4_abnormal,
                'ç”µå•† æ­¥éª¤5 MinMaxæ ‡å‡†åŒ–åæ•°æ®.xlsx': step5_minmax,
                'ç”µå•† æ­¥éª¤5 ZScoreæ ‡å‡†åŒ–åæ•°æ®.xlsx': step5_zscore
            }

            # æ•´ç†è¿›åº¦æ—¥å¿—
            progress_log = [
                f"æ­¥éª¤1ï¼šå®Œæˆç¼ºå¤±å€¼ç»Ÿè®¡ï¼Œå…±{len(step1_missing)}ä¸ªå­—æ®µ",
                f"æ­¥éª¤2ï¼šå®Œæˆè¿›è´§ä»·æ ¼å¤„ç†ï¼ˆå»é™¤è´§å¸ç¬¦å·å¹¶è½¬æ¢ä¸ºæ•´æ•°å‹ï¼‰",
                f"æ­¥éª¤3ï¼šå®Œæˆåˆ©æ¶¦ä¿®æ­£ï¼ˆä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹ï¼‰",
                f"æ­¥éª¤4ï¼šå®Œæˆå¼‚å¸¸å€¼ä¿®æ­£ï¼ˆæˆæœ¬é«˜äºå”®ä»·å¼‚å¸¸ï¼‰",
                f"æ­¥éª¤5ï¼šå®Œæˆæ ‡å‡†åŒ–å¤„ç†ï¼Œç”ŸæˆMinMaxå’ŒZScoreä¸¤ç§æ ‡å‡†åŒ–ç»“æœ"
            ]

            return result_files, progress_log, final_data, encoders, self.column_types

        except Exception as e:
            return None, [f"é¢„å¤„ç†é”™è¯¯: {str(e)}"], None, None, None
# ============================================================================
# å¢å¼ºç‰ˆä»»åŠ¡2ï¼šå¤šç»´é”€å”®ç‰¹å¾åˆ†æç±»ï¼ˆæŒ‰è®ºæ–‡è¦æ±‚é‡æ„ï¼‰
# ============================================================================
# ============================================================================
# å¢å¼ºå¯è§†åŒ–åŠŸèƒ½ç±»
# ============================================================================
class EnhancedVisualizer:
    def __init__(self, df, column_types):
        self.df = df.copy()
        self.column_types = column_types
        self.results = {}

    def create_interactive_dashboard(self):
        """åˆ›å»ºäº¤äº’å¼ä»ªè¡¨æ¿"""
        figs = {}

        try:
            # 1. é”€å”®è¶‹åŠ¿å›¾
            if any('æ—¥æœŸ' in col for col in self.df.columns):
                date_col = next(col for col in self.df.columns if 'æ—¥æœŸ' in col)
                daily_sales = self.df.groupby(date_col).agg({
                    'é”€å”®é¢': 'sum',
                    'åˆ©æ¶¦': 'sum',
                    'é”€å”®æ•°': 'sum'
                }).reset_index()

                fig_trend = go.Figure()
                fig_trend.add_trace(go.Scatter(x=daily_sales[date_col], y=daily_sales['é”€å”®é¢'],
                                               mode='lines+markers', name='é”€å”®é¢', line=dict(color='#1f77b4')))
                fig_trend.add_trace(go.Scatter(x=daily_sales[date_col], y=daily_sales['åˆ©æ¶¦'],
                                               mode='lines+markers', name='åˆ©æ¶¦', line=dict(color='#ff7f0e')))
                fig_trend.update_layout(title='æ¯æ—¥é”€å”®è¶‹åŠ¿', xaxis_title='æ—¥æœŸ', yaxis_title='é‡‘é¢')
                figs['sales_trend'] = fig_trend

            # 2. å•†å“å“ç±»é”€å”®åˆ†å¸ƒ
            if 'å•†å“å“ç±»' in self.df.columns:
                category_sales = self.df.groupby('å•†å“å“ç±»').agg({
                    'é”€å”®é¢': 'sum',
                    'åˆ©æ¶¦': 'sum'
                }).reset_index()

                fig_category = px.sunburst(category_sales, path=['å•†å“å“ç±»'], values='é”€å”®é¢',
                                           title='å•†å“å“ç±»é”€å”®åˆ†å¸ƒ')
                figs['category_sunburst'] = fig_category

                # æŸ±çŠ¶å›¾ç‰ˆæœ¬
                fig_bar = px.bar(category_sales.nlargest(10, 'é”€å”®é¢'),
                                 x='å•†å“å“ç±»', y='é”€å”®é¢', color='åˆ©æ¶¦',
                                 title='Top 10 å•†å“å“ç±»é”€å”®é¢')
                figs['category_bar'] = fig_bar

            # 3. åœ°ç†åˆ†å¸ƒçƒ­åŠ›å›¾
            if 'åŒºåŸŸ' in self.df.columns:
                region_sales = self.df.groupby('åŒºåŸŸ').agg({
                    'é”€å”®é¢': 'sum',
                    'åˆ©æ¶¦': 'sum'
                }).reset_index()

                fig_region = px.bar(region_sales.nlargest(10, 'é”€å”®é¢'),
                                    x='åŒºåŸŸ', y='é”€å”®é¢', color='åˆ©æ¶¦',
                                    title='åŒºåŸŸé”€å”®é¢Top 10')
                figs['region_bar'] = fig_region

            # 4. å®¢æˆ·ç”»åƒåˆ†æ
            if all(col in self.df.columns for col in ['å®¢æˆ·æ€§åˆ«', 'å®¢æˆ·å¹´é¾„']):
                fig_demographic = px.scatter(self.df, x='å®¢æˆ·å¹´é¾„', y='é”€å”®é¢', color='å®¢æˆ·æ€§åˆ«',
                                             size='é”€å”®æ•°', hover_data=['å•†å“å“ç±»'],
                                             title='å®¢æˆ·å¹´é¾„-é”€å”®é¢åˆ†å¸ƒ')
                figs['demographic_scatter'] = fig_demographic

            # 5. ä»·æ ¼-é”€é‡å…³ç³»å›¾
            if all(col in self.df.columns for col in ['å®é™…å”®ä»·', 'é”€å”®æ•°']):
                fig_price_volume = px.scatter(self.df, x='å®é™…å”®ä»·', y='é”€å”®æ•°', color='å•†å“å“ç±»',
                                              trendline="lowess", title='ä»·æ ¼-é”€é‡å…³ç³»åˆ†æ')
                figs['price_volume'] = fig_price_volume

            # 6. åˆ©æ¶¦è´¡çŒ®åˆ†æ
            if 'åˆ©æ¶¦' in self.df.columns:
                profit_analysis = self.df.nlargest(10, 'åˆ©æ¶¦')
                fig_profit = px.bar(profit_analysis, x='å•†å“å“ç±»', y='åˆ©æ¶¦', color='åŒºåŸŸ',
                                    title='Top 10 åˆ©æ¶¦è´¡çŒ®å•†å“')
                figs['profit_analysis'] = fig_profit

            self.results['interactive_dashboard'] = figs
            return True

        except Exception as e:
            st.error(f"äº¤äº’å¼ä»ªè¡¨æ¿åˆ›å»ºé”™è¯¯: {str(e)}")
            return False

    # ... è¿™é‡Œè¿˜è¦æ·»åŠ  create_advanced_analytics_chartsã€create_customer_segmentation_chartsã€
    # create_performance_metricsã€generate_all_visualizations ç­‰æ–¹æ³• ...


class EnhancedTask2Analyzer:
    def __init__(self, df, column_types):
        self.df = df.copy()
        self.column_types = column_types
        self.results = {}

    def enhanced_task2_multidimensional_analysis(self):
        """å¢å¼ºç‰ˆå¤šç»´åˆ†æé¡µé¢ - ä¼˜åŒ–ç•Œé¢"""
        st.header("ğŸ” ä»»åŠ¡2: å¤šç»´é”€å”®ç‰¹å¾åˆ†æ")

        # ============================================================================
        # é¡¶éƒ¨å·¥å…·æ  - æ¨ªæ’æ“ä½œæŒ‰é’®
        # ============================================================================
        st.markdown("### ğŸ› ï¸ åˆ†æå·¥å…·æ ")
        toolbar_col1, toolbar_col2, toolbar_col3, toolbar_col4, toolbar_col5 = st.columns(5)

        with toolbar_col1:
            data_source_option = st.selectbox(
                "æ•°æ®æº",
                ["ä½¿ç”¨åŸå§‹æ•°æ®", "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶", "ä¸Šä¼ æ–°æ–‡ä»¶"],
                key="data_source_task2"
            )

        with toolbar_col2:
            analysis_mode = st.selectbox(
                "åˆ†ææ¨¡å¼",
                ["ğŸ“Š Pythonå¯è§†åŒ–å±•ç¤º", "ğŸ“ è®ºæ–‡å›¾è¡¨æ•°æ®å¯¼å‡º", "ğŸ¨ äº¤äº’å¼å¯è§†åŒ–ä»ªè¡¨æ¿"],
                key="analysis_mode"
            )

        with toolbar_col3:
            if st.button("ğŸš€ æ‰§è¡Œåˆ†æ", type="primary", use_container_width=True):
                st.session_state.run_analysis = True

        with toolbar_col4:
            if st.session_state.get('task2_completed'):
                if st.button("ğŸ“¥ ä¸‹è½½ç»“æœ", use_container_width=True):
                    st.session_state.download_results = True

        with toolbar_col5:
            if st.button("ğŸ”„ é‡æ–°å¼€å§‹", use_container_width=True):
                st.session_state.task2_completed = False
                st.session_state.run_analysis = False
                st.rerun()

        # ============================================================================
        # æ•°æ®å¯¼å…¥å’Œæ¸…æ´—åŒºåŸŸ
        # ============================================================================
        st.markdown("### ğŸ“ æ•°æ®å‡†å¤‡")

        data_source = None
        current_data = None

        # æ•°æ®æºå¤„ç†
        if data_source_option == "ä½¿ç”¨åŸå§‹æ•°æ®":
            if st.session_state.get('raw_data') is not None:
                current_data = st.session_state.raw_data
                data_source = "åŸå§‹æ•°æ®"
                st.success(f"âœ… ä½¿ç”¨åŸå§‹æ•°æ®ï¼Œå…± {len(current_data)} æ¡è®°å½•")
            else:
                st.error("âŒ æš‚æ— åŸå§‹æ•°æ®ï¼Œè¯·å…ˆåœ¨ä»»åŠ¡1ä¸­ä¸Šä¼ æ–‡ä»¶")
                return

        elif data_source_option == "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶":
            task1_files = {
                "æ­¥éª¤2_è¿›è´§ä»·æ ¼å¤„ç†åæ•°æ®": "step2_price_data",
                "æ­¥éª¤3_åˆ©æ¶¦ä¿®æ­£åæ•°æ®": "step3_profit_data",
                "æ­¥éª¤4_å¼‚å¸¸ä¿®æ­£åŠåˆ©æ¶¦é‡ç®—åæ•°æ®": "step4_abnormal_data",
                "æ­¥éª¤5_MinMaxæ ‡å‡†åŒ–åæ•°æ®": "step5_minmax_data",
                "æ­¥éª¤5_ZScoreæ ‡å‡†åŒ–åæ•°æ®": "step5_zscore_data"
            }

            selected_file = st.selectbox(
                "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶:",
                list(task1_files.keys()),
                key="task1_file_task2"
            )

            if selected_file and st.session_state.get(task1_files[selected_file]) is not None:
                current_data = st.session_state[task1_files[selected_file]]
                data_source = f"ä»»åŠ¡1: {selected_file}"
                st.success(f"âœ… ä½¿ç”¨{selected_file}ï¼Œå…± {len(current_data)} æ¡è®°å½•")
            else:
                st.error("âŒ é€‰æ‹©çš„æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®Œæˆä»»åŠ¡1")
                return

        else:  # ä¸Šä¼ æ–°æ–‡ä»¶
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ å¤šç»´åˆ†ææ•°æ®æ–‡ä»¶",
                type=["xlsx", "csv"],
                key="upload_task2_new"
            )

            if uploaded_file:
                try:
                    if uploaded_file.name.endswith('.xlsx'):
                        current_data = pd.read_excel(uploaded_file)
                    else:
                        current_data = pd.read_csv(uploaded_file)

                    current_data = clean_numeric_columns(current_data)
                    data_source = f"è‡ªå®šä¹‰æ–‡ä»¶: {uploaded_file.name}"
                    st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼å…± {len(current_data)} æ¡è®°å½•")
                except Exception as e:
                    st.error(f"âŒ æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")
                    return
            else:
                st.info("ğŸ“ è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶")
                return

        # æ•°æ®æ¸…æ´—å’Œæ£€æŸ¥
        if current_data is not None:
            # æ•°æ®æ¸…æ´—å¡ç‰‡
            with st.expander("ğŸ§¹ æ•°æ®æ¸…æ´—è®¾ç½®", expanded=True):
                col_clean1, col_clean2 = st.columns(2)

                with col_clean1:
                    # æ•°å€¼å­—æ®µè½¬æ¢
                    numeric_columns = ['åˆ©æ¶¦', 'é”€å”®é¢', 'é”€å”®æ•°', 'å®é™…å”®ä»·', 'è¿›è´§ä»·æ ¼']
                    for col in numeric_columns:
                        if col in current_data.columns:
                            current_data[col] = pd.to_numeric(current_data[col], errors='coerce')

                    # åŒºåŸŸå­—æ®µå¤„ç†
                    if 'åŒºåŸŸ' in current_data.columns:
                        current_data['åŒºåŸŸ'] = current_data['åŒºåŸŸ'].astype(str)
                        if current_data['åŒºåŸŸ'].str.contains('-').any():
                            current_data['çœä»½'] = current_data['åŒºåŸŸ'].apply(
                                lambda x: x.split('-')[1] if '-' in str(x) and len(x.split('-')) > 1 else x
                            )
                        else:
                            current_data['çœä»½'] = current_data['åŒºåŸŸ']

                with col_clean2:
                    # ç§»é™¤ç©ºå€¼
                    original_count = len(current_data)
                    if 'åˆ©æ¶¦' in current_data.columns:
                        current_data = current_data.dropna(subset=['åˆ©æ¶¦'])
                        removed_count = original_count - len(current_data)
                        if removed_count > 0:
                            st.warning(f"ç§»é™¤ {removed_count} æ¡åˆ©æ¶¦ä¸ºç©ºçš„è®°å½•")

            # æ•°æ®é¢„è§ˆå¡ç‰‡
            with st.expander("ğŸ‘€ æ•°æ®é¢„è§ˆ", expanded=False):
                preview_col1, preview_col2 = st.columns(2)
                with preview_col1:
                    st.dataframe(current_data.head(8))
                with preview_col2:
                    # æ•°æ®ç»Ÿè®¡
                    st.metric("æ€»è®°å½•æ•°", len(current_data))
                    st.metric("å­—æ®µæ•°é‡", len(current_data.columns))
                    st.metric("æ•°æ®å¤§å°", f"{current_data.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB")

        # ============================================================================
        # åˆ†ææ‰§è¡Œå’Œç»“æœæ˜¾ç¤ºåŒºåŸŸ
        # ============================================================================
        if st.session_state.get('run_analysis') and current_data is not None:
            st.markdown("---")
            st.markdown("### ğŸ“ˆ åˆ†ææ‰§è¡Œ")

            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            required_columns = ['åŒºåŸŸ', 'å•†å“å“ç±»', 'åˆ©æ¶¦']
            missing_columns = [col for col in required_columns if col not in current_data.columns]
            if missing_columns:
                st.error(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_columns)}")
                st.info("ğŸ’¡ å¤šç»´åˆ†æéœ€è¦ä»¥ä¸‹å­—æ®µï¼šåŒºåŸŸã€å•†å“å“ç±»ã€åˆ©æ¶¦")
                return

            with st.spinner("ğŸ”„ æ­£åœ¨æ‰§è¡Œå¤šç»´åˆ†æ..."):
                # è‡ªåŠ¨æ£€æµ‹å­—æ®µç±»å‹
                column_types = auto_detect_column_types(current_data)

                analyzer = EnhancedTask2Analyzer(current_data, column_types)
                visualizer = EnhancedVisualizer(current_data, column_types)

                # æ‰§è¡Œåˆ†æ
                heatmap_success = analyzer.create_heatmaps()
                cluster_success = analyzer.perform_clustering_analysis()
                visualization_success = visualizer.generate_all_visualizations()

                # ç”Ÿæˆæ‰€æœ‰åˆ†ææ•°æ®
                all_analysis_data = analyzer.generate_all_analysis_data()

                # ä¿å­˜ç»“æœåˆ°session state
                st.session_state.task2_results = analyzer.results
                st.session_state.task2_visualizations = visualizer.results
                st.session_state.task2_analysis_data = all_analysis_data
                st.session_state.task2_completed = True

            # åˆ†æç»“æœæ‘˜è¦
            st.success("âœ… å¤šç»´ç‰¹å¾åˆ†æå®Œæˆï¼")

            summary_col1, summary_col2, summary_col3, summary_col4 = st.columns(4)
            with summary_col1:
                st.metric("çƒ­åŠ›å›¾åˆ†æ", "âœ… å®Œæˆ" if heatmap_success else "âŒ å¤±è´¥")
            with summary_col2:
                st.metric("èšç±»åˆ†æ", "âœ… å®Œæˆ" if cluster_success else "âŒ å¤±è´¥")
            with summary_col3:
                st.metric("å¯è§†åŒ–", "âœ… å®Œæˆ" if visualization_success else "âš ï¸ éƒ¨åˆ†å®Œæˆ")
            with summary_col4:
                analysis_count = sum(1 for data in all_analysis_data.values() if data is not None)
                st.metric("åˆ†æç»´åº¦", f"{analysis_count}ä¸ª")

            # ç»“æœæ˜¾ç¤º
            st.markdown("### ğŸ“Š åˆ†æç»“æœ")

            if analysis_mode == "ğŸ“Š Pythonå¯è§†åŒ–å±•ç¤º":
                show_python_visualizations(analyzer)
            elif analysis_mode == "ğŸ“ è®ºæ–‡å›¾è¡¨æ•°æ®å¯¼å‡º":
                show_data_export_interface(all_analysis_data)
            else:  # äº¤äº’å¼å¯è§†åŒ–ä»ªè¡¨æ¿
                show_interactive_dashboard_optimized(visualizer.results)

        elif not st.session_state.get('run_analysis'):
            # åˆ†æå‰çš„åŠŸèƒ½è¯´æ˜
            st.markdown("---")
            st.markdown("### ğŸ’¡ åŠŸèƒ½è¯´æ˜")

            info_col1, info_col2, info_col3 = st.columns(3)

            with info_col1:
                st.markdown("""
                <div style='background: white; padding: 1.5rem; border-radius: 10px; border-left: 4px solid #007bff;'>
                <h4>ğŸ“Š Pythonå¯è§†åŒ–</h4>
                <ul>
                <li>äº¤å‰ç»´åº¦çƒ­åŠ›å›¾</li>
                <li>å®¢æˆ·-å•†å“èšç±»</li>
                <li>ç³»ç»Ÿå†…ç½®å›¾è¡¨</li>
                </ul>
                </div>
                """, unsafe_allow_html=True)

            with info_col2:
                st.markdown("""
                <div style='background: white; padding: 1.5rem; border-radius: 10px; border-left: 4px solid #28a745;'>
                <h4>ğŸ“ æ•°æ®å¯¼å‡º</h4>
                <ul>
                <li>åŸå¸‚åˆ†å¸ƒæ•°æ®</li>
                <li>å®¢æˆ·ç”»åƒæ•°æ®</li>
                <li>æ—¶é—´åºåˆ—æ•°æ®</li>
                <li>ç›¸å…³æ€§çŸ©é˜µ</li>
                </ul>
                </div>
                """, unsafe_allow_html=True)

            with info_col3:
                st.markdown("""
                <div style='background: white; padding: 1.5rem; border-radius: 10px; border-left: 4px solid #ff6b6b;'>
                <h4>ğŸ¨ äº¤äº’å¼ä»ªè¡¨æ¿</h4>
                <ul>
                <li>å®æ—¶æŒ‡æ ‡ç›‘æ§</li>
                <li>äº¤äº’å¼å›¾è¡¨</li>
                <li>é«˜çº§åˆ†æåŠŸèƒ½</li>
                <li>å®¢æˆ·åˆ†ç¾¤åˆ†æ</li>
                </ul>
                </div>
                """, unsafe_allow_html=True)

        # ä¸‹è½½åŠŸèƒ½
        if st.session_state.get('download_results') and st.session_state.task2_completed:
            st.markdown("---")
            st.markdown("### ğŸ“¥ ç»“æœä¸‹è½½")
            # è¿™é‡Œæ·»åŠ å…·ä½“çš„ä¸‹è½½é€»è¾‘
            st.info("ä¸‹è½½åŠŸèƒ½å·²å°±ç»ªï¼Œå¯é€‰æ‹©éœ€è¦ä¸‹è½½çš„åˆ†æç»“æœæ–‡ä»¶")

    def create_heatmaps(self):
        """åˆ›å»ºçƒ­åŠ›å›¾ - ä¿®å¤æ•°æ®ç±»å‹é”™è¯¯"""
        try:
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
            plt.rcParams['axes.unicode_minus'] = False

            figs = {}

            # 1. å•†å“å“ç±»ä¸çœä»½äº¤å‰çƒ­åŠ›å›¾
            if all(col in self.df.columns for col in ['åŒºåŸŸ', 'å•†å“å“ç±»', 'åˆ©æ¶¦']):
                # æå–çœä»½
                if self.df['åŒºåŸŸ'].str.contains('-').any():
                    self.df['çœä»½'] = self.df['åŒºåŸŸ'].apply(lambda x: x.split('-')[1] if '-' in str(x) else x)
                else:
                    self.df['çœä»½'] = self.df['åŒºåŸŸ']

                # æ•°æ®æ¸…æ´—ï¼šç¡®ä¿åˆ©æ¶¦æ˜¯æ•°å€¼ç±»å‹
                self.df['åˆ©æ¶¦'] = pd.to_numeric(self.df['åˆ©æ¶¦'], errors='coerce')
                self.df = self.df.dropna(subset=['åˆ©æ¶¦'])

                # åˆ›å»ºæ•°æ®é€è§†è¡¨ï¼Œç¡®ä¿æ•°æ®æ˜¯æ•°å€¼ç±»å‹
                category_province_pivot = self.df.pivot_table(
                    index='å•†å“å“ç±»',
                    columns='çœä»½',
                    values='åˆ©æ¶¦',
                    aggfunc='sum',
                    fill_value=0
                )

                # ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½æ˜¯æ•°å€¼ç±»å‹
                category_province_pivot = category_province_pivot.apply(pd.to_numeric, errors='coerce').fillna(0)

                # è¿‡æ»¤æ‰å…¨ä¸º0çš„è¡Œå’Œåˆ—
                category_province_pivot = category_province_pivot.loc[
                    (category_province_pivot != 0).any(axis=1),
                    (category_province_pivot != 0).any(axis=0)
                ]

                if not category_province_pivot.empty and len(category_province_pivot) > 1:
                    plt.figure(figsize=(12, 8))
                    sns.heatmap(category_province_pivot,
                                cmap='Blues',
                                annot=False,
                                cbar_kws={'label': 'åˆ©æ¶¦æ€»é¢'})
                    plt.title('å•†å“å“ç±»å’Œçœä»½äº¤å‰çš„åˆ©æ¶¦çƒ­åŠ›å›¾', fontsize=14, fontweight='bold')
                    plt.xlabel('çœä»½', fontsize=12)
                    plt.xticks(rotation=45, ha='right')
                    plt.ylabel('å•†å“å“ç±»', fontsize=12)
                    plt.tight_layout()
                    figs['category_province_profit'] = plt.gcf()
                    plt.close()
                else:
                    st.warning("å•†å“å“ç±»-çœä»½çƒ­åŠ›å›¾ï¼šæ•°æ®ä¸è¶³æˆ–å…¨ä¸º0å€¼")

            # 2. çœä»½ä¸æ—¥æœŸäº¤å‰çƒ­åŠ›å›¾
            if all(col in self.df.columns for col in ['æ—¥æœŸ', 'çœä»½', 'åˆ©æ¶¦']):
                # æ•°æ®æ¸…æ´—
                self.df['åˆ©æ¶¦'] = pd.to_numeric(self.df['åˆ©æ¶¦'], errors='coerce')
                self.df = self.df.dropna(subset=['åˆ©æ¶¦', 'æ—¥æœŸ'])

                # å¦‚æœçœä»½åˆ—ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
                if 'çœä»½' not in self.df.columns and 'åŒºåŸŸ' in self.df.columns:
                    if self.df['åŒºåŸŸ'].str.contains('-').any():
                        self.df['çœä»½'] = self.df['åŒºåŸŸ'].apply(lambda x: x.split('-')[1] if '-' in str(x) else x)
                    else:
                        self.df['çœä»½'] = self.df['åŒºåŸŸ']

                # æ—¥æœŸå¤„ç†ï¼šè½¬æ¢ä¸ºå­—ç¬¦ä¸²é¿å…æ•°å€¼é—®é¢˜
                self.df['æ—¥æœŸ'] = self.df['æ—¥æœŸ'].astype(str)

                province_date_pivot = self.df.pivot_table(
                    index='çœä»½',
                    columns='æ—¥æœŸ',
                    values='åˆ©æ¶¦',
                    aggfunc='sum',
                    fill_value=0
                )

                # ç¡®ä¿æ•°æ®æ˜¯æ•°å€¼ç±»å‹
                province_date_pivot = province_date_pivot.apply(pd.to_numeric, errors='coerce').fillna(0)

                # è¿‡æ»¤æ•°æ®ï¼Œåªæ˜¾ç¤ºæœ‰å˜åŒ–çš„æ—¥æœŸå’Œçœä»½
                province_date_pivot = province_date_pivot.loc[
                    (province_date_pivot != 0).any(axis=1),
                    (province_date_pivot != 0).any(axis=0)
                ]

                # é™åˆ¶åˆ—æ•°ï¼Œé¿å…å›¾è¡¨è¿‡äºæ‹¥æŒ¤
                if len(province_date_pivot.columns) > 20:
                    province_date_pivot = province_date_pivot.iloc[:, :20]  # åªå–å‰20ä¸ªæ—¥æœŸ

                if not province_date_pivot.empty and len(province_date_pivot) > 1:
                    plt.figure(figsize=(15, 8))
                    sns.heatmap(province_date_pivot,
                                cmap='Blues',
                                annot=False,
                                cbar_kws={'label': 'åˆ©æ¶¦æ€»é¢'})
                    plt.title('çœä»½å’Œæ—¥æœŸäº¤å‰çš„åˆ©æ¶¦çƒ­åŠ›å›¾', fontsize=14, fontweight='bold')
                    plt.xlabel('æ—¥æœŸ', fontsize=12)
                    plt.xticks(rotation=90)
                    plt.ylabel('çœä»½', fontsize=12)
                    plt.tight_layout()
                    figs['province_date_profit'] = plt.gcf()
                    plt.close()
                else:
                    st.warning("çœä»½-æ—¥æœŸçƒ­åŠ›å›¾ï¼šæ•°æ®ä¸è¶³æˆ–å…¨ä¸º0å€¼")

            # 3. å¤‡ç”¨çƒ­åŠ›å›¾ï¼šå•†å“å“ç±»ä¸åˆ©æ¶¦å…³ç³»
            if all(col in self.df.columns for col in ['å•†å“å“ç±»', 'åˆ©æ¶¦']):
                # æ•°æ®æ¸…æ´—
                self.df['åˆ©æ¶¦'] = pd.to_numeric(self.df['åˆ©æ¶¦'], errors='coerce')
                self.df = self.df.dropna(subset=['åˆ©æ¶¦'])

                category_profit = self.df.groupby('å•†å“å“ç±»')['åˆ©æ¶¦'].sum().sort_values(ascending=False).head(10)

                if len(category_profit) > 1:
                    plt.figure(figsize=(10, 6))
                    category_profit.plot(kind='bar', color='skyblue', alpha=0.8)
                    plt.title('Top 10å•†å“å“ç±»åˆ©æ¶¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
                    plt.xlabel('å•†å“å“ç±»', fontsize=12)
                    plt.ylabel('åˆ©æ¶¦æ€»é¢', fontsize=12)
                    plt.xticks(rotation=45, ha='right')
                    plt.grid(axis='y', alpha=0.3)
                    plt.tight_layout()
                    figs['category_profit_bar'] = plt.gcf()
                    plt.close()

            self.results['heatmaps'] = figs
            return len(figs) > 0

        except Exception as e:
            st.error(f"çƒ­åŠ›å›¾ç”Ÿæˆé”™è¯¯: {str(e)}")
            import traceback
            st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return False

    def perform_clustering_analysis(self):
        """æ‰§è¡Œèšç±»åˆ†æ - åŸæœ‰çš„èšç±»åŠŸèƒ½"""
        try:
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
            plt.rcParams['axes.unicode_minus'] = False

            # é€‰æ‹©æ•°å€¼å‹åˆ—è¿›è¡Œèšç±»
            numeric_cols = ['å®¢æˆ·å¹´é¾„', 'è¿›è´§ä»·æ ¼', 'å®é™…å”®ä»·', 'é”€å”®æ•°', 'é”€å”®é¢', 'åˆ©æ¶¦']
            existing_numeric_cols = [col for col in numeric_cols if col in self.df.columns]

            if len(existing_numeric_cols) < 2:
                st.warning(f"å¯ç”¨äºèšç±»çš„æ•°å€¼å‹åˆ—ä¸è¶³ï¼Œä»…æ‰¾åˆ°: {existing_numeric_cols}")
                return False

            # æå–æ•°å€¼å‹æ•°æ®å¹¶å¤„ç†ç¼ºå¤±å€¼
            df_numeric = self.df[existing_numeric_cols].fillna(0)

            # ç¡®å®šæœ€ä½³èšç±»æ•°k
            sse = []
            silhouette_scores = []
            k_range = range(2, 11)

            for k in k_range:
                kmeans = KMeans(n_clusters=k, random_state=2024, n_init='auto')
                kmeans.fit(df_numeric)
                sse.append(kmeans.inertia_)
                labels = kmeans.labels_
                score = silhouette_score(df_numeric, labels)
                silhouette_scores.append(score)

            # ç»˜åˆ¶è¯„ä¼°å›¾è¡¨
            fig1, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
            ax1.plot(k_range, sse, 'bx-')
            ax1.set_xlabel('èšç±»æ•°é‡k')
            ax1.set_ylabel('SSEï¼ˆè¯¯å·®å¹³æ–¹å’Œï¼‰')
            ax1.set_title('æ‰‹è‚˜æ³•ç¡®å®šæœ€ä½³kå€¼')
            ax2.plot(k_range, silhouette_scores, 'rx-')
            ax2.set_xlabel('èšç±»æ•°é‡k')
            ax2.set_ylabel('è½®å»“ç³»æ•°')
            ax2.set_title('è½®å»“ç³»æ•°ç¡®å®šæœ€ä½³kå€¼')
            plt.tight_layout()

            self.results['cluster_evaluation_plot'] = fig1

            # é€‰æ‹©æœ€ä½³kå€¼
            best_k_index = silhouette_scores.index(max(silhouette_scores))
            best_k = k_range[best_k_index]

            # ä½¿ç”¨æœ€ä½³kå€¼æ‰§è¡Œæœ€ç»ˆèšç±»
            final_kmeans = KMeans(n_clusters=best_k, random_state=2024, n_init='auto')
            cluster_labels = final_kmeans.fit_predict(df_numeric)

            # ä¿å­˜èšç±»ç»“æœ
            df_clustered = self.df.copy()
            df_clustered['èšç±»æ ‡ç­¾'] = cluster_labels
            cluster_analysis = df_clustered.groupby('èšç±»æ ‡ç­¾')[existing_numeric_cols].mean().round(2)

            self.results['clustered_data'] = df_clustered
            self.results['cluster_analysis'] = cluster_analysis
            self.results['best_k'] = best_k

            return True

        except Exception as e:
            st.error(f"èšç±»åˆ†æé”™è¯¯: {str(e)}")
            return False

    def generate_city_distribution_data(self):
        """ç”ŸæˆåŸå¸‚åˆ†å¸ƒæ•°æ®ï¼ˆå¯¹åº”è®ºæ–‡å›¾4ï¼‰"""
        if 'åŒºåŸŸ' not in self.df.columns:
            return None

        # æå–åŸå¸‚ä¿¡æ¯
        if self.df['åŒºåŸŸ'].str.contains('-').any():
            self.df['åŸå¸‚'] = self.df['åŒºåŸŸ'].apply(lambda x: x.split('-')[1] if '-' in str(x) else x)
        else:
            self.df['åŸå¸‚'] = self.df['åŒºåŸŸ']

        # åŸå¸‚ç”¨æˆ·æ•°ç»Ÿè®¡
        city_stats = self.df['åŸå¸‚'].value_counts().reset_index()
        city_stats.columns = ['åŸå¸‚', 'ç”¨æˆ·æ•°']
        city_stats = city_stats.head(15)  # Top 15åŸå¸‚

        return city_stats

    def generate_province_distribution_data(self):
        """ç”Ÿæˆçœä»½åˆ†å¸ƒæ•°æ®ï¼ˆå¯¹åº”è®ºæ–‡å›¾5ï¼‰"""
        if 'åŒºåŸŸ' not in self.df.columns:
            return None

        # æå–çœä»½ä¿¡æ¯
        if 'çœä»½' not in self.df.columns:
            if self.df['åŒºåŸŸ'].str.contains('-').any():
                self.df['çœä»½'] = self.df['åŒºåŸŸ'].apply(lambda x: x.split('-')[0] if '-' in str(x) else x)
            else:
                self.df['çœä»½'] = self.df['åŒºåŸŸ']

        province_stats = self.df['çœä»½'].value_counts().reset_index()
        province_stats.columns = ['çœä»½', 'ç”¨æˆ·æ•°']

        return province_stats

    def generate_city_tier_data(self):
        """ç”ŸæˆåŸå¸‚åˆ†çº§æ•°æ®ï¼ˆå¯¹åº”è®ºæ–‡å›¾6ï¼‰"""
        if 'åŸå¸‚' not in self.df.columns:
            return None

        # åŸå¸‚åˆ†çº§å®šä¹‰ï¼ˆæ ¹æ®è®ºæ–‡ï¼‰
        tier_1 = ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³']
        tier_2 = ['æ˜†æ˜', 'ç¦å·', 'å¦é—¨', 'æ— é”¡', 'å“ˆå°”æ»¨', 'é•¿æ˜¥', 'å®æ³¢', 'æµå—', 'å¤§è¿', 'éƒ‘å·',
                  'é•¿æ²™', 'æˆéƒ½', 'æ­å·', 'å—äº¬', 'æ­¦æ±‰', 'è¥¿å®‰', 'è‹å·', 'å¤©æ´¥', 'é’å²›', 'æ²ˆé˜³',
                  'ä¸œè', 'ä½›å±±', 'åˆè‚¥', 'çŸ³å®¶åº„', 'å—å®', 'å¸¸å·', 'çƒŸå°', 'å”å±±', 'å¾å·', 'æ¸©å·']
        tier_3 = ['å…°å·', 'æµ·å£', 'ä¹Œé²æœ¨é½', 'è´µé˜³', 'é“¶å·', 'è¥¿å®', 'å‘¼å’Œæµ©ç‰¹', 'æ‹‰è¨', 'ä¿å®š',
                  'æƒ å·', 'ç æµ·', 'ä¸­å±±', 'æ±Ÿé—¨', 'è‚‡åº†', 'æ¸…è¿œ', 'éŸ¶å…³', 'æ¹›æ±Ÿ', 'èŒ‚å', 'é˜³æ±Ÿ',
                  'äº‘æµ®', 'æ±•å¤´', 'æ½®å·', 'æ­é˜³', 'æ±•å°¾', 'æ¢…å·', 'æ²³æº']

        def assign_city_tier(city):
            if pd.isna(city):
                return 'å…¶ä»–åŸå¸‚'
            city_str = str(city)
            if city_str in tier_1:
                return 'ä¸€çº¿åŸå¸‚'
            elif city_str in tier_2:
                return 'äºŒçº¿åŸå¸‚'
            elif city_str in tier_3:
                return 'ä¸‰çº¿åŸå¸‚'
            else:
                return 'å…¶ä»–åŸå¸‚'

        self.df['åŸå¸‚ç­‰çº§'] = self.df['åŸå¸‚'].apply(assign_city_tier)
        tier_stats = self.df['åŸå¸‚ç­‰çº§'].value_counts().reset_index()
        tier_stats.columns = ['åŸå¸‚ç­‰çº§', 'ç”¨æˆ·æ•°']
        tier_stats['å æ¯”'] = (tier_stats['ç”¨æˆ·æ•°'] / len(self.df) * 100).round(2)

        return tier_stats

    def generate_region_tier_data(self):
        """ç”ŸæˆåŒºåŸŸåˆ†çº§æ•°æ®ï¼ˆå¯¹åº”è®ºæ–‡å›¾7ï¼‰"""
        if 'çœä»½' not in self.df.columns:
            return None

        # åŒºåŸŸå®šä¹‰
        region_mapping = {
            'åå—': ['å¹¿ä¸œ', 'å¹¿è¥¿', 'æµ·å—', 'ç¦å»º'],
            'åä¸œ': ['ä¸Šæµ·', 'æ±Ÿè‹', 'æµ™æ±Ÿ', 'å®‰å¾½', 'æ±Ÿè¥¿', 'å±±ä¸œ'],
            'ååŒ—': ['åŒ—äº¬', 'å¤©æ´¥', 'æ²³åŒ—', 'å±±è¥¿', 'å†…è’™å¤'],
            'ä¸œåŒ—': ['è¾½å®', 'å‰æ—', 'é»‘é¾™æ±Ÿ'],
            'è¥¿å—': ['é‡åº†', 'å››å·', 'è´µå·', 'äº‘å—', 'è¥¿è—'],
            'è¥¿åŒ—': ['é™•è¥¿', 'ç”˜è‚ƒ', 'é’æµ·', 'å®å¤', 'æ–°ç–†'],
            'åä¸­': ['æ²³å—', 'æ¹–åŒ—', 'æ¹–å—']
        }

        def assign_region(province):
            if pd.isna(province):
                return 'å…¶ä»–'
            province_str = str(province)
            for region, provinces in region_mapping.items():
                if province_str in provinces:
                    return region
            return 'å…¶ä»–'

        self.df['å¤§åŒº'] = self.df['çœä»½'].apply(assign_region)
        region_stats = self.df['å¤§åŒº'].value_counts().reset_index()
        region_stats.columns = ['å¤§åŒº', 'ç”¨æˆ·æ•°']
        region_stats['å æ¯”'] = (region_stats['ç”¨æˆ·æ•°'] / len(self.df) * 100).round(2)

        return region_stats

    def generate_gender_category_analysis(self):
        """ç”Ÿæˆæ€§åˆ«-å“ç±»åˆ†ææ•°æ®ï¼ˆå¯¹åº”è®ºæ–‡å›¾8ï¼‰"""
        if not all(col in self.df.columns for col in ['å®¢æˆ·æ€§åˆ«', 'å•†å“å“ç±»']):
            return None

        gender_category_stats = self.df.groupby(['å•†å“å“ç±»', 'å®¢æˆ·æ€§åˆ«']).size().reset_index()
        gender_category_stats.columns = ['å•†å“å“ç±»', 'å®¢æˆ·æ€§åˆ«', 'è®¢å•äººæ•°']

        return gender_category_stats

    def generate_age_gender_analysis(self):
        """ç”Ÿæˆå¹´é¾„-æ€§åˆ«åˆ†ææ•°æ®ï¼ˆå¯¹åº”è®ºæ–‡å›¾9ï¼‰"""
        if 'å®¢æˆ·å¹´é¾„' not in self.df.columns or 'å®¢æˆ·æ€§åˆ«' not in self.df.columns:
            return None

        # å¹´é¾„åˆ†æ®µ
        def assign_age_group(age):
            if pd.isna(age):
                return 'æœªçŸ¥'
            try:
                age = int(age)
                if age < 25:
                    return '20-24å²'
                elif age < 30:
                    return '25-29å²'
                elif age < 35:
                    return '30-34å²'
                elif age < 40:
                    return '35-39å²'
                elif age < 45:
                    return '40-44å²'
                elif age < 50:
                    return '45-49å²'
                elif age < 55:
                    return '50-54å²'
                elif age < 60:
                    return '55-59å²'
                else:
                    return '60å²ä»¥ä¸Š'
            except:
                return 'æœªçŸ¥'

        self.df['å¹´é¾„æ®µ'] = self.df['å®¢æˆ·å¹´é¾„'].apply(assign_age_group)
        age_gender_stats = self.df.groupby(['å¹´é¾„æ®µ', 'å®¢æˆ·æ€§åˆ«']).size().reset_index()
        age_gender_stats.columns = ['å¹´é¾„æ®µ', 'å®¢æˆ·æ€§åˆ«', 'è®¢å•äººæ•°']

        return age_gender_stats

    def generate_time_series_analysis(self):
        """ç”Ÿæˆæ—¶é—´åºåˆ—åˆ†ææ•°æ®ï¼ˆå¯¹åº”è®ºæ–‡å›¾10ï¼‰"""
        date_col = next((col for col in self.column_types['identifier'] if 'æ—¥æœŸ' in col), None)
        if not date_col:
            return None

        time_stats = self.df.groupby(date_col).size().reset_index()
        time_stats.columns = ['æ—¥æœŸ', 'è®¢å•äººæ•°æ€»å’Œ']

        return time_stats

    def generate_correlation_analysis(self):
        """ç”Ÿæˆç›¸å…³æ€§åˆ†ææ•°æ®ï¼ˆå¯¹åº”è®ºæ–‡å›¾13ï¼‰"""
        numeric_cols = self.column_types['numeric']
        if len(numeric_cols) < 2:
            return None

        correlation_matrix = self.df[numeric_cols].corr().round(4)

        return correlation_matrix

    def generate_all_analysis_data(self):
        """ç”Ÿæˆæ‰€æœ‰åˆ†æç»´åº¦çš„æ•°æ®"""
        analysis_results = {}

        # åœ°ç†åˆ†å¸ƒåˆ†æ
        analysis_results['city_distribution'] = self.generate_city_distribution_data()
        analysis_results['province_distribution'] = self.generate_province_distribution_data()
        analysis_results['city_tier_analysis'] = self.generate_city_tier_data()
        analysis_results['region_tier_analysis'] = self.generate_region_tier_data()

        # å®¢æˆ·ç”»åƒåˆ†æ
        analysis_results['gender_category_analysis'] = self.generate_gender_category_analysis()
        analysis_results['age_gender_analysis'] = self.generate_age_gender_analysis()

        # æ—¶é—´åºåˆ—åˆ†æ
        analysis_results['time_series_analysis'] = self.generate_time_series_analysis()

        # ç»Ÿè®¡å…³ç³»åˆ†æ
        analysis_results['correlation_analysis'] = self.generate_correlation_analysis()

        # ä¿ç•™åŸæœ‰çš„çƒ­åŠ›å›¾å’Œèšç±»åˆ†æ
        analysis_results.update(self.results)

        return analysis_results


def show_python_visualizations(analyzer):
    """æ˜¾ç¤ºPythonåŸç”Ÿå¯è§†åŒ–"""
    st.subheader("ğŸ“Š Pythonå¯è§†åŒ–å±•ç¤º")

    # åŸæœ‰çš„çƒ­åŠ›å›¾å’Œèšç±»åˆ†æå±•ç¤º
    if 'heatmaps' in analyzer.results and len(analyzer.results['heatmaps']) > 0:
        st.subheader("1. äº¤å‰ç»´åº¦çƒ­åŠ›å›¾åˆ†æ")
        for name, fig in analyzer.results['heatmaps'].items():
            st.pyplot(fig)

    if 'cluster_evaluation_plot' in analyzer.results:
        st.subheader("2. èšç±»åˆ†æç»“æœ")
        st.pyplot(analyzer.results['cluster_evaluation_plot'])

        if 'cluster_analysis' in analyzer.results:
            st.subheader("èšç±»ç‰¹å¾å¹³å‡å€¼å¯¹æ¯”")
            st.dataframe(analyzer.results['cluster_analysis'])


def show_data_export_interface(analysis_data):
    """æ˜¾ç¤ºæ•°æ®å¯¼å‡ºç•Œé¢ - ä½¿ç”¨Excelæ ¼å¼é¿å…ç¼–ç é—®é¢˜"""
    st.subheader("ğŸ“ è®ºæ–‡å›¾è¡¨æ•°æ®å¯¼å‡º")

    st.markdown("""
    ### å¯¼å‡ºè¯´æ˜
    ä»¥ä¸‹æ•°æ®å¯ç›´æ¥ç”¨äºåœ¨Excelã€Tableauã€Echartsç­‰å·¥å…·ä¸­åˆ¶ä½œè®ºæ–‡å›¾è¡¨ã€‚
    ä¸ºé¿å…ç¼–ç é—®é¢˜ï¼Œå·²æä¾›Excelæ ¼å¼ä¸‹è½½ã€‚
    """)

    def convert_to_excel(df, sheet_name="æ•°æ®"):
        """å°†DataFrameè½¬æ¢ä¸ºExcelæ ¼å¼"""
        import io
        output = io.BytesIO()

        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name=sheet_name, index=False)

        output.seek(0)
        return output.getvalue()

    # åœ°ç†åˆ†å¸ƒæ•°æ®å¯¼å‡º
    st.markdown("#### ğŸŒ åœ°ç†åˆ†å¸ƒåˆ†æ")
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        if analysis_data.get('city_distribution') is not None:
            excel_data = convert_to_excel(analysis_data['city_distribution'], "åŸå¸‚åˆ†å¸ƒ")
            st.download_button(
                label="ä¸‹è½½åŸå¸‚åˆ†å¸ƒæ•°æ®",
                data=excel_data,
                file_name="åŸå¸‚åˆ†å¸ƒæ•°æ®_Top15åŸå¸‚.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    with col2:
        if analysis_data.get('province_distribution') is not None:
            excel_data = convert_to_excel(analysis_data['province_distribution'], "çœä»½åˆ†å¸ƒ")
            st.download_button(
                label="ä¸‹è½½çœä»½åˆ†å¸ƒæ•°æ®",
                data=excel_data,
                file_name="çœä»½åˆ†å¸ƒæ•°æ®.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    with col3:
        if analysis_data.get('city_tier_analysis') is not None:
            excel_data = convert_to_excel(analysis_data['city_tier_analysis'], "åŸå¸‚åˆ†çº§")
            st.download_button(
                label="ä¸‹è½½åŸå¸‚åˆ†çº§æ•°æ®",
                data=excel_data,
                file_name="åŸå¸‚åˆ†çº§ç¯çŠ¶å›¾æ•°æ®.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    with col4:
        if analysis_data.get('region_tier_analysis') is not None:
            excel_data = convert_to_excel(analysis_data['region_tier_analysis'], "åŒºåŸŸåˆ†çº§")
            st.download_button(
                label="ä¸‹è½½åŒºåŸŸåˆ†çº§æ•°æ®",
                data=excel_data,
                file_name="åŒºåŸŸåˆ†çº§ç¯çŠ¶å›¾æ•°æ®.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    # å®¢æˆ·ç”»åƒæ•°æ®å¯¼å‡º
    st.markdown("#### ğŸ‘¥ å®¢æˆ·ç”»åƒåˆ†æ")
    col1, col2 = st.columns(2)

    with col1:
        if analysis_data.get('gender_category_analysis') is not None:
            excel_data = convert_to_excel(analysis_data['gender_category_analysis'], "æ€§åˆ«å“ç±»")
            st.download_button(
                label="ä¸‹è½½æ€§åˆ«-å“ç±»æ•°æ®",
                data=excel_data,
                file_name="æ€§åˆ«å“ç±»äº¤å‰åˆ†ææ•°æ®.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    with col2:
        if analysis_data.get('age_gender_analysis') is not None:
            excel_data = convert_to_excel(analysis_data['age_gender_analysis'], "å¹´é¾„æ€§åˆ«")
            st.download_button(
                label="ä¸‹è½½å¹´é¾„-æ€§åˆ«æ•°æ®",
                data=excel_data,
                file_name="å¹´é¾„æ€§åˆ«åˆ†å¸ƒæ•°æ®.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    # æ—¶é—´åºåˆ—å’Œç›¸å…³æ€§åˆ†æ
    st.markdown("#### ğŸ“ˆ æ—¶é—´ä¸å…³ç³»åˆ†æ")
    col1, col2 = st.columns(2)

    with col1:
        if analysis_data.get('time_series_analysis') is not None:
            excel_data = convert_to_excel(analysis_data['time_series_analysis'], "æ—¶é—´åºåˆ—")
            st.download_button(
                label="ä¸‹è½½æ—¶é—´åºåˆ—æ•°æ®",
                data=excel_data,
                file_name="æ—¶é—´åºåˆ—è®¢å•æ•°æ®.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    with col2:
        if analysis_data.get('correlation_analysis') is not None:
            # ç›¸å…³æ€§çŸ©é˜µéœ€è¦ä¿ç•™ç´¢å¼•
            import io
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                analysis_data['correlation_analysis'].to_excel(writer, sheet_name="ç›¸å…³æ€§çŸ©é˜µ")
            excel_data = output.getvalue()
            st.download_button(
                label="ä¸‹è½½ç›¸å…³æ€§çŸ©é˜µ",
                data=excel_data,
                file_name="å˜é‡ç›¸å…³æ€§çŸ©é˜µ.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    # æ•°æ®é¢„è§ˆï¼ˆä¿æŒä¸å˜ï¼‰
    st.markdown("#### ğŸ‘€ æ•°æ®é¢„è§ˆ")
    available_datasets = [key for key in analysis_data.keys() if
                          analysis_data[key] is not None and hasattr(analysis_data[key], 'head')]
    if available_datasets:
        dataset_to_preview = st.selectbox(
            "é€‰æ‹©è¦é¢„è§ˆçš„æ•°æ®é›†:",
            available_datasets
        )

        if dataset_to_preview:
            st.dataframe(analysis_data[dataset_to_preview].head(10))

            # æ•°æ®ç»Ÿè®¡ä¿¡æ¯
            st.markdown("**æ•°æ®ç»Ÿè®¡:**")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("è¡Œæ•°", len(analysis_data[dataset_to_preview]))
            with col2:
                st.metric("åˆ—æ•°", len(analysis_data[dataset_to_preview].columns))
            with col3:
                st.metric("æ•°æ®ç±»å‹", str(analysis_data[dataset_to_preview].dtypes.unique()[0]))

    st.success("âœ… ç°åœ¨ä¸‹è½½çš„Excelæ–‡ä»¶åº”è¯¥ä¸ä¼šå‡ºç°ä¹±ç é—®é¢˜äº†ï¼")


# ============================================================================
# ä»»åŠ¡3ï¼šé”€å”®é¢„æµ‹ç±»ï¼ˆæŒ‰ç…§ç‹¬ç«‹è„šæœ¬é€»è¾‘é‡æ„ï¼‰
# ============================================================================
class Task3Forecaster:
    def __init__(self, df, column_types):
        self.df = df.copy()
        self.column_types = column_types
        self.results = {}

    def prepare_time_series_data(self):
        """å‡†å¤‡æ—¶é—´åºåˆ—æ•°æ®ï¼ˆåŸºäºç‹¬ç«‹è„šæœ¬é€»è¾‘ï¼‰"""
        try:
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_cols = ["æ—¥æœŸ", "åˆ©æ¶¦", "é”€å”®é¢", "å®é™…å”®ä»·", "è¿›è´§ä»·æ ¼", "å®¢æˆ·æ€§åˆ«"]
            missing_cols = [col for col in required_cols if col not in self.df.columns]
            if missing_cols:
                st.error(f"æ•°æ®ç¼ºå¤±å¿…è¦å­—æ®µï¼š{missing_cols}")
                return False

            # æ—¥æœŸæ ¼å¼è½¬æ¢ï¼ˆè½¬ä¸ºæ•´æ•°å‹ï¼‰
            self.df['æ—¥æœŸ'] = pd.to_numeric(self.df['æ—¥æœŸ'], errors='coerce')
            self.df = self.df.dropna(subset=['æ—¥æœŸ'])

            # æŒ‰æ—¥èšåˆåˆ©æ¶¦æ•°æ® - ä½¿ç”¨åˆ©æ¶¦å­—æ®µï¼ˆå¯¹åº”ç‹¬ç«‹è„šæœ¬çš„æ­£ç¡®åˆ©æ¶¦ï¼‰
            daily_profit = self.df.groupby('æ—¥æœŸ')['åˆ©æ¶¦'].sum().reset_index()
            daily_profit = daily_profit.rename(columns={'åˆ©æ¶¦': 'æ¯æ—¥æ€»åˆ©æ¶¦'})

            # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ˆæ—¥æœŸ<=24ä¸ºè®­ç»ƒé›†ï¼Œ>24ä¸ºæµ‹è¯•é›†ï¼‰
            train = daily_profit[daily_profit['æ—¥æœŸ'] <= 24]
            test = daily_profit[daily_profit['æ—¥æœŸ'] > 24]

            if len(train) == 0 or len(test) == 0:
                st.error("æ•°æ®æ—¥æœŸèŒƒå›´ä¸è¶³ï¼Œæ— æ³•åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†")
                return False

            self.results['time_series_data'] = daily_profit
            self.results['train_data'] = train
            self.results['test_data'] = test
            self.results['y_train'] = train['æ¯æ—¥æ€»åˆ©æ¶¦'].values
            self.results['y_test'] = test['æ¯æ—¥æ€»åˆ©æ¶¦'].values

            st.success(f"æ—¶é—´åºåˆ—å‡†å¤‡å®Œæˆï¼šè®­ç»ƒé›†{len(train)}å¤©ï¼Œæµ‹è¯•é›†{len(test)}å¤©")
            return True

        except Exception as e:
            st.error(f"æ—¶é—´åºåˆ—å‡†å¤‡é”™è¯¯: {str(e)}")
            return False

    def create_features(self, day_indices, residuals=None):
        """ç‰¹å¾å·¥ç¨‹å‡½æ•°ï¼ˆåŸºäºç‹¬ç«‹è„šæœ¬é€»è¾‘ï¼‰"""
        features = []

        # é¢„è®¡ç®—è®­ç»ƒé›†æ¯æ—¥ç»Ÿè®¡é‡
        train_days_data = self.df[self.df['æ—¥æœŸ'] <= 24]
        train_stats = train_days_data.groupby('æ—¥æœŸ').agg({
            'é”€å”®é¢': ['count', 'mean', 'sum'],
            'å®¢æˆ·æ€§åˆ«': lambda x: (x == 'å¥³').mean() if 'å®¢æˆ·æ€§åˆ«' in train_days_data.columns else 0.5
        })
        train_stats.columns = ['order_count', 'avg_sale', 'total_sale', 'female_ratio']

        # é¢„è®¡ç®—æ¯ä¸ªæ—¥æœŸçš„ç»Ÿè®¡é‡
        daily_stats = self.df.groupby('æ—¥æœŸ').agg({
            'é”€å”®é¢': ['count', 'mean', 'sum'],
            'å®é™…å”®ä»·': 'mean',
            'è¿›è´§ä»·æ ¼': 'mean',
            'å®¢æˆ·æ€§åˆ«': lambda x: (x == 'å¥³').mean() if 'å®¢æˆ·æ€§åˆ«' in self.df.columns else 0.5
        }).round(4)

        # å¤„ç†åˆ—å
        daily_stats.columns = ['order_count', 'avg_sale', 'total_sale',
                               'avg_selling_price', 'avg_cost_price', 'female_ratio']

        # è®¡ç®—æ¯›åˆ©ç‡
        daily_stats['gross_profit_margin'] = (
                (daily_stats['avg_selling_price'] - daily_stats['avg_cost_price']) /
                daily_stats['avg_cost_price']
        ).fillna(0).round(4)

        # è®¡ç®—å•å®¢ä»·å€¼
        daily_stats['customer_value'] = (
                daily_stats['total_sale'] / daily_stats['order_count']
        ).fillna(0).round(2)

        for day in day_indices:
            day_features = {}

            # 1. åŸºç¡€æ—¶é—´ç‰¹å¾
            day_features['day'] = day
            day_features['day_of_week'] = (day - 1) % 7  # 0=å‘¨ä¸€, 6=å‘¨æ—¥
            day_features['day_of_month'] = day
            day_features['is_weekend'] = 1 if day_features['day_of_week'] in [5, 6] else 0
            day_features['is_month_end'] = 1 if day >= 28 else 0

            # 2. ä»é¢„è®¡ç®—çš„ç»Ÿè®¡é‡ä¸­è·å–ä¸šåŠ¡ç‰¹å¾
            if day in daily_stats.index:
                stats = daily_stats.loc[day]
                day_features.update({
                    'order_count': stats['order_count'],
                    'avg_sale_amount': stats['avg_sale'],
                    'total_sale': stats['total_sale'],
                    'gross_profit_margin': stats['gross_profit_margin'],
                    'customer_value': stats['customer_value'],
                    'female_ratio': stats['female_ratio']
                })
            else:
                # ä½¿ç”¨è®­ç»ƒé›†çš„ä¸­ä½æ•°å¡«å……
                day_features.update({
                    'order_count': train_stats['order_count'].median(),
                    'avg_sale_amount': train_stats['avg_sale'].median(),
                    'total_sale': train_stats['total_sale'].median(),
                    'gross_profit_margin': 0.3,  # é»˜è®¤æ¯›åˆ©ç‡
                    'customer_value': train_stats['total_sale'].median() / max(1, train_stats['order_count'].median()),
                    'female_ratio': train_stats['female_ratio'].median()
                })

            # 3. æ»åæ®‹å·®ç‰¹å¾
            if residuals is not None:
                for lag in [1, 2, 3]:
                    lag_day = day - lag
                    lag_key = f'residual_lag_{lag}'
                    if lag_day > 0 and lag_day in residuals.index:
                        day_features[lag_key] = residuals[lag_day]
                    else:
                        day_features[lag_key] = residuals.median() if not residuals.empty else 0

            features.append(day_features)

        return pd.DataFrame(features)

    def hybrid_forecast(self):
        """ARIMA-XGBoostæ··åˆé¢„æµ‹ï¼ˆåŸºäºç‹¬ç«‹è„šæœ¬é€»è¾‘ï¼‰"""
        try:
            from statsmodels.tsa.arima.model import ARIMA
            from xgboost import XGBRegressor
            from sklearn.metrics import mean_absolute_percentage_error
            import warnings
            warnings.filterwarnings('ignore')

            # è·å–æ•°æ®
            train = self.results['train_data']
            test = self.results['test_data']
            y_train = self.results['y_train']
            y_test = self.results['y_test']

            # 1. ARIMAå»ºæ¨¡
            st.info("Step 1: ARIMAå»ºæ¨¡...")
            try:
                arima_model = ARIMA(y_train, order=(2, 1, 2))
                arima_fit = arima_model.fit()
                arima_train_pred = arima_fit.predict(start=0, end=len(y_train) - 1)
                arima_test_pred = arima_fit.forecast(steps=len(y_test))
                st.success(f"ARIMAæ¨¡å‹è®­ç»ƒæˆåŠŸ (AIC: {arima_fit.aic:.2f})")
            except Exception as e:
                st.warning(f"ARIMAæ¨¡å‹è®­ç»ƒå¤±è´¥ï¼Œä½¿ç”¨å‡å€¼é¢„æµ‹: {e}")
                arima_train_pred = np.full_like(y_train, y_train.mean())
                arima_test_pred = np.full_like(y_test, y_train.mean())
                arima_fit = None

            # 2. è®¡ç®—æ®‹å·®
            residuals_train = y_train - arima_train_pred
            residual_series = pd.Series(residuals_train, index=train['æ—¥æœŸ'])

            # 3. XGBoostå­¦ä¹ æ®‹å·®
            st.info("Step 2: XGBoostå­¦ä¹ æ®‹å·®...")

            # åˆ›å»ºç‰¹å¾
            X_train = self.create_features(train['æ—¥æœŸ'], residual_series)
            X_train = X_train.fillna(0)

            # ç‰¹å¾ç»Ÿè®¡åˆ†æ
            feature_stats = pd.DataFrame({
                'mean': X_train.mean(),
                'std': X_train.std(),
                'min': X_train.min(),
                'max': X_train.max(),
                'zeros': (X_train == 0).sum(),
                'unique': X_train.nunique()
            })

            # ç­›é€‰ä½æ–¹å·®ç‰¹å¾
            low_variance_features = feature_stats[feature_stats['std'] < 1e-5].index.tolist()
            if low_variance_features:
                st.info(f"ä½æ–¹å·®ç‰¹å¾: {low_variance_features}")
                X_train = X_train.drop(columns=low_variance_features)

            # XGBoostæ¨¡å‹è®­ç»ƒï¼ˆä½¿ç”¨ç‹¬ç«‹è„šæœ¬å‚æ•°ï¼‰
            xgb_model = XGBRegressor(
                max_depth=3,
                learning_rate=0.05,
                n_estimators=1000,
                subsample=0.8,
                colsample_bytree=0.8,
                reg_alpha=0.1,
                reg_lambda=0.1,
                random_state=42,
                eval_metric='mae'
            )
            xgb_model.fit(X_train, residuals_train)

            # æµ‹è¯•é›†ç‰¹å¾
            X_test = self.create_features(test['æ—¥æœŸ'])
            X_test = X_test.fillna(0)

            # åˆ é™¤è®­ç»ƒé›†ä¸­å·²å‰”é™¤çš„ä½æ–¹å·®ç‰¹å¾
            for col in low_variance_features:
                if col in X_test.columns:
                    X_test = X_test.drop(columns=col)

            # ç¡®ä¿ç‰¹å¾ä¸€è‡´æ€§
            for col in X_train.columns:
                if col not in X_test.columns:
                    X_test[col] = 0
            X_test = X_test[X_train.columns]

            # é¢„æµ‹æ®‹å·®
            xgb_residual_pred = xgb_model.predict(X_test)

            # 4. æœ€ç»ˆé¢„æµ‹
            final_pred = arima_test_pred + xgb_residual_pred
            mape = mean_absolute_percentage_error(y_test, final_pred) * 100

            # ä¿å­˜ç»“æœ
            self.results['arima_model'] = arima_fit
            self.results['xgb_model'] = xgb_model
            self.results['arima_test_pred'] = arima_test_pred
            self.results['xgb_residual_pred'] = xgb_residual_pred
            self.results['final_pred'] = final_pred
            self.results['mape'] = mape
            self.results['residuals_train'] = residuals_train

            # ç‰¹å¾é‡è¦æ€§
            self.results['feature_importance'] = pd.DataFrame({
                'feature': X_train.columns,
                'importance': xgb_model.feature_importances_
            }).sort_values('importance', ascending=False)

            # åˆ›å»ºè¯¦ç»†ç»“æœè¡¨
            results_df = pd.DataFrame({
                'æ—¥æœŸ': test['æ—¥æœŸ'],
                'å®é™…æ¯æ—¥æ€»åˆ©æ¶¦': y_test,
                'ARIMAé¢„æµ‹åˆ©æ¶¦': arima_test_pred,
                'XGBoostæ®‹å·®é¢„æµ‹': xgb_residual_pred,
                'æœ€ç»ˆé¢„æµ‹åˆ©æ¶¦': final_pred,
                'ç›¸å¯¹è¯¯å·®(%)': np.abs(y_test - final_pred) / y_test * 100
            })
            self.results['detailed_results'] = results_df

            st.success(f"æ··åˆé¢„æµ‹å®Œæˆï¼æµ‹è¯•é›†MAPE: {mape:.2f}%")
            return True

        except Exception as e:
            st.error(f"æ··åˆé¢„æµ‹é”™è¯¯: {str(e)}")
            return False

    def generate_visualizations(self):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆåŸºäºç‹¬ç«‹è„šæœ¬é€»è¾‘ï¼‰"""
        try:
            # è®¾ç½®ä¸­æ–‡å­—ä½“
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False

            figs = {}
            train = self.results['train_data']
            test = self.results['test_data']
            y_train = self.results['y_train']
            y_test = self.results['y_test']

            # 1. ä¸»é¢„æµ‹å¯¹æ¯”å›¾
            fig1, ax1 = plt.subplots(figsize=(12, 8))

            # è®­ç»ƒé›†å®é™…å€¼
            ax1.plot(train['æ—¥æœŸ'], y_train / 10000, 'bo-', label='è®­ç»ƒé›†å®é™…åˆ©æ¶¦',
                     alpha=0.7, markersize=6, linewidth=2)
            # æµ‹è¯•é›†å®é™…å€¼
            ax1.plot(test['æ—¥æœŸ'], y_test / 10000, 'ro-', label='æµ‹è¯•é›†å®é™…åˆ©æ¶¦',
                     alpha=0.7, markersize=8, linewidth=2)

            # ARIMAè®­ç»ƒé›†æ‹Ÿåˆå€¼
            if self.results['arima_model'] is not None:
                arima_train_fit = self.results['arima_model'].predict(start=1, end=24)
                ax1.plot(train['æ—¥æœŸ'], arima_train_fit / 10000, 'c--', label='ARIMAè®­ç»ƒé›†æ‹Ÿåˆ',
                         alpha=0.8, linewidth=2)

            # ARIMAæµ‹è¯•é›†é¢„æµ‹å€¼
            ax1.plot(test['æ—¥æœŸ'], self.results['arima_test_pred'] / 10000, 'm--',
                     label='ARIMAæµ‹è¯•é›†é¢„æµ‹', alpha=0.8, linewidth=2)
            # æœ€ç»ˆç»„åˆé¢„æµ‹å€¼
            ax1.plot(test['æ—¥æœŸ'], self.results['final_pred'] / 10000, 'gs-',
                     label='ARIMA+XGBoostæœ€ç»ˆé¢„æµ‹', markersize=8, linewidth=2)

            ax1.set_xlabel('æ—¥æœŸ (11æœˆå¤©æ•°)', fontsize=12)
            ax1.set_ylabel('åˆ©æ¶¦ (ä¸‡å…ƒ)', fontsize=12)
            ax1.set_title('ç”µå•†å¹³å°æ¯æ—¥æ€»åˆ©æ¶¦é¢„æµ‹å¯¹æ¯”', fontsize=14, fontweight='bold')
            ax1.legend(fontsize=11)
            ax1.grid(True, alpha=0.3)
            ax1.axvline(x=24.5, color='gray', linestyle=':', alpha=0.7, linewidth=2)
            ax1.text(24.7, ax1.get_ylim()[1] * 0.9, 'æµ‹è¯•é›†å¼€å§‹', rotation=90, va='top', fontsize=10)
            figs['main_forecast'] = fig1

            # 2. è¯¯å·®åˆ†æå›¾
            fig2, ax2 = plt.subplots(figsize=(10, 6))
            relative_errors = self.results['detailed_results']['ç›¸å¯¹è¯¯å·®(%)']
            bars = ax2.bar(test['æ—¥æœŸ'], relative_errors, alpha=0.7, color='orange',
                           edgecolor='darkorange', linewidth=1)

            ax2.set_xlabel('æ—¥æœŸ (11æœˆå¤©æ•°)', fontsize=12)
            ax2.set_ylabel('ç›¸å¯¹è¯¯å·® (%)', fontsize=12)
            ax2.set_title(f'ç”µå•†å¹³å°åˆ©æ¶¦é¢„æµ‹è¯¯å·®åˆ†æ (MAPE = {self.results["mape"]:.2f}%)',
                          fontsize=14, fontweight='bold')
            ax2.grid(True, alpha=0.3, axis='y')

            # æ·»åŠ è¯¯å·®æ•°å€¼æ ‡ç­¾
            for date, error in zip(test['æ—¥æœŸ'], relative_errors):
                ax2.text(date, error + 1, f'{error:.1f}%', ha='center', va='bottom',
                         fontsize=10, fontweight='bold')
            figs['error_analysis'] = fig2

            # 3. æ®‹å·®åˆ†æå›¾
            fig3, ax3 = plt.subplots(figsize=(12, 6))
            residuals_train = self.results['residuals_train']

            ax3.plot(range(1, 25), residuals_train / 10000, 'o-', color='purple',
                     alpha=0.7, markersize=6, linewidth=2, label='æ¯æ—¥æ®‹å·®')
            ax3.axhline(y=0, color='red', linestyle='--', linewidth=2, alpha=0.7, label='é›¶åŸºå‡†çº¿')

            mean_residual = residuals_train.mean() / 10000
            ax3.axhline(y=mean_residual, color='blue', linestyle=':', linewidth=2, alpha=0.7,
                        label=f'æ®‹å·®å‡å€¼: {mean_residual:.2f}ä¸‡å…ƒ')

            ax3.set_xlabel('è®­ç»ƒé›†æ—¥æœŸ (11æœˆå¤©æ•°)', fontsize=12)
            ax3.set_ylabel('æ®‹å·® (ä¸‡å…ƒ)', fontsize=12)
            ax3.set_title('ARIMAæ¨¡å‹æ®‹å·®åˆ†å¸ƒ', fontsize=14, fontweight='bold')
            ax3.legend(fontsize=11)
            ax3.grid(True, alpha=0.3)

            # ç»Ÿè®¡ä¿¡æ¯æ¡†
            stats_text = (f'å‡å€¼: {residuals_train.mean() / 10000:.2f}ä¸‡å…ƒ\n'
                          f'æ ‡å‡†å·®: {residuals_train.std() / 10000:.2f}ä¸‡å…ƒ\n'
                          f'æœ€å¤§å€¼: {residuals_train.max() / 10000:.2f}ä¸‡å…ƒ\n'
                          f'æœ€å°å€¼: {residuals_train.min() / 10000:.2f}ä¸‡å…ƒ')
            ax3.text(0.02, 0.98, stats_text, transform=ax3.transAxes, fontsize=11,
                     verticalalignment='top', bbox=dict(boxstyle="round,pad=0.3",
                                                        facecolor="lightgray", alpha=0.7))
            figs['residual_analysis'] = fig3

            # 4. ç‰¹å¾é‡è¦æ€§å›¾
            fig4, ax4 = plt.subplots(figsize=(12, 8))
            feature_importance = self.results['feature_importance'].head(10)

            # ç‰¹å¾åç§°æ˜ å°„
            feature_names_map = {
                'day': 'æ—¥æœŸ', 'day_of_week': 'æ˜ŸæœŸ', 'day_of_month': 'æœˆå†…å¤©æ•°',
                'is_weekend': 'æ˜¯å¦å‘¨æœ«', 'is_month_end': 'æ˜¯å¦æœˆæœ«',
                'order_count': 'è®¢å•æ•°', 'avg_sale_amount': 'å¹³å‡é”€å”®é¢',
                'total_sale': 'æ€»é”€å”®é¢', 'gross_profit_margin': 'æ¯›åˆ©ç‡',
                'customer_value': 'å•å®¢ä»·å€¼', 'female_ratio': 'å¥³æ€§å®¢æˆ·å æ¯”',
                'residual_lag_1': 'æ®‹å·®æ»å1å¤©', 'residual_lag_2': 'æ®‹å·®æ»å2å¤©',
                'residual_lag_3': 'æ®‹å·®æ»å3å¤©'
            }

            feature_importance['feature_cn'] = feature_importance['feature'].map(
                lambda x: feature_names_map.get(x, x)
            )
            feature_importance = feature_importance.sort_values('importance', ascending=True)

            y_pos = np.arange(len(feature_importance))
            colors = plt.cm.viridis(np.linspace(0, 1, len(feature_importance)))

            ax4.barh(y_pos, feature_importance['importance'], color=colors,
                     alpha=0.8, edgecolor='black')
            ax4.set_yticks(y_pos)
            ax4.set_yticklabels(feature_importance['feature_cn'], fontsize=11)
            ax4.set_xlabel('ç‰¹å¾é‡è¦æ€§å¾—åˆ†', fontsize=12, fontweight='bold')
            ax4.set_title('XGBoostæ®‹å·®é¢„æµ‹ç‰¹å¾é‡è¦æ€§', fontsize=14, fontweight='bold')
            ax4.grid(True, alpha=0.3, axis='x')

            # æ·»åŠ é‡è¦æ€§æ•°å€¼æ ‡ç­¾
            for i, v in enumerate(feature_importance['importance']):
                ax4.text(v + 0.005, i, f'{v:.3f}', va='center', fontsize=10, fontweight='bold')

            figs['feature_importance'] = fig4

            self.results['visualizations'] = figs
            return True

        except Exception as e:
            st.error(f"å¯è§†åŒ–ç”Ÿæˆé”™è¯¯: {str(e)}")
            import traceback
            st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return False

    def generate_all_results(self, forecast_days=14):
        """ç”Ÿæˆæ‰€æœ‰é¢„æµ‹ç»“æœ"""
        try:
            if not self.prepare_time_series_data():
                return None, ["æ—¶é—´åºåˆ—æ•°æ®å‡†å¤‡å¤±è´¥"]

            if not self.hybrid_forecast():
                return None, ["æ··åˆé¢„æµ‹æ¨¡å‹æ‰§è¡Œå¤±è´¥"]

            if not self.generate_visualizations():
                return None, ["å¯è§†åŒ–ç”Ÿæˆå¤±è´¥"]

            # æ•´ç†ç»“æœæ–‡ä»¶
            result_files = {
                '01_æ—¶é—´åºåˆ—å†å²æ•°æ®.xlsx': self.results['time_series_data'],
                '02_é”€å”®é¢„æµ‹ç»“æœ.xlsx': self.results['detailed_results'],
                '03_ç‰¹å¾é‡è¦æ€§åˆ†æ.xlsx': self.results['feature_importance']
            }

            # è¿›åº¦æ—¥å¿—
            progress_log = [
                f"æ—¶é—´åºåˆ—å‡†å¤‡å®Œæˆï¼šè®­ç»ƒé›†{len(self.results['train_data'])}å¤©ï¼Œæµ‹è¯•é›†{len(self.results['test_data'])}å¤©",
                f"ARIMA-XGBoostæ··åˆé¢„æµ‹å®Œæˆï¼šæµ‹è¯•é›†MAPE {self.results['mape']:.2f}%",
                f"ç‰¹å¾é‡è¦æ€§åˆ†æå®Œæˆï¼š{len(self.results['feature_importance'])}ä¸ªç‰¹å¾",
                f"å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆï¼š4ä¸ªåˆ†æå›¾è¡¨"
            ]

            return result_files, progress_log

        except Exception as e:
            return None, [f"é¢„æµ‹é”™è¯¯: {str(e)}"]


# ============================================================================
# ä»»åŠ¡4ï¼šè¿è¥ç­–ç•¥ä¼˜åŒ–ç±»
# ============================================================================
class Task4Optimizer:
    def __init__(self, df, column_types):
        self.df = df.copy()
        self.column_types = column_types
        self.results = {}

    def abc_classification_analysis(self):
        """ABCåˆ†ç±»åˆ†æï¼ˆåŸºäºå¸•ç´¯æ‰˜æ³•åˆ™ï¼‰"""
        try:
            # æŒ‰å•†å“å“ç±»èšåˆé”€å”®é¢å’Œåˆ©æ¶¦
            category_stats = self.df.groupby('å•†å“å“ç±»').agg({
                'é”€å”®é¢': 'sum',
                'åˆ©æ¶¦': 'sum',
                'é”€å”®æ•°': 'sum'
            }).reset_index()

            # è®¡ç®—ç´¯è®¡å æ¯”
            category_stats = category_stats.sort_values('é”€å”®é¢', ascending=False)
            category_stats['é”€å”®é¢ç´¯è®¡å æ¯”%'] = (
                        category_stats['é”€å”®é¢'].cumsum() / category_stats['é”€å”®é¢'].sum() * 100).round(2)
            category_stats['åˆ©æ¶¦ç´¯è®¡å æ¯”%'] = (
                        category_stats['åˆ©æ¶¦'].cumsum() / category_stats['åˆ©æ¶¦'].sum() * 100).round(2)
            category_stats['é”€å”®é¢å æ¯”%'] = (category_stats['é”€å”®é¢'] / category_stats['é”€å”®é¢'].sum() * 100).round(2)
            category_stats['åˆ©æ¶¦å æ¯”%'] = (category_stats['åˆ©æ¶¦'] / category_stats['åˆ©æ¶¦'].sum() * 100).round(2)

            # ABCåˆ†ç±»ï¼ˆåŸºäºé”€å”®é¢ï¼‰
            def assign_abc_class(cumulative_percent):
                if cumulative_percent <= 70:
                    return 'Aç±»'
                elif cumulative_percent <= 90:
                    return 'Bç±»'
                else:
                    return 'Cç±»'

            category_stats['ABCåˆ†ç±»ï¼ˆé”€å”®é¢ï¼‰'] = category_stats['é”€å”®é¢ç´¯è®¡å æ¯”%'].apply(assign_abc_class)

            # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
            self._create_abc_visualizations(category_stats)

            self.results['abc_classification'] = category_stats
            return True

        except Exception as e:
            st.error(f"ABCåˆ†ç±»åˆ†æé”™è¯¯: {str(e)}")
            return False

    def _create_abc_visualizations(self, category_stats):
        """åˆ›å»ºABCåˆ†ç±»å¯è§†åŒ–å›¾è¡¨"""
        try:
            figs = {}

            # 1. é”€å”®é¢åˆ†å¸ƒå›¾
            plt.figure(figsize=(12, 6))
            top_categories = category_stats.head(10)
            plt.bar(range(len(top_categories)), top_categories['é”€å”®é¢'], color='skyblue', alpha=0.8)
            plt.xlabel('å•†å“å“ç±»')
            plt.ylabel('é”€å”®é¢')
            plt.title('Top 10å•†å“å“ç±»é”€å”®é¢åˆ†å¸ƒ')
            plt.xticks(range(len(top_categories)), top_categories['å•†å“å“ç±»'], rotation=45, ha='right')
            plt.grid(axis='y', alpha=0.3)
            plt.tight_layout()
            figs['sales_distribution'] = plt.gcf()
            plt.close()

            # 2. ç´¯è®¡é”€å”®é¢å¸•ç´¯æ‰˜å›¾
            plt.figure(figsize=(12, 6))
            fig, ax1 = plt.subplots(figsize=(12, 6))

            # æŸ±çŠ¶å›¾ï¼ˆé”€å”®é¢ï¼‰
            bars = ax1.bar(range(len(category_stats)), category_stats['é”€å”®é¢'],
                           color='lightblue', alpha=0.7, label='é”€å”®é¢')
            ax1.set_xlabel('å•†å“å“ç±»')
            ax1.set_ylabel('é”€å”®é¢', color='blue')
            ax1.tick_params(axis='y', labelcolor='blue')

            # æŠ˜çº¿å›¾ï¼ˆç´¯è®¡å æ¯”ï¼‰
            ax2 = ax1.twinx()
            line = ax2.plot(range(len(category_stats)), category_stats['é”€å”®é¢ç´¯è®¡å æ¯”%'],
                            color='red', marker='o', linewidth=2, label='ç´¯è®¡å æ¯”')
            ax2.set_ylabel('ç´¯è®¡å æ¯” (%)', color='red')
            ax2.tick_params(axis='y', labelcolor='red')
            ax2.axhline(y=70, color='green', linestyle='--', alpha=0.7, label='Aç±»åˆ†ç•Œçº¿ (70%)')
            ax2.axhline(y=90, color='orange', linestyle='--', alpha=0.7, label='Bç±»åˆ†ç•Œçº¿ (90%)')

            plt.title('ABCåˆ†ç±»å¸•ç´¯æ‰˜åˆ†æ')
            fig.legend(loc='upper right')
            plt.tight_layout()
            figs['cumulative_sales'] = fig
            plt.close()

            # 3. ABCåˆ†ç±»åˆ†å¸ƒå›¾
            abc_counts = category_stats['ABCåˆ†ç±»ï¼ˆé”€å”®é¢ï¼‰'].value_counts()
            plt.figure(figsize=(8, 6))
            colors = {'Aç±»': 'red', 'Bç±»': 'orange', 'Cç±»': 'green'}
            abc_colors = [colors.get(cls, 'gray') for cls in abc_counts.index]
            plt.pie(abc_counts.values, labels=abc_counts.index, autopct='%1.1f%%',
                    colors=abc_colors, startangle=90)
            plt.title('ABCåˆ†ç±»åˆ†å¸ƒ')
            figs['abc_distribution'] = plt.gcf()
            plt.close()

            self.results['abc_visualizations'] = figs
            return True

        except Exception as e:
            st.error(f"ABCå¯è§†åŒ–ç”Ÿæˆé”™è¯¯: {str(e)}")
            return False

    def price_sensitivity_analysis(self):
        """ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ"""
        try:
            # æŒ‰å•†å“å“ç±»åˆ†æä»·æ ¼-é”€é‡å…³ç³»
            sensitivity_results = []

            for category in self.df['å•†å“å“ç±»'].unique():
                category_data = self.df[self.df['å•†å“å“ç±»'] == category]

                if len(category_data) < 10:  # æ•°æ®é‡å¤ªå°‘è·³è¿‡
                    continue

                # ä»·æ ¼åˆ†ç®±ï¼ˆç­‰é¢‘8åŒºé—´ï¼‰
                try:
                    category_data = category_data.copy()
                    category_data['ä»·æ ¼åŒºé—´'] = pd.qcut(category_data['å®é™…å”®ä»·'], q=8, duplicates='drop')

                    # è®¡ç®—æ¯ä¸ªä»·æ ¼åŒºé—´çš„å¹³å‡é”€é‡
                    price_bin_stats = category_data.groupby('ä»·æ ¼åŒºé—´').agg({
                        'å®é™…å”®ä»·': 'mean',
                        'é”€å”®æ•°': 'mean',
                        'åˆ©æ¶¦': 'mean'
                    }).reset_index()

                    if len(price_bin_stats) < 3:  # åŒºé—´å¤ªå°‘æ— æ³•åˆ†æ
                        continue

                    # çº¿æ€§å›å½’åˆ†æä»·æ ¼-é”€é‡å…³ç³»
                    X = price_bin_stats['å®é™…å”®ä»·'].values.reshape(-1, 1)
                    y = price_bin_stats['é”€å”®æ•°'].values

                    from sklearn.linear_model import LinearRegression
                    from sklearn.metrics import r2_score

                    model = LinearRegression()
                    model.fit(X, y)
                    y_pred = model.predict(X)
                    r2 = r2_score(y, y_pred)
                    slope = model.coef_[0]

                    # è®¡ç®—ä»·æ ¼å¼¹æ€§ç³»æ•°ï¼ˆå–ç»å¯¹å€¼ï¼‰
                    price_elasticity = abs(slope * (X.mean() / y.mean()))[0]

                    # åˆ¤æ–­æ•æ„Ÿåº¦ç­‰çº§
                    if price_elasticity > 1.5:
                        sensitivity_level = 'é«˜æ•æ„Ÿ'
                    elif price_elasticity > 0.8:
                        sensitivity_level = 'ä¸­æ•æ„Ÿ'
                    else:
                        sensitivity_level = 'ä½æ•æ„Ÿ'

                    sensitivity_results.append({
                        'å•†å“å“ç±»': category,
                        'ä»·æ ¼å¼¹æ€§ç³»æ•°': round(price_elasticity, 4),
                        'RÂ²å†³å®šç³»æ•°': round(r2, 4),
                        'æ•æ„Ÿåº¦ç­‰çº§': sensitivity_level,
                        'æ•°æ®ç‚¹æ•°': len(price_bin_stats),
                        'å¹³å‡ä»·æ ¼': round(price_bin_stats['å®é™…å”®ä»·'].mean(), 2),
                        'å¹³å‡é”€é‡': round(price_bin_stats['é”€å”®æ•°'].mean(), 2)
                    })

                    # ä¸ºå‰å‡ ä¸ªå“ç±»ç”Ÿæˆæ‹Ÿåˆå›¾è¡¨
                    if len(self.results.get('fitting_charts', {})) < 4:
                        self._create_price_fitting_chart(category, price_bin_stats, model, price_elasticity)

                except Exception as e:
                    continue  # å•ä¸ªå“ç±»åˆ†æå¤±è´¥æ—¶ç»§ç»­ä¸‹ä¸€ä¸ª

            sensitivity_df = pd.DataFrame(sensitivity_results)
            self.results['price_sensitivity'] = sensitivity_df.sort_values('ä»·æ ¼å¼¹æ€§ç³»æ•°', ascending=False)
            return True

        except Exception as e:
            st.error(f"ä»·æ ¼æ•æ„Ÿåº¦åˆ†æé”™è¯¯: {str(e)}")
            return False

    def _create_price_fitting_chart(self, category, price_bin_stats, model, elasticity):
        """åˆ›å»ºä»·æ ¼-é”€é‡æ‹Ÿåˆå›¾è¡¨"""
        try:
            if 'fitting_charts' not in self.results:
                self.results['fitting_charts'] = {}

            plt.figure(figsize=(10, 6))

            # æ•£ç‚¹å›¾
            plt.scatter(price_bin_stats['å®é™…å”®ä»·'], price_bin_stats['é”€å”®æ•°'],
                        color='blue', alpha=0.7, s=60, label='å®é™…æ•°æ®')

            # æ‹Ÿåˆçº¿
            X_range = np.linspace(price_bin_stats['å®é™…å”®ä»·'].min(),
                                  price_bin_stats['å®é™…å”®ä»·'].max(), 100).reshape(-1, 1)
            y_range = model.predict(X_range)
            plt.plot(X_range, y_range, color='red', linewidth=2, label='çº¿æ€§æ‹Ÿåˆ')

            plt.xlabel('å®é™…å”®ä»·')
            plt.ylabel('å¹³å‡é”€é‡')
            plt.title(f'{category}\nä»·æ ¼-é”€é‡å…³ç³» (å¼¹æ€§ç³»æ•°: {elasticity:.3f})')
            plt.legend()
            plt.grid(True, alpha=0.3)
            plt.tight_layout()

            self.results['fitting_charts'][f'price_fit_{category}'] = plt.gcf()
            plt.close()

            return True

        except Exception as e:
            return False

    def user_segmentation_analysis(self):
        """ç”¨æˆ·åˆ†å±‚åˆ†æ"""
        try:
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_cols = ['å®¢æˆ·å¹´é¾„', 'å®¢æˆ·æ€§åˆ«', 'å®é™…å”®ä»·']
            missing_cols = [col for col in required_cols if col not in self.df.columns]
            if missing_cols:
                st.warning(f"ç”¨æˆ·åˆ†å±‚åˆ†æç¼ºå°‘å­—æ®µ: {missing_cols}")
                return False

            # å¹´é¾„åˆ†æ®µ
            def assign_age_group(age):
                try:
                    age = float(age)
                    if age < 25:
                        return '20-24å²'
                    elif age < 30:
                        return '25-29å²'
                    elif age < 35:
                        return '30-34å²'
                    elif age < 40:
                        return '35-39å²'
                    elif age < 45:
                        return '40-44å²'
                    elif age < 50:
                        return '45-49å²'
                    elif age < 55:
                        return '50-54å²'
                    elif age < 60:
                        return '55-59å²'
                    else:
                        return '60å²ä»¥ä¸Š'
                except:
                    return 'æœªçŸ¥'

            self.df['å¹´é¾„æ®µ'] = self.df['å®¢æˆ·å¹´é¾„'].apply(assign_age_group)

            # ç”¨æˆ·åˆ†å±‚åˆ†æ
            user_segments = []

            for age_group in self.df['å¹´é¾„æ®µ'].unique():
                for gender in self.df['å®¢æˆ·æ€§åˆ«'].unique():
                    segment_data = self.df[
                        (self.df['å¹´é¾„æ®µ'] == age_group) &
                        (self.df['å®¢æˆ·æ€§åˆ«'] == gender)
                        ]

                    if len(segment_data) > 0:
                        # è®¡ç®—ä»·æ ¼æ¥å—åº¦ (R1) - å¹³å‡è´­ä¹°ä»·æ ¼ä¸æ€»ä½“å¹³å‡ä»·æ ¼çš„æ¯”å€¼
                        avg_price_segment = segment_data['å®é™…å”®ä»·'].mean()
                        avg_price_total = self.df['å®é™…å”®ä»·'].mean()
                        price_acceptance = avg_price_segment / avg_price_total if avg_price_total > 0 else 1

                        # è®¡ç®—é›†ä¸­åº¦ (R2) - è¯¥åˆ†ç¾¤åœ¨æ€»é”€å”®é¢ä¸­çš„å æ¯”
                        sales_share = segment_data['é”€å”®é¢'].sum() / self.df['é”€å”®é¢'].sum() if self.df[
                                                                                                    'é”€å”®é¢'].sum() > 0 else 0

                        # è®¡ç®—æ•æ„Ÿå€¾å‘æŒ‡æ•° (R3) - åŸºäºä»·æ ¼å˜åŒ–çš„è¡Œä¸º
                        # ç®€åŒ–è®¡ç®—ï¼šä½¿ç”¨ä»·æ ¼æ–¹å·®ä½œä¸ºæ•æ„Ÿåº¦æŒ‡æ ‡
                        price_variance = segment_data['å®é™…å”®ä»·'].var()
                        total_variance = self.df['å®é™…å”®ä»·'].var()
                        sensitivity_index = price_variance / total_variance if total_variance > 0 else 1

                        user_segments.append({
                            'å¹´é¾„æ®µ': age_group,
                            'å®¢æˆ·æ€§åˆ«': gender,
                            'ç”¨æˆ·æ•°é‡': len(segment_data),
                            'å¹³å‡è´­ä¹°ä»·æ ¼': round(avg_price_segment, 2),
                            'ä»·æ ¼æ¥å—åº¦(R1)': round(price_acceptance, 3),
                            'é”€å”®é¢å æ¯”(R2)': round(sales_share, 3),
                            'æ•æ„Ÿå€¾å‘æŒ‡æ•°(R3)': round(sensitivity_index, 3),
                            'æ€»é”€å”®é¢': round(segment_data['é”€å”®é¢'].sum(), 2)
                        })

            user_segments_df = pd.DataFrame(user_segments)
            self.results['user_segmentation'] = user_segments_df.sort_values('é”€å”®é¢å æ¯”(R2)', ascending=False)
            return True

        except Exception as e:
            st.error(f"ç”¨æˆ·åˆ†å±‚åˆ†æé”™è¯¯: {str(e)}")
            return False

    def scenario_price_analysis(self):
        """åœºæ™¯ä»·æ ¼åˆ†æ"""
        try:
            # å®šä¹‰å•†å“å“ç±»åˆ°æ¶ˆè´¹åœºæ™¯çš„æ˜ å°„
            scenario_mapping = {
                'åŠå…¬': ['åŠå…¬ç”¨å“', 'æ–‡å…·', 'æ‰“å°æœº', 'ç”µè„‘é…ä»¶'],
                'å®¶å±…': ['å®¶å…·', 'å®¶å±…è£…é¥°', 'åºŠä¸Šç”¨å“', 'å¨æˆ¿ç”¨å“'],
                'æ•°ç ': ['æ‰‹æœº', 'å¹³æ¿', 'ç›¸æœº', 'è€³æœº'],
                'æœé¥°': ['æœè£…', 'é‹ç±»', 'é…é¥°', 'ç®±åŒ…'],
                'ç¾å¦†': ['åŒ–å¦†å“', 'æŠ¤è‚¤å“', 'é¦™æ°´', 'ä¸ªæŠ¤'],
                'é£Ÿå“': ['é›¶é£Ÿ', 'é¥®æ–™', 'ç”Ÿé²œ', 'ç²®æ²¹']
            }

            # ä¸ºæ¯ä¸ªå•†å“å“ç±»åˆ†é…åœºæ™¯
            def assign_scenario(category):
                category_str = str(category)
                for scenario, keywords in scenario_mapping.items():
                    if any(keyword in category_str for keyword in keywords):
                        return scenario
                return 'å…¶ä»–'

            self.df['æ¶ˆè´¹åœºæ™¯'] = self.df['å•†å“å“ç±»'].apply(assign_scenario)

            # åœºæ™¯ä»·æ ¼åˆ†æ
            scenario_analysis = []

            for scenario in self.df['æ¶ˆè´¹åœºæ™¯'].unique():
                scenario_data = self.df[self.df['æ¶ˆè´¹åœºæ™¯'] == scenario]

                if len(scenario_data) > 0:
                    # ä»·æ ¼å¸¦åˆ†æ
                    price_stats = scenario_data['å®é™…å”®ä»·'].describe()

                    # è®¡ç®—åœºæ™¯ä»·æ ¼æ•æ„Ÿåº¦æŒ‡æ•° (SI)
                    # ä½¿ç”¨ä»·æ ¼å˜å¼‚ç³»æ•°ä½œä¸ºæ•æ„Ÿåº¦æŒ‡æ ‡
                    price_cv = scenario_data['å®é™…å”®ä»·'].std() / scenario_data['å®é™…å”®ä»·'].mean() if scenario_data[
                                                                                                         'å®é™…å”®ä»·'].mean() > 0 else 0

                    scenario_analysis.append({
                        'æ¶ˆè´¹åœºæ™¯': scenario,
                        'å•†å“æ•°é‡': len(scenario_data['å•†å“å“ç±»'].unique()),
                        'æ€»é”€å”®é¢': round(scenario_data['é”€å”®é¢'].sum(), 2),
                        'å¹³å‡ä»·æ ¼': round(scenario_data['å®é™…å”®ä»·'].mean(), 2),
                        'æœ€ä½ä»·æ ¼': round(price_stats['min'], 2),
                        'æœ€é«˜ä»·æ ¼': round(price_stats['max'], 2),
                        'ä»·æ ¼æ ‡å‡†å·®': round(scenario_data['å®é™…å”®ä»·'].std(), 2),
                        'ä»·æ ¼æ•æ„Ÿåº¦æŒ‡æ•°(SI)': round(price_cv, 4),
                        'æ•æ„Ÿåº¦ç­‰çº§': 'é«˜æ•æ„Ÿ' if price_cv > 0.5 else 'ä¸­æ•æ„Ÿ' if price_cv > 0.2 else 'ä½æ•æ„Ÿ'
                    })

            scenario_df = pd.DataFrame(scenario_analysis)
            self.results['scenario_analysis'] = scenario_df.sort_values('æ€»é”€å”®é¢', ascending=False)
            return True

        except Exception as e:
            st.error(f"åœºæ™¯ä»·æ ¼åˆ†æé”™è¯¯: {str(e)}")
            return False

    def comprehensive_model_fusion(self):
        """ç»¼åˆæ¨¡å‹èåˆï¼ˆAHPå±‚æ¬¡åˆ†ææ³•ï¼‰"""
        try:
            # è·å–å„ç»´åº¦çš„åˆ†æç»“æœ
            abc_data = self.results.get('abc_classification', pd.DataFrame())
            price_data = self.results.get('price_sensitivity', pd.DataFrame())
            user_data = self.results.get('user_segmentation', pd.DataFrame())
            scenario_data = self.results.get('scenario_analysis', pd.DataFrame())

            if abc_data.empty or price_data.empty:
                st.warning("ç»¼åˆæ¨¡å‹èåˆéœ€è¦ABCåˆ†ç±»å’Œä»·æ ¼æ•æ„Ÿåº¦åˆ†æç»“æœ")
                return False

            # æ„å»ºç»¼åˆè¯„ä¼°çŸ©é˜µ
            comprehensive_results = []

            for _, abc_row in abc_data.iterrows():
                category = abc_row['å•†å“å“ç±»']

                # æŸ¥æ‰¾å¯¹åº”çš„ä»·æ ¼æ•æ„Ÿåº¦æ•°æ®
                price_row = price_data[price_data['å•†å“å“ç±»'] == category]
                if price_row.empty:
                    continue

                # AHPæƒé‡åˆ†é…ï¼ˆåŸºäºè®ºæ–‡é€»è¾‘ï¼‰
                weights = {
                    'å“ç±»é‡è¦æ€§': 0.66,  # ABCåˆ†ç±»æƒé‡
                    'ä»·æ ¼æ•æ„Ÿåº¦': 0.23,  # ä»·æ ¼æ•æ„Ÿåº¦æƒé‡
                    'ç”¨æˆ·åå¥½': 0.07,  # ç”¨æˆ·åˆ†å±‚æƒé‡
                    'åœºæ™¯é€‚é…': 0.04  # åœºæ™¯åˆ†ææƒé‡
                }

                # å“ç±»é‡è¦æ€§å¾—åˆ†ï¼ˆAç±»=1.0, Bç±»=0.7, Cç±»=0.3ï¼‰
                abc_score_map = {'Aç±»': 1.0, 'Bç±»': 0.7, 'Cç±»': 0.3}
                abc_score = abc_score_map.get(abc_row['ABCåˆ†ç±»ï¼ˆé”€å”®é¢ï¼‰'], 0.3)

                # ä»·æ ¼æ•æ„Ÿåº¦å¾—åˆ†ï¼ˆè½¬æ¢ä¸º0-1çš„æ ‡å‡†åŒ–å¾—åˆ†ï¼‰
                price_elasticity = price_row.iloc[0]['ä»·æ ¼å¼¹æ€§ç³»æ•°']
                price_score = min(price_elasticity / 2.0, 1.0)  # å‡è®¾æœ€å¤§å¼¹æ€§ä¸º2.0

                # ç”¨æˆ·åå¥½å¾—åˆ†ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
                user_score = 0.5  # é»˜è®¤å€¼ï¼Œå®é™…åº”æ ¹æ®ç”¨æˆ·åˆ†å±‚æ•°æ®è®¡ç®—

                # åœºæ™¯é€‚é…å¾—åˆ†ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
                scenario_score = 0.5  # é»˜è®¤å€¼ï¼Œå®é™…åº”æ ¹æ®åœºæ™¯åˆ†ææ•°æ®è®¡ç®—

                # ç»¼åˆå¾—åˆ†è®¡ç®—
                comprehensive_score = (
                        abc_score * weights['å“ç±»é‡è¦æ€§'] +
                        price_score * weights['ä»·æ ¼æ•æ„Ÿåº¦'] +
                        user_score * weights['ç”¨æˆ·åå¥½'] +
                        scenario_score * weights['åœºæ™¯é€‚é…']
                )

                # æ•æ„Ÿåº¦ç­‰çº§åˆ¤å®š
                if comprehensive_score >= 0.7:
                    sensitivity_level = 'é«˜æ•æ„Ÿ'
                    operation_priority = 'é«˜'
                elif comprehensive_score >= 0.4:
                    sensitivity_level = 'ä¸­æ•æ„Ÿ'
                    operation_priority = 'ä¸­'
                else:
                    sensitivity_level = 'ä½æ•æ„Ÿ'
                    operation_priority = 'ä½'

                comprehensive_results.append({
                    'å•†å“å“ç±»': category,
                    'ABCåˆ†ç±»': abc_row['ABCåˆ†ç±»ï¼ˆé”€å”®é¢ï¼‰'],
                    'ä»·æ ¼å¼¹æ€§ç³»æ•°': price_elasticity,
                    'å“ç±»é‡è¦æ€§å¾—åˆ†': round(abc_score, 3),
                    'ä»·æ ¼æ•æ„Ÿåº¦å¾—åˆ†': round(price_score, 3),
                    'ç”¨æˆ·åå¥½å¾—åˆ†': round(user_score, 3),
                    'åœºæ™¯é€‚é…å¾—åˆ†': round(scenario_score, 3),
                    'ç»¼åˆæ•æ„Ÿåº¦å¾—åˆ†': round(comprehensive_score, 3),
                    'æ•æ„Ÿåº¦ç­‰çº§': sensitivity_level,
                    'è¿è¥ä¼˜å…ˆçº§': operation_priority
                })

            comprehensive_df = pd.DataFrame(comprehensive_results)
            self.results['comprehensive_fusion'] = comprehensive_df.sort_values('ç»¼åˆæ•æ„Ÿåº¦å¾—åˆ†', ascending=False)

            # ç”Ÿæˆè¿è¥ç­–ç•¥æ¨è
            self._generate_operation_strategies(comprehensive_df)

            return True

        except Exception as e:
            st.error(f"ç»¼åˆæ¨¡å‹èåˆé”™è¯¯: {str(e)}")
            return False

    def _generate_operation_strategies(self, comprehensive_df):
        """ç”Ÿæˆè¿è¥ç­–ç•¥æ¨è"""
        try:
            strategies = []

            for _, row in comprehensive_df.iterrows():
                category = row['å•†å“å“ç±»']
                abc_class = row['ABCåˆ†ç±»']
                sensitivity_level = row['æ•æ„Ÿåº¦ç­‰çº§']
                comprehensive_score = row['ç»¼åˆæ•æ„Ÿåº¦å¾—åˆ†']

                # æ ¹æ®ABCåˆ†ç±»å’Œæ•æ„Ÿåº¦ç­‰çº§ç”Ÿæˆç­–ç•¥
                if abc_class == 'Aç±»' and sensitivity_level == 'é«˜æ•æ„Ÿ':
                    strategies.append({
                        'å•†å“å“ç±»': category,
                        'ç­–ç•¥ç±»å‹': 'ä»·æ ¼ä¼˜åŒ–',
                        'å…·ä½“æªæ–½': 'å®æ–½åŠ¨æ€å®šä»·ï¼Œå…³æ³¨ç«å“ä»·æ ¼ï¼Œè®¾ç½®ä»·æ ¼é¢„è­¦æœºåˆ¶',
                        'é¢„æœŸæ•ˆæœ': 'æå‡ä»·æ ¼ç«äº‰åŠ›ï¼Œä¿æŒå¸‚åœºä»½é¢',
                        'ä¼˜å…ˆçº§': 'é«˜'
                    })
                    strategies.append({
                        'å•†å“å“ç±»': category,
                        'ç­–ç•¥ç±»å‹': 'åº“å­˜ä¼˜åŒ–',
                        'å…·ä½“æªæ–½': 'å¢åŠ å®‰å…¨åº“å­˜ï¼Œä¼˜åŒ–è¡¥è´§é¢‘ç‡ï¼Œé¿å…ç¼ºè´§æŸå¤±',
                        'é¢„æœŸæ•ˆæœ': 'æé«˜åº“å­˜å‘¨è½¬ç‡ï¼Œå‡å°‘ç¼ºè´§é£é™©',
                        'ä¼˜å…ˆçº§': 'é«˜'
                    })

                elif abc_class == 'Aç±»' and sensitivity_level == 'ä¸­æ•æ„Ÿ':
                    strategies.append({
                        'å•†å“å“ç±»': category,
                        'ç­–ç•¥ç±»å‹': 'ä¿ƒé”€ç­–ç•¥',
                        'å…·ä½“æªæ–½': 'è®¾è®¡ç»„åˆä¿ƒé”€ï¼Œæ†ç»‘é”€å”®é«˜åˆ©æ¶¦å•†å“',
                        'é¢„æœŸæ•ˆæœ': 'æå‡å®¢å•ä»·ï¼Œå¢åŠ æ•´ä½“åˆ©æ¶¦',
                        'ä¼˜å…ˆçº§': 'ä¸­'
                    })

                elif abc_class == 'Bç±»':
                    strategies.append({
                        'å•†å“å“ç±»': category,
                        'ç­–ç•¥ç±»å‹': 'å¸‚åœºæ‹“å±•',
                        'å…·ä½“æªæ–½': 'åŠ å¼ºç›®æ ‡ç”¨æˆ·æ¨å¹¿ï¼Œä¼˜åŒ–äº§å“å±•ç¤ºä½ç½®',
                        'é¢„æœŸæ•ˆæœ': 'æå‡å“ç±»çŸ¥ååº¦ï¼Œä¿ƒè¿›é”€å”®å¢é•¿',
                        'ä¼˜å…ˆçº§': 'ä¸­'
                    })

                elif abc_class == 'Cç±»':
                    strategies.append({
                        'å•†å“å“ç±»': category,
                        'ç­–ç•¥ç±»å‹': 'æˆæœ¬æ§åˆ¶',
                        'å…·ä½“æªæ–½': 'ç²¾ç®€SKUï¼Œä¼˜åŒ–é‡‡è´­æ‰¹é‡ï¼Œé™ä½åº“å­˜æˆæœ¬',
                        'é¢„æœŸæ•ˆæœ': 'å‡å°‘èµ„æºå ç”¨ï¼Œæé«˜è¿è¥æ•ˆç‡',
                        'ä¼˜å…ˆçº§': 'ä½'
                    })

                # æ ¹æ®æ•æ„Ÿåº¦ç­‰çº§è¡¥å……ç­–ç•¥
                if sensitivity_level == 'é«˜æ•æ„Ÿ':
                    strategies.append({
                        'å•†å“å“ç±»': category,
                        'ç­–ç•¥ç±»å‹': 'ä»·æ ¼ç›‘æ§',
                        'å…·ä½“æªæ–½': 'å»ºç«‹ä»·æ ¼ç›‘æµ‹ä½“ç³»ï¼Œå¿«é€Ÿå“åº”å¸‚åœºå˜åŒ–',
                        'é¢„æœŸæ•ˆæœ': 'ä¿æŒä»·æ ¼æ•æ„Ÿåº¦ä¼˜åŠ¿',
                        'ä¼˜å…ˆçº§': 'é«˜'
                    })

            strategies_df = pd.DataFrame(strategies)
            self.results['operation_strategies'] = strategies_df

            return True

        except Exception as e:
            st.error(f"è¿è¥ç­–ç•¥ç”Ÿæˆé”™è¯¯: {str(e)}")
            return False
def display_task4_results(results, result_files, progress_log):
    """æ˜¾ç¤ºä»»åŠ¡4åˆ†æç»“æœ"""

    # 1. æ˜¾ç¤ºåˆ†ææ—¥å¿—
    st.subheader("ğŸ“ åˆ†ææ‰§è¡Œæ—¥å¿—")
    for log in progress_log:
        st.write(f"â–ªï¸ {log}")

    # 2. ABCåˆ†ç±»åˆ†æç»“æœ
    if 'abc_classification' in results:
        st.subheader("ğŸ“Š ABCåˆ†ç±»åˆ†æ")

        abc_data = results['abc_classification']

        # æ£€æŸ¥åˆ—åå¹¶é€‚é…
        abc_columns_to_show = ['å•†å“å“ç±»', 'é”€å”®é¢å æ¯”%', 'åˆ©æ¶¦å æ¯”%']

        # åŠ¨æ€ç¡®å®šABCåˆ†ç±»åˆ—å
        abc_class_col = None
        possible_abc_cols = ['ABCåˆ†ç±»ï¼ˆé”€å”®é¢ï¼‰', 'ABCåˆ†ç±»', 'ABC_class']
        for col in possible_abc_cols:
            if col in abc_data.columns:
                abc_class_col = col
                break

        if abc_class_col:
            abc_columns_to_show.append(abc_class_col)

        col1, col2 = st.columns(2)

        with col1:
            st.dataframe(abc_data[abc_columns_to_show])

        with col2:
            if 'abc_visualizations' in results:
                st.pyplot(results['abc_visualizations']['sales_distribution'])

        # æ˜¾ç¤ºå…¶ä»–å›¾è¡¨
        if 'abc_visualizations' in results:
            col1, col2 = st.columns(2)
            with col1:
                st.pyplot(results['abc_visualizations']['cumulative_sales'])
            with col2:
                st.pyplot(results['abc_visualizations']['abc_distribution'])

    # 3. ä»·æ ¼æ•æ„Ÿåº¦åˆ†æç»“æœ
    if 'price_sensitivity' in results:
        st.subheader("ğŸ’° ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ")

        sensitivity_data = results['price_sensitivity']

        # æ˜¾ç¤ºæ•æ„Ÿåº¦åˆ†æç»“æœ
        st.dataframe(sensitivity_data)

        # æ˜¾ç¤ºæ‹Ÿåˆå›¾è¡¨
        if 'fitting_charts' in results:
            st.subheader("ğŸ“ˆ ä»·æ ¼-é”€é‡å…³ç³»æ‹Ÿåˆå›¾")
            cols = st.columns(2)
            chart_count = 0

            for chart_name, fig in results['fitting_charts'].items():
                with cols[chart_count % 2]:
                    st.pyplot(fig)
                chart_count += 1

    # 4. ç”¨æˆ·åˆ†å±‚åˆ†æç»“æœ
    if 'user_segmentation' in results:
        st.subheader("ğŸ‘¥ ç”¨æˆ·åˆ†å±‚åˆ†æ")
        st.dataframe(results['user_segmentation'])

    # 5. åœºæ™¯ä»·æ ¼åˆ†æç»“æœ
    if 'scenario_analysis' in results:
        st.subheader("ğŸ·ï¸ åœºæ™¯ä»·æ ¼åˆ†æ")
        st.dataframe(results['scenario_analysis'])

    # 6. ç»¼åˆæ¨¡å‹èåˆç»“æœ
    if 'comprehensive_fusion' in results:
        st.subheader("ğŸ¯ ç»¼åˆæ•æ„Ÿåº¦è¯„ä¼°")
        st.dataframe(results['comprehensive_fusion'])

    # 7. è¿è¥ç­–ç•¥æ¨è
    if 'operation_strategies' in results:
        st.subheader("ğŸš€ å¯æ‰§è¡Œè¿è¥ç­–ç•¥")

        # æŒ‰ä¼˜å…ˆçº§ç­›é€‰
        priority_filter = st.selectbox("ç­›é€‰ç­–ç•¥ä¼˜å…ˆçº§:", ["å…¨éƒ¨", "é«˜", "ä¸­"])

        strategy_data = results['operation_strategies']
        if priority_filter != "å…¨éƒ¨":
            filtered_strategies = strategy_data[
                strategy_data['ä¼˜å…ˆçº§'] == priority_filter]
        else:
            filtered_strategies = strategy_data

        st.dataframe(filtered_strategies)

    # 8. æ–‡ä»¶ä¸‹è½½
    st.subheader("ğŸ“¥ åˆ†æç»“æœä¸‹è½½")
    for filename, data in result_files.items():
        excel_bytes = io.BytesIO()
        with pd.ExcelWriter(excel_bytes, engine='openpyxl') as writer:
            data.to_excel(writer, index=False)
        st.download_button(
            label=f"ä¸‹è½½ {filename}",
            data=excel_bytes.getvalue(),
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
# ============================================================================
# é¡µé¢å‡½æ•°
# ============================================================================
def show_project_overview():
    """é¡¹ç›®æ¦‚è§ˆé¡µé¢"""
    st.header("ğŸ¯ é¡¹ç›®æ¦‚è§ˆ")

    st.markdown(
        '<div class="fix-note"><strong>ç³»ç»ŸåŠŸèƒ½ï¼š</strong><br>1. æ¯ä¸ªä»»åŠ¡éƒ½æ”¯æŒç‹¬ç«‹æ•°æ®å¯¼å…¥<br>2. å¯é€‰æ‹©ä½¿ç”¨ä»»åŠ¡1å¤„ç†æ•°æ®æˆ–ä¸Šä¼ æ–°æ•°æ®<br>3. è‡ªåŠ¨å­—æ®µç±»å‹è¯†åˆ«å’Œå¿…éœ€å­—æ®µæ£€æŸ¥<br>4. æŒ‰è®ºæ–‡æ ‡å‡†æµç¨‹ç”Ÿæˆåˆ†æç»“æœ</div>',
        unsafe_allow_html=True)

    col1, col2 = st.columns([2, 1])
    with col1:
        st.markdown("""
        ### ç³»ç»ŸåŠŸèƒ½æ¦‚è¿°
        å®Œæ•´çš„ç”µå•†é”€å”®åˆ†ææµç¨‹ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½æ”¯æŒç‹¬ç«‹æ•°æ®å¯¼å…¥ï¼š

        - **æ•°æ®é¢„å¤„ç†**: æŒ‰è®ºæ–‡è¦æ±‚ç”Ÿæˆ6ä¸ªæ ‡å‡†åŒ–è¾“å‡ºæ–‡ä»¶
        - **å¤šç»´ç‰¹å¾åˆ†æ**: æ”¯æŒè‡ªå®šä¹‰æ•°æ®æˆ–ä½¿ç”¨é¢„å¤„ç†æ•°æ®
        - **é”€å”®é¢„æµ‹**: ç‹¬ç«‹æ•°æ®å¯¼å…¥ï¼Œè‡ªåŠ¨æ£€æµ‹æ—¶é—´åºåˆ—å­—æ®µ  
        - **è¿è¥ä¼˜åŒ–**: çµæ´»çš„æ•°æ®æºé€‰æ‹©ï¼Œæ”¯æŒå¤šç»´åº¦åˆ†æ

        **æ•°æ®å¯¼å…¥é€‰é¡¹ï¼š**
        - âœ… ä½¿ç”¨ä»»åŠ¡1é¢„å¤„ç†åçš„æ•°æ®
        - âœ… ä¸Šä¼ æ–°çš„Excel/CSVæ–‡ä»¶
        - âœ… è‡ªåŠ¨å­—æ®µç±»å‹è¯†åˆ«
        - âœ… å¿…éœ€å­—æ®µæ£€æŸ¥
        """)

    with col2:
        st.metric("æ ‡å‡†è¾“å‡ºæ–‡ä»¶", "6ä¸ª")
        st.metric("åˆ†æä»»åŠ¡", "4ä¸ª")
        st.metric("æ•°æ®å¯¼å…¥æ–¹å¼", "æ¯ä¸ªä»»åŠ¡ç‹¬ç«‹")
        st.metric("æ”¯æŒæ ¼å¼", "Excel/CSV")

    # ä»»åŠ¡çŠ¶æ€æ¦‚è§ˆ
    st.subheader("ä»»åŠ¡å®ŒæˆçŠ¶æ€")
    tasks = [
        ("æ•°æ®é¢„å¤„ç†", st.session_state.task1_completed),
        ("å¤šç»´åˆ†æ", st.session_state.task2_completed),
        ("é”€å”®é¢„æµ‹", st.session_state.task3_completed),
        ("è¿è¥ä¼˜åŒ–", st.session_state.task4_completed)
    ]

    for task_name, completed in tasks:
        status = "âœ… å·²å®Œæˆ" if completed else "â³ å¾…å®Œæˆ"
        st.write(f"- {task_name}: {status}")

    # æ–°å¢ï¼šä½¿ç”¨æŒ‡å—
    st.subheader("ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—")

    with st.expander("ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜", expanded=True):
        st.markdown("""
        **ç¬¬ä¸€æ­¥ï¼šæ•°æ®é¢„å¤„ç†ï¼ˆä»»åŠ¡1ï¼‰**
        - ä¸Šä¼ åŸå§‹Excel/CSVæ•°æ®æ–‡ä»¶
        - ç³»ç»Ÿè‡ªåŠ¨æ‰§è¡Œ5ä¸ªæ ‡å‡†åŒ–å¤„ç†æ­¥éª¤
        - ç”Ÿæˆ6ä¸ªè®ºæ–‡è¦æ±‚çš„è¾“å‡ºæ–‡ä»¶

        **ç¬¬äºŒæ­¥ï¼šå¤šç»´ç‰¹å¾åˆ†æï¼ˆä»»åŠ¡2ï¼‰**
        - å¯é€‰æ‹©ä½¿ç”¨ä»»åŠ¡1å¤„ç†æ•°æ®æˆ–ä¸Šä¼ æ–°æ–‡ä»¶
        - å¿…éœ€å­—æ®µï¼šåŒºåŸŸã€å•†å“å“ç±»ã€åˆ©æ¶¦
        - ç”Ÿæˆçƒ­åŠ›å›¾ã€èšç±»åˆ†æã€åœ°ç†åˆ†å¸ƒç­‰

        **ç¬¬ä¸‰æ­¥ï¼šé”€å”®é¢„æµ‹ï¼ˆä»»åŠ¡3ï¼‰**
        - å¯é€‰æ‹©ä½¿ç”¨ä»»åŠ¡1å¤„ç†æ•°æ®æˆ–ä¸Šä¼ æ–°æ–‡ä»¶  
        - å¿…éœ€å­—æ®µï¼šæ—¥æœŸã€åˆ©æ¶¦
        - ä½¿ç”¨ARIMA+XGBoostæ··åˆæ¨¡å‹é¢„æµ‹

        **ç¬¬å››æ­¥ï¼šè¿è¥ä¼˜åŒ–ï¼ˆä»»åŠ¡4ï¼‰**
        - å¯é€‰æ‹©ä½¿ç”¨ä»»åŠ¡1å¤„ç†æ•°æ®æˆ–ä¸Šä¼ æ–°æ–‡ä»¶
        - å¿…éœ€å­—æ®µï¼šå•†å“å“ç±»ã€é”€å”®é¢ã€åˆ©æ¶¦ã€å®é™…å”®ä»·ã€é”€å”®æ•°
        - ç”ŸæˆABCåˆ†ç±»ã€ä»·æ ¼æ•æ„Ÿåº¦ã€è¿è¥ç­–ç•¥ç­‰
        """)

    # æ–°å¢ï¼šæ•°æ®è¦æ±‚è¯´æ˜
    st.subheader("ğŸ“‹ æ•°æ®å­—æ®µè¦æ±‚")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        **æ ¸å¿ƒä¸šåŠ¡å­—æ®µï¼š**
        - å•†å“å“ç±»
        - åŒºåŸŸ/çœä»½/åŸå¸‚
        - é”€å”®é¢
        - åˆ©æ¶¦
        - é”€å”®æ•°
        """)

    with col2:
        st.markdown("""
        **ä»·æ ¼ç›¸å…³å­—æ®µï¼š**
        - è¿›è´§ä»·æ ¼
        - å®é™…å”®ä»·
        - æˆæœ¬ä»·æ ¼
        - æŠ˜æ‰£é‡‘é¢
        """)

    with col3:
        st.markdown("""
        **å®¢æˆ·ç›¸å…³å­—æ®µï¼š**
        - å®¢æˆ·æ€§åˆ«
        - å®¢æˆ·å¹´é¾„
        - å®¢æˆ·ç­‰çº§
        - è´­ä¹°æ—¥æœŸ
        """)

    # æ–°å¢ï¼šæ–‡ä»¶æ ¼å¼è¯´æ˜
    st.subheader("ğŸ“ æ–‡ä»¶æ ¼å¼æ”¯æŒ")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        **Excelæ ¼å¼ (.xlsx)ï¼š**
        - æ”¯æŒå¤šå·¥ä½œè¡¨
        - è‡ªåŠ¨è¯†åˆ«æ•°æ®ç±»å‹
        - ä¿æŒåŸå§‹æ ¼å¼

        **æ¨èç”¨äºï¼š**
        - å¤æ‚æ•°æ®ç»“æ„
        - å¤šç»´åº¦åˆ†æ
        - å¤§å‹æ•°æ®é›†
        """)

    with col2:
        st.markdown("""
        **CSVæ ¼å¼ (.csv)ï¼š**
        - é€šç”¨æ•°æ®æ ¼å¼
        - å¿«é€ŸåŠ è½½å¤„ç†
        - å…¼å®¹æ€§å¥½

        **æ¨èç”¨äºï¼š**
        - ç®€å•æ•°æ®ç»“æ„
        - å¿«é€Ÿæµ‹è¯•
        - è·¨å¹³å°ä½¿ç”¨
        """)

    # ä»»åŠ¡çŠ¶æ€æ¦‚è§ˆ
    st.subheader("ä»»åŠ¡å®ŒæˆçŠ¶æ€")
    tasks = [
        ("æ•°æ®é¢„å¤„ç†", st.session_state.task1_completed),
        ("å¤šç»´åˆ†æ", st.session_state.task2_completed),
        ("é”€å”®é¢„æµ‹", st.session_state.task3_completed),
        ("è¿è¥ä¼˜åŒ–", st.session_state.task4_completed)
    ]

    for task_name, completed in tasks:
        status = "âœ… å·²å®Œæˆ" if completed else "â³ å¾…å®Œæˆ"
        st.write(f"- {task_name}: {status}")


def task1_data_preprocessing():
    """ä»»åŠ¡1ï¼šæ•°æ®é¢„å¤„ç†é¡µé¢ï¼ˆæŒ‰è®ºæ–‡è¦æ±‚ç”Ÿæˆæ ‡å‡†åŒ–è¾“å‡ºæ–‡ä»¶ï¼‰"""
    st.header("ğŸ“ ä»»åŠ¡1: æ•°æ®é¢„å¤„ç†")

    st.markdown(
        '<div class="fix-note"><strong>è®ºæ–‡è¦æ±‚è¾“å‡ºæ–‡ä»¶ï¼š</strong><br>1. ç”µå•† æ­¥éª¤1 ç¼ºå¤±å€¼ç»Ÿè®¡ç»“æœ.xlsx<br>2. ç”µå•† æ­¥éª¤2 è¿›è´§ä»·æ ¼å¤„ç†åæ•°æ®.xlsx<br>3. ç”µå•† æ­¥éª¤3 åˆ©æ¶¦ä¿®æ­£åæ•°æ®.xlsx<br>4. ç”µå•† æ­¥éª¤4 å¼‚å¸¸ä¿®æ­£åŠåˆ©æ¶¦é‡ç®—åæ•°æ®.xlsx<br>5. ç”µå•† æ­¥éª¤5 MinMaxæ ‡å‡†åŒ–åæ•°æ®.xlsx<br>6. ç”µå•† æ­¥éª¤5 ZScoreæ ‡å‡†åŒ–åæ•°æ®.xlsx</div>',
        unsafe_allow_html=True)

    # æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
    uploaded_file = st.file_uploader("ä¸Šä¼ åŸå§‹æ•°æ®è¡¨ï¼ˆæ”¯æŒExcelæˆ–CSVæ ¼å¼ï¼‰", type=["xlsx", "csv"])

    if uploaded_file is not None:
        # è¯»å–æ–‡ä»¶
        try:
            if uploaded_file.name.endswith('.xlsx'):
                df = pd.read_excel(uploaded_file)
            else:
                df = pd.read_csv(uploaded_file)

            # ä¿å­˜åŸå§‹æ•°æ®
            st.session_state.raw_data = df
            st.session_state.current_file = uploaded_file.name

            # æ•°æ®æ¸…æ´—ï¼šè‡ªåŠ¨å¤„ç†æ•°å€¼åˆ—ä¸­çš„éæ•°å€¼å­—ç¬¦
            df_clean = clean_numeric_columns(df)

            st.success(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼å…± {len(df)} æ¡è®°å½•ï¼Œ{len(df.columns)} ä¸ªå­—æ®µ")

            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆå’Œæ¸…æ´—å‰åå¯¹æ¯”
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("åŸå§‹æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰")
                st.dataframe(df.head())

            with col2:
                st.subheader("æ¸…æ´—åæ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰")
                st.dataframe(df_clean.head())

            # æ˜¾ç¤ºæ•°æ®ç±»å‹ä¿¡æ¯
            st.subheader("æ•°æ®ç±»å‹ä¿¡æ¯")
            dtype_df = pd.DataFrame({
                'å­—æ®µå': df_clean.columns,
                'æ•°æ®ç±»å‹': df_clean.dtypes.astype(str)
            })
            st.dataframe(dtype_df)

            # æ‰§è¡Œé¢„å¤„ç†æŒ‰é’®
            if st.button("ğŸš€ å¼€å§‹æ•°æ®é¢„å¤„ç†ï¼ˆæŒ‰è®ºæ–‡æ­¥éª¤ï¼‰", type="primary"):
                with st.spinner("æ­£åœ¨æ‰§è¡Œæ•°æ®é¢„å¤„ç†...ï¼ˆæŒ‰è®ºæ–‡è¦æ±‚ç”Ÿæˆ6ä¸ªè¾“å‡ºæ–‡ä»¶ï¼‰"):
                    preprocessor = Task1Preprocessor(df_clean)
                    result_files, progress_log, final_data, encoders, column_types = preprocessor.generate_all_results()

                    if result_files:
                        # ä¿å­˜ç»“æœåˆ°session state
                        st.session_state.step1_missing_data = result_files['ç”µå•† æ­¥éª¤1 ç¼ºå¤±å€¼ç»Ÿè®¡ç»“æœ.xlsx']
                        st.session_state.step2_price_data = result_files['ç”µå•† æ­¥éª¤2 è¿›è´§ä»·æ ¼å¤„ç†åæ•°æ®.xlsx']
                        st.session_state.step3_profit_data = result_files['ç”µå•† æ­¥éª¤3 åˆ©æ¶¦ä¿®æ­£åæ•°æ®.xlsx']
                        st.session_state.step4_abnormal_data = result_files['ç”µå•† æ­¥éª¤4 å¼‚å¸¸ä¿®æ­£åŠåˆ©æ¶¦é‡ç®—åæ•°æ®.xlsx']
                        st.session_state.step5_minmax_data = result_files['ç”µå•† æ­¥éª¤5 MinMaxæ ‡å‡†åŒ–åæ•°æ®.xlsx']
                        st.session_state.step5_zscore_data = result_files['ç”µå•† æ­¥éª¤5 ZScoreæ ‡å‡†åŒ–åæ•°æ®.xlsx']
                        st.session_state.processed_data = final_data
                        st.session_state.category_encoder = encoders
                        st.session_state.column_types = column_types
                        st.session_state.task1_completed = True

                        st.success("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼å·²ç”Ÿæˆè®ºæ–‡è¦æ±‚çš„6ä¸ªè¾“å‡ºæ–‡ä»¶")

                        # 1. å±•ç¤ºé¢„å¤„ç†æ­¥éª¤ç»“æœé¢„è§ˆ
                        st.subheader("1. é¢„å¤„ç†æ­¥éª¤ç»“æœé¢„è§ˆ")

                        # æ­¥éª¤1ï¼šç¼ºå¤±å€¼ç»Ÿè®¡ç»“æœ
                        st.markdown("#### æ­¥éª¤1ï¼šç¼ºå¤±å€¼ç»Ÿè®¡ç»“æœ")
                        st.dataframe(st.session_state.step1_missing_data.head())

                        # æ­¥éª¤2ï¼šè¿›è´§ä»·æ ¼å¤„ç†åæ•°æ®
                        st.markdown("#### æ­¥éª¤2ï¼šè¿›è´§ä»·æ ¼å¤„ç†åæ•°æ®")
                        st.dataframe(st.session_state.step2_price_data[['å•†å“å“ç±»', 'è¿›è´§ä»·æ ¼']].head())

                        # æ­¥éª¤3ï¼šåˆ©æ¶¦ä¿®æ­£åæ•°æ®
                        st.markdown("#### æ­¥éª¤3ï¼šåˆ©æ¶¦ä¿®æ­£åæ•°æ®")
                        if 'åˆ©æ¶¦æ˜¯å¦æ­£ç¡®' in st.session_state.step3_profit_data.columns:
                            st.dataframe(
                                st.session_state.step3_profit_data[['å•†å“å“ç±»', 'åˆ©æ¶¦', 'åˆ©æ¶¦æ˜¯å¦æ­£ç¡®']].head())
                        else:
                            st.dataframe(st.session_state.step3_profit_data[['å•†å“å“ç±»', 'åˆ©æ¶¦']].head())

                        # 2. å±•ç¤ºé¢„å¤„ç†æ—¥å¿—
                        st.subheader("2. é¢„å¤„ç†æ‰§è¡Œæ—¥å¿—")
                        for log in progress_log:
                            st.write(f"â–ªï¸ {log}")

                        # 3. æä¾›ç»“æœæ–‡ä»¶ä¸‹è½½ï¼ˆæŒ‰è®ºæ–‡è¦æ±‚çš„æ–‡ä»¶åï¼‰
                        st.subheader("ğŸ“¥ è®ºæ–‡è¦æ±‚è¾“å‡ºæ–‡ä»¶ä¸‹è½½")
                        for filename, data in result_files.items():
                            if isinstance(data, pd.ExcelWriter):
                                excel_bytes = io.BytesIO()
                                data.save(excel_bytes)
                                excel_bytes.seek(0)
                                st.download_button(
                                    label=f"ä¸‹è½½ {filename}",
                                    data=excel_bytes,
                                    file_name=filename,
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                            elif isinstance(data, pd.DataFrame):
                                excel_bytes = io.BytesIO()
                                with pd.ExcelWriter(excel_bytes, engine='openpyxl') as writer:
                                    data.to_excel(writer, index=False)
                                st.download_button(
                                    label=f"ä¸‹è½½ {filename}",
                                    data=excel_bytes.getvalue(),
                                    file_name=filename,
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )

                        # æç¤ºä¸‹ä¸€æ­¥æ“ä½œ
                        st.info("é¢„å¤„ç†å®Œæˆï¼å¯ç»§ç»­è¿›è¡Œ å¤šç»´é”€å”®ç‰¹å¾åˆ†æï¼ˆä»»åŠ¡2ï¼‰")
                    else:
                        st.error("é¢„å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–æŸ¥çœ‹é”™è¯¯æ—¥å¿—")
                        for log in progress_log:
                            st.error(log)

        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")
    else:
        st.info("è¯·ä¸Šä¼ åŸå§‹æ•°æ®æ–‡ä»¶å¼€å§‹é¢„å¤„ç†æµç¨‹ï¼ˆå»ºè®®åŒ…å«ï¼šå•†å“å“ç±»ã€åŒºåŸŸã€é”€å”®é¢ã€åˆ©æ¶¦ã€æ—¥æœŸç­‰å­—æ®µï¼‰")


def enhanced_task2_multidimensional_analysis():
    """å¢å¼ºç‰ˆå¤šç»´åˆ†æé¡µé¢"""
    st.header("ğŸ” ä»»åŠ¡2: å¤šç»´é”€å”®ç‰¹å¾åˆ†æ")

    # ============================================================================
    # ä½¿ç”¨æ–°çš„æ•°æ®å¯¼å…¥ç»„ä»¶
    # ============================================================================
    st.subheader("ğŸ“ æ•°æ®å¯¼å…¥")

    col1, col2 = st.columns(2)
    data_source = None
    current_data = None

    with col1:
        # æ•°æ®æºé€‰æ‹©
        data_source_option = st.radio(
            "é€‰æ‹©å¤šç»´åˆ†ææ•°æ®æº:",
            ["ä½¿ç”¨åŸå§‹æ•°æ®", "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶", "ä¸Šä¼ æ–°æ–‡ä»¶"],
            key="data_source_task2"
        )

    with col2:
        if data_source_option == "ä½¿ç”¨åŸå§‹æ•°æ®":
            if st.session_state.get('raw_data') is not None:
                current_data = st.session_state.raw_data
                data_source = "åŸå§‹æ•°æ®"
                st.success(f"ä½¿ç”¨åŸå§‹æ•°æ®ï¼Œå…± {len(current_data)} æ¡è®°å½•")
            else:
                st.error("æš‚æ— åŸå§‹æ•°æ®ï¼Œè¯·å…ˆåœ¨ä»»åŠ¡1ä¸­ä¸Šä¼ æ–‡ä»¶")
                return

        elif data_source_option == "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶":
            # ä»»åŠ¡1ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨
            task1_files = {
                "æ­¥éª¤2_è¿›è´§ä»·æ ¼å¤„ç†åæ•°æ®": "step2_price_data",
                "æ­¥éª¤3_åˆ©æ¶¦ä¿®æ­£åæ•°æ®": "step3_profit_data",
                "æ­¥éª¤4_å¼‚å¸¸ä¿®æ­£åŠåˆ©æ¶¦é‡ç®—åæ•°æ®": "step4_abnormal_data",
                "æ­¥éª¤5_MinMaxæ ‡å‡†åŒ–åæ•°æ®": "step5_minmax_data",
                "æ­¥éª¤5_ZScoreæ ‡å‡†åŒ–åæ•°æ®": "step5_zscore_data"
            }

            selected_file = st.selectbox(
                "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶:",
                list(task1_files.keys()),
                key="task1_file_task2"
            )

            if selected_file and st.session_state.get(task1_files[selected_file]) is not None:
                current_data = st.session_state[task1_files[selected_file]]
                data_source = f"ä»»åŠ¡1: {selected_file}"
                st.success(f"ä½¿ç”¨{selected_file}ï¼Œå…± {len(current_data)} æ¡è®°å½•")
            else:
                st.error("é€‰æ‹©çš„æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®Œæˆä»»åŠ¡1")
                return

        else:  # ä¸Šä¼ æ–°æ–‡ä»¶
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ å¤šç»´åˆ†ææ•°æ®æ–‡ä»¶",
                type=["xlsx", "csv"],
                key="upload_task2_new"
            )

            if uploaded_file:
                try:
                    if uploaded_file.name.endswith('.xlsx'):
                        current_data = pd.read_excel(uploaded_file)
                    else:
                        current_data = pd.read_csv(uploaded_file)

                    current_data = clean_numeric_columns(current_data)
                    data_source = f"è‡ªå®šä¹‰æ–‡ä»¶: {uploaded_file.name}"
                    st.success(f"æ•°æ®åŠ è½½æˆåŠŸï¼å…± {len(current_data)} æ¡è®°å½•")
                except Exception as e:
                    st.error(f"æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")
                    return
            else:
                st.info("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶")
                return

    # æ£€æŸ¥å¿…éœ€å­—æ®µï¼ˆå¤šç»´åˆ†æéœ€è¦çš„æ ¸å¿ƒå­—æ®µï¼‰
    required_columns = ['åŒºåŸŸ', 'å•†å“å“ç±»', 'åˆ©æ¶¦']
    if current_data is not None:
        missing_columns = [col for col in required_columns if col not in current_data.columns]
        if missing_columns:
            st.error(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_columns)}")
            st.info(f"å¤šç»´åˆ†æéœ€è¦çš„å­—æ®µ: {', '.join(required_columns)}")
            st.info("å¯é€‰å­—æ®µ: æ—¥æœŸ, å®¢æˆ·æ€§åˆ«, å®¢æˆ·å¹´é¾„, é”€å”®é¢, é”€å”®æ•°ç­‰")
            return

    # æ˜¾ç¤ºæ•°æ®æºä¿¡æ¯
    if current_data is not None:
        st.success(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ - æ•°æ®æº: {data_source}")
        st.info(f"æ•°æ®ç»´åº¦: {len(current_data)} è¡Œ Ã— {len(current_data.columns)} åˆ—")

        # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
        with st.expander("ğŸ“‹ æ•°æ®é¢„è§ˆ"):
            st.dataframe(current_data.head(10))
    else:
        return
    # ============================================================================
    # ç»“æŸæ•°æ®å¯¼å…¥éƒ¨åˆ†
    # ============================================================================

    # è‡ªåŠ¨æ£€æµ‹å­—æ®µç±»å‹
    column_types = auto_detect_column_types(current_data)

    # åˆ†ææ¨¡å¼é€‰æ‹©
    analysis_mode = st.radio(
        "é€‰æ‹©åˆ†ææ¨¡å¼:",
        ["ğŸ“Š Pythonå¯è§†åŒ–å±•ç¤º", "ğŸ“ è®ºæ–‡å›¾è¡¨æ•°æ®å¯¼å‡º", "ğŸ¨ äº¤äº’å¼å¯è§†åŒ–ä»ªè¡¨æ¿"],  # æ–°å¢ç¬¬ä¸‰ä¸ªé€‰é¡¹
        horizontal=True
    )

    if st.button("ğŸš€ æ‰§è¡Œå¤šç»´ç‰¹å¾åˆ†æ", type="primary"):
        with st.spinner("æ­£åœ¨æ‰§è¡Œå¤šç»´åˆ†æ..."):
            analyzer = EnhancedTask2Analyzer(current_data, column_types)

            # æ‰§è¡ŒåŸºç¡€åˆ†æï¼ˆçƒ­åŠ›å›¾å’Œèšç±»ï¼‰
            heatmap_success = analyzer.create_heatmaps()
            cluster_success = analyzer.perform_clustering_analysis()

            # ç”Ÿæˆæ‰€æœ‰åˆ†ææ•°æ®
            all_analysis_data = analyzer.generate_all_analysis_data()

            st.session_state.task2_results = analyzer.results
            st.session_state.task2_analysis_data = all_analysis_data
            st.session_state.task2_completed = True

            st.success("âœ… å¤šç»´ç‰¹å¾åˆ†æå®Œæˆï¼")

            # æ˜¾ç¤ºåˆ†æç»“æœæ‘˜è¦
            st.subheader("ğŸ“Š åˆ†æç»“æœæ‘˜è¦")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("çƒ­åŠ›å›¾ç”Ÿæˆ", "æˆåŠŸ" if heatmap_success else "éƒ¨åˆ†å¤±è´¥")
            with col2:
                st.metric("èšç±»åˆ†æ", "æˆåŠŸ" if cluster_success else "å¤±è´¥")
            with col3:
                analysis_count = sum(1 for data in all_analysis_data.values() if data is not None)
                st.metric("åˆ†æç»´åº¦", f"{analysis_count}ä¸ª")

            if analysis_mode == "ğŸ“Š Pythonå¯è§†åŒ–å±•ç¤º":
                show_python_visualizations(analyzer)
            else:
                show_data_export_interface(all_analysis_data)
    else:
        st.info("""
        **å¤šç»´ç‰¹å¾åˆ†æåŠŸèƒ½è¯´æ˜ï¼š**

        **å¿…éœ€å­—æ®µï¼š**
        - åŒºåŸŸï¼ˆç”¨äºåœ°ç†åˆ†å¸ƒåˆ†æï¼‰
        - å•†å“å“ç±»ï¼ˆç”¨äºå“ç±»åˆ†æï¼‰  
        - åˆ©æ¶¦ï¼ˆç”¨äºä»·å€¼åˆ†æï¼‰

        **æ¨èå­—æ®µï¼š**
        - æ—¥æœŸï¼ˆç”¨äºæ—¶é—´åºåˆ—åˆ†æï¼‰
        - å®¢æˆ·æ€§åˆ«ã€å®¢æˆ·å¹´é¾„ï¼ˆç”¨äºç”¨æˆ·ç”»åƒåˆ†æï¼‰
        - é”€å”®æ•°ã€è¿›è´§ä»·æ ¼ï¼ˆç”¨äºä¸šåŠ¡åˆ†æï¼‰

        **åˆ†ææ¨¡å¼ï¼š**
        - ğŸ“Š Pythonå¯è§†åŒ–å±•ç¤ºï¼šç³»ç»Ÿå†…ç½®å›¾è¡¨ï¼Œå³æ—¶æŸ¥çœ‹åˆ†æç»“æœ
        - ğŸ“ è®ºæ–‡å›¾è¡¨æ•°æ®å¯¼å‡ºï¼šå¯¼å‡ºExcelæ•°æ®ç”¨äºè®ºæ–‡å›¾è¡¨åˆ¶ä½œ

        **ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®å¼€å§‹åˆ†æï¼**
        """)


def task3_sales_forecast():
    """ä»»åŠ¡3ï¼šé”€å”®é¢„æµ‹é¡µé¢"""
    st.header("ğŸ“ˆ ä»»åŠ¡3: é”€å”®é¢„æµ‹")

    # ============================================================================
    # ä½¿ç”¨æ–°çš„æ•°æ®å¯¼å…¥ç»„ä»¶
    # ============================================================================
    st.subheader("ğŸ“ æ•°æ®å¯¼å…¥")

    col1, col2 = st.columns(2)
    data_source = None
    current_data = None

    with col1:
        # æ•°æ®æºé€‰æ‹©
        data_source_option = st.radio(
            "é€‰æ‹©é”€å”®é¢„æµ‹æ•°æ®æº:",
            ["ä½¿ç”¨åŸå§‹æ•°æ®", "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶", "ä¸Šä¼ æ–°æ–‡ä»¶"],
            key="data_source_task3"
        )

    with col2:
        if data_source_option == "ä½¿ç”¨åŸå§‹æ•°æ®":
            if st.session_state.get('raw_data') is not None:
                current_data = st.session_state.raw_data
                data_source = "åŸå§‹æ•°æ®"
                st.success(f"ä½¿ç”¨åŸå§‹æ•°æ®ï¼Œå…± {len(current_data)} æ¡è®°å½•")
            else:
                st.error("æš‚æ— åŸå§‹æ•°æ®ï¼Œè¯·å…ˆåœ¨ä»»åŠ¡1ä¸­ä¸Šä¼ æ–‡ä»¶")
                return

        elif data_source_option == "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶":
            # ä»»åŠ¡1ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨
            task1_files = {
                "æ­¥éª¤2_è¿›è´§ä»·æ ¼å¤„ç†åæ•°æ®": "step2_price_data",
                "æ­¥éª¤3_åˆ©æ¶¦ä¿®æ­£åæ•°æ®": "step3_profit_data",
                "æ­¥éª¤4_å¼‚å¸¸ä¿®æ­£åŠåˆ©æ¶¦é‡ç®—åæ•°æ®": "step4_abnormal_data",
                "æ­¥éª¤5_MinMaxæ ‡å‡†åŒ–åæ•°æ®": "step5_minmax_data",
                "æ­¥éª¤5_ZScoreæ ‡å‡†åŒ–åæ•°æ®": "step5_zscore_data"
            }

            selected_file = st.selectbox(
                "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶:",
                list(task1_files.keys()),
                key="task1_file_task3"
            )

            if selected_file and st.session_state.get(task1_files[selected_file]) is not None:
                current_data = st.session_state[task1_files[selected_file]]
                data_source = f"ä»»åŠ¡1: {selected_file}"
                st.success(f"ä½¿ç”¨{selected_file}ï¼Œå…± {len(current_data)} æ¡è®°å½•")
            else:
                st.error("é€‰æ‹©çš„æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®Œæˆä»»åŠ¡1")
                return

        else:  # ä¸Šä¼ æ–°æ–‡ä»¶
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ é”€å”®é¢„æµ‹æ•°æ®æ–‡ä»¶",
                type=["xlsx", "csv"],
                key="upload_task3_new"
            )

            if uploaded_file:
                try:
                    if uploaded_file.name.endswith('.xlsx'):
                        current_data = pd.read_excel(uploaded_file)
                    else:
                        current_data = pd.read_csv(uploaded_file)

                    current_data = clean_numeric_columns(current_data)
                    data_source = f"è‡ªå®šä¹‰æ–‡ä»¶: {uploaded_file.name}"
                    st.success(f"æ•°æ®åŠ è½½æˆåŠŸï¼å…± {len(current_data)} æ¡è®°å½•")
                except Exception as e:
                    st.error(f"æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")
                    return
            else:
                st.info("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶")
                return

    # æ£€æŸ¥å¿…éœ€å­—æ®µï¼ˆé”€å”®é¢„æµ‹éœ€è¦çš„æ ¸å¿ƒå­—æ®µï¼‰
    required_columns = ['æ—¥æœŸ', 'åˆ©æ¶¦']
    if current_data is not None:
        missing_columns = [col for col in required_columns if col not in current_data.columns]
        if missing_columns:
            st.error(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_columns)}")
            st.info(f"é”€å”®é¢„æµ‹éœ€è¦çš„å­—æ®µ: {', '.join(required_columns)}")
            st.info("æ¨èå­—æ®µ: é”€å”®é¢, é”€å”®æ•°, è¿›è´§ä»·æ ¼, å®é™…å”®ä»·ç­‰")
            return

    # æ˜¾ç¤ºæ•°æ®æºä¿¡æ¯
    if current_data is not None:
        st.success(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ - æ•°æ®æº: {data_source}")
        st.info(f"æ•°æ®ç»´åº¦: {len(current_data)} è¡Œ Ã— {len(current_data.columns)} åˆ—")

        # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
        with st.expander("ğŸ“‹ æ•°æ®é¢„è§ˆ"):
            st.dataframe(current_data.head(10))

        # æ£€æŸ¥æ—¥æœŸå­—æ®µæ ¼å¼
        date_col = next((col for col in current_data.columns if 'æ—¥æœŸ' in col), None)
        if date_col:
            st.info(f"æ£€æµ‹åˆ°æ—¥æœŸå­—æ®µ: {date_col}")
            # å°è¯•è½¬æ¢æ—¥æœŸä¸ºæ•°å€¼æ ¼å¼ï¼ˆä¸é¢„æµ‹ä»£ç ä¸€è‡´ï¼‰
            try:
                current_data[date_col] = pd.to_numeric(current_data[date_col], errors='coerce')
                date_range = f"{current_data[date_col].min()} è‡³ {current_data[date_col].max()}"
                st.info(f"æ—¥æœŸèŒƒå›´: {date_range}")
            except:
                st.warning("æ—¥æœŸå­—æ®µæ ¼å¼å¯èƒ½éœ€è¦è°ƒæ•´")
    else:
        return
    # ============================================================================
    # ç»“æŸæ•°æ®å¯¼å…¥éƒ¨åˆ†
    # ============================================================================

    # è‡ªåŠ¨æ£€æµ‹å­—æ®µç±»å‹
    column_types = auto_detect_column_types(current_data)

    # æ‰§è¡Œé¢„æµ‹
    if st.button("ğŸš€ æ‰§è¡ŒARIMA-XGBoostæ··åˆé¢„æµ‹", type="primary"):
        with st.spinner("é¢„æµ‹ä¸­...ï¼ˆä½¿ç”¨ARIMA(2,1,2)+XGBoostæ··åˆæ¨¡å‹ï¼‰"):
            forecaster = Task3Forecaster(current_data, column_types)
            result_files, progress_log = forecaster.generate_all_results()

            if result_files:
                st.session_state.task3_results = forecaster.results
                st.session_state.task3_completed = True
                st.success("âœ… é”€å”®é¢„æµ‹å®Œæˆï¼")

                # 1. å±•ç¤ºé¢„æµ‹ç»“æœå¯è§†åŒ–
                st.subheader("ğŸ“Š é¢„æµ‹ç»“æœå¯è§†åŒ–")

                if 'visualizations' in forecaster.results:
                    viz_results = forecaster.results['visualizations']

                    # åˆ©æ¶¦é¢„æµ‹å¯¹æ¯”å›¾ï¼ˆå¿…é¡»å±•ç¤ºï¼‰
                    st.markdown("#### 1. åˆ©æ¶¦é¢„æµ‹å¯¹æ¯”å›¾")
                    st.pyplot(viz_results['main_forecast'])
                    st.markdown("""
                    **å›¾è¡¨è¯´æ˜ï¼š**
                    - è“è‰²çº¿ï¼šè®­ç»ƒé›†å®é™…åˆ©æ¶¦å€¼
                    - çº¢è‰²çº¿ï¼šæµ‹è¯•é›†å®é™…åˆ©æ¶¦å€¼  
                    - ç²‰è‰²è™šçº¿ï¼šARIMAæ¨¡å‹é¢„æµ‹å€¼
                    - ç»¿è‰²çº¿ï¼šARIMA+XGBoostæœ€ç»ˆé¢„æµ‹å€¼
                    - ç°è‰²è™šçº¿ï¼šè®­ç»ƒé›†/æµ‹è¯•é›†åˆ†ç•Œçº¿
                    """)

                    # è¯¯å·®åˆ†æå›¾
                    st.markdown("#### 2. é¢„æµ‹è¯¯å·®åˆ†æå›¾")
                    st.pyplot(viz_results['error_analysis'])
                    st.markdown("""
                    **å›¾è¡¨è¯´æ˜ï¼š**
                    - æ˜¾ç¤ºæ¯æ—¥é¢„æµ‹çš„ç›¸å¯¹è¯¯å·®ç™¾åˆ†æ¯”
                    - MAPEï¼ˆå¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®ï¼‰æ˜¯ä¸»è¦è¯„ä¼°æŒ‡æ ‡
                    - è¯¯å·®è¶Šå°ï¼Œæ¨¡å‹é¢„æµ‹ç²¾åº¦è¶Šé«˜
                    """)

                    # æ®‹å·®åˆ†æå›¾
                    if 'residual_analysis' in viz_results:
                        st.markdown("#### 3. ARIMAæ¨¡å‹æ®‹å·®åˆ†æå›¾")
                        st.pyplot(viz_results['residual_analysis'])
                        st.markdown("""
                        **å›¾è¡¨è¯´æ˜ï¼š**
                        - æ˜¾ç¤ºARIMAæ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„æ®‹å·®åˆ†å¸ƒ
                        - æ®‹å·®è¶Šæ¥è¿‘0ä¸”æ³¢åŠ¨è¶Šå°ï¼Œè¯´æ˜ARIMAæ¨¡å‹æ‹Ÿåˆè¶Šå¥½
                        - ä¸ºXGBoostæä¾›å­¦ä¹ ç›®æ ‡
                        """)

                    # ç‰¹å¾é‡è¦æ€§æ’åå›¾
                    if 'feature_importance' in viz_results:
                        st.markdown("#### 4. ç‰¹å¾é‡è¦æ€§æ’åå›¾")
                        st.pyplot(viz_results['feature_importance'])
                        st.markdown("""
                        **å›¾è¡¨è¯´æ˜ï¼š**
                        - æ˜¾ç¤ºXGBoostæ¨¡å‹ä¸­å„ç‰¹å¾çš„é‡è¦æ€§å¾—åˆ†
                        - é‡è¦æ€§è¶Šé«˜ï¼Œè¯¥ç‰¹å¾å¯¹æ®‹å·®é¢„æµ‹çš„è´¡çŒ®è¶Šå¤§
                        - å¸®åŠ©ç†è§£æ¨¡å‹å†³ç­–ä¾æ®
                        """)

                # 2. å±•ç¤ºé¢„æµ‹ç»“æœè¡¨æ ¼
                st.subheader("ğŸ“‹ é¢„æµ‹ç»“æœè¯¦æƒ…")
                if 'detailed_results' in forecaster.results:
                    forecast_df = forecaster.results['detailed_results']
                    st.dataframe(forecast_df.round(2))

                    # å…³é”®æŒ‡æ ‡æ€»ç»“
                    st.subheader("ğŸ¯ é¢„æµ‹å…³é”®æŒ‡æ ‡")
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        mape = forecaster.results.get('mape', 0)
                        st.metric("æµ‹è¯•é›†MAPE", f"{mape:.2f}%")

                    with col2:
                        best_error = forecast_df['ç›¸å¯¹è¯¯å·®(%)'].min()
                        best_day = forecast_df.loc[forecast_df['ç›¸å¯¹è¯¯å·®(%)'].idxmin(), 'æ—¥æœŸ']
                        st.metric("æœ€ä½³é¢„æµ‹ç²¾åº¦", f"{best_error:.1f}%", f"11æœˆ{int(best_day)}æ—¥")

                    with col3:
                        worst_error = forecast_df['ç›¸å¯¹è¯¯å·®(%)'].max()
                        worst_day = forecast_df.loc[forecast_df['ç›¸å¯¹è¯¯å·®(%)'].idxmax(), 'æ—¥æœŸ']
                        st.metric("æœ€å·®é¢„æµ‹ç²¾åº¦", f"{worst_error:.1f}%", f"11æœˆ{int(worst_day)}æ—¥")

                # 3. ç‰¹å¾é‡è¦æ€§åˆ†æ
                st.subheader("ğŸ” ç‰¹å¾é‡è¦æ€§åˆ†æ")
                if 'feature_importance' in forecaster.results:
                    feature_importance = forecaster.results['feature_importance']
                    st.dataframe(feature_importance.round(4))

                    st.info("""
                    **ç‰¹å¾é‡è¦æ€§è§£è¯»ï¼š**
                    - **é«˜é‡è¦æ€§ç‰¹å¾**ï¼šå¯¹æ¨¡å‹é¢„æµ‹å½±å“æœ€å¤§çš„å› ç´ 
                    - **ä¸­ç­‰é‡è¦æ€§ç‰¹å¾**ï¼šæœ‰ä¸€å®šé¢„æµ‹ä»·å€¼çš„è¾…åŠ©å› ç´   
                    - **ä½é‡è¦æ€§ç‰¹å¾**ï¼šå¯¹é¢„æµ‹ç»“æœå½±å“è¾ƒå°
                    """)

                # 4. è¿›åº¦æ—¥å¿—
                st.subheader("ğŸ“ é¢„æµ‹æ‰§è¡Œæ—¥å¿—")
                for log in progress_log:
                    st.write(f"â–ªï¸ {log}")

                # 5. æ–‡ä»¶ä¸‹è½½
                st.subheader("ğŸ“¥ é¢„æµ‹ç»“æœæ–‡ä»¶ä¸‹è½½")
                for filename, data in result_files.items():
                    if isinstance(data, pd.DataFrame):
                        excel_bytes = io.BytesIO()
                        with pd.ExcelWriter(excel_bytes, engine='openpyxl') as writer:
                            data.to_excel(writer, index=False)
                        st.download_button(
                            label=f"ä¸‹è½½ {filename}",
                            data=excel_bytes.getvalue(),
                            file_name=filename,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )

                # æç¤ºä¸‹ä¸€æ­¥æ“ä½œ
                st.info("é”€å”®é¢„æµ‹å®Œæˆï¼å¯ç»§ç»­è¿›è¡Œ è¿è¥ç­–ç•¥ä¼˜åŒ–ï¼ˆä»»åŠ¡4ï¼‰")
            else:
                st.error("é¢„æµ‹å¤±è´¥ï¼Œè¯·æŸ¥çœ‹é”™è¯¯æ—¥å¿—")
                for log in progress_log:
                    st.error(log)
    else:
        st.info("""
        **ARIMA-XGBoostæ··åˆé¢„æµ‹æ¨¡å‹è¯´æ˜ï¼š**

        **å¿…éœ€å­—æ®µï¼š**
        - æ—¥æœŸï¼ˆæ—¶é—´åºåˆ—ç´¢å¼•ï¼Œæ”¯æŒæ•°å€¼æ ¼å¼å¦‚1-30è¡¨ç¤º11æœˆ1-30æ—¥ï¼‰
        - åˆ©æ¶¦ï¼ˆé¢„æµ‹ç›®æ ‡å˜é‡ï¼‰

        **æ¨èå­—æ®µï¼š**
        - é”€å”®é¢ã€é”€å”®æ•°ï¼ˆç‰¹å¾å˜é‡ï¼‰
        - è¿›è´§ä»·æ ¼ã€å®é™…å”®ä»·ï¼ˆä¸šåŠ¡ç‰¹å¾ï¼‰
        - å•†å“å“ç±»ã€åŒºåŸŸï¼ˆåˆ†ç±»ç‰¹å¾ï¼‰

        **æ¨¡å‹ç‰¹ç‚¹ï¼š**
        - ä½¿ç”¨ARIMA(2,1,2)æ¨¡å‹æ•æ‰æ—¶é—´åºåˆ—è¶‹åŠ¿
        - ä½¿ç”¨XGBoostæ¨¡å‹å­¦ä¹ ARIMAçš„æ®‹å·®æ¨¡å¼
        - æœ€ç»ˆé¢„æµ‹ = ARIMAé¢„æµ‹ + XGBoostæ®‹å·®é¢„æµ‹
        - è‡ªåŠ¨åˆ’åˆ†è®­ç»ƒé›†ï¼ˆå‰24å¤©ï¼‰å’Œæµ‹è¯•é›†ï¼ˆå6å¤©ï¼‰
        - è¾“å‡ºMAPEï¼ˆå¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®ï¼‰è¯„ä¼°é¢„æµ‹ç²¾åº¦

        **ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®å¼€å§‹é¢„æµ‹åˆ†æï¼**
        """)


def task4_operation_optimization():
    """ä»»åŠ¡4ï¼šè¿è¥ç­–ç•¥ä¼˜åŒ–é¡µé¢"""
    st.header("ğŸ’¡ ä»»åŠ¡4: è¿è¥ç­–ç•¥ä¼˜åŒ–")

    # ============================================================================
    # ä½¿ç”¨æ–°çš„æ•°æ®å¯¼å…¥ç»„ä»¶
    # ============================================================================
    st.subheader("ğŸ“ æ•°æ®å¯¼å…¥")

    col1, col2 = st.columns(2)
    data_source = None
    current_data = None

    with col1:
        # æ•°æ®æºé€‰æ‹©
        data_source_option = st.radio(
            "é€‰æ‹©è¿è¥ä¼˜åŒ–æ•°æ®æº:",
            ["ä½¿ç”¨åŸå§‹æ•°æ®", "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶", "ä¸Šä¼ æ–°æ–‡ä»¶"],
            key="data_source_task4"
        )

    with col2:
        if data_source_option == "ä½¿ç”¨åŸå§‹æ•°æ®":
            if st.session_state.get('raw_data') is not None:
                current_data = st.session_state.raw_data
                data_source = "åŸå§‹æ•°æ®"
                st.success(f"ä½¿ç”¨åŸå§‹æ•°æ®ï¼Œå…± {len(current_data)} æ¡è®°å½•")
            else:
                st.error("æš‚æ— åŸå§‹æ•°æ®ï¼Œè¯·å…ˆåœ¨ä»»åŠ¡1ä¸­ä¸Šä¼ æ–‡ä»¶")
                return

        elif data_source_option == "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶":
            # ä»»åŠ¡1ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨
            task1_files = {
                "æ­¥éª¤2_è¿›è´§ä»·æ ¼å¤„ç†åæ•°æ®": "step2_price_data",
                "æ­¥éª¤3_åˆ©æ¶¦ä¿®æ­£åæ•°æ®": "step3_profit_data",
                "æ­¥éª¤4_å¼‚å¸¸ä¿®æ­£åŠåˆ©æ¶¦é‡ç®—åæ•°æ®": "step4_abnormal_data",
                "æ­¥éª¤5_MinMaxæ ‡å‡†åŒ–åæ•°æ®": "step5_minmax_data",
                "æ­¥éª¤5_ZScoreæ ‡å‡†åŒ–åæ•°æ®": "step5_zscore_data"
            }

            selected_file = st.selectbox(
                "é€‰æ‹©ä»»åŠ¡1å¤„ç†æ–‡ä»¶:",
                list(task1_files.keys()),
                key="task1_file_task4"
            )

            if selected_file and st.session_state.get(task1_files[selected_file]) is not None:
                current_data = st.session_state[task1_files[selected_file]]
                data_source = f"ä»»åŠ¡1: {selected_file}"
                st.success(f"ä½¿ç”¨{selected_file}ï¼Œå…± {len(current_data)} æ¡è®°å½•")
            else:
                st.error("é€‰æ‹©çš„æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®Œæˆä»»åŠ¡1")
                return

        else:  # ä¸Šä¼ æ–°æ–‡ä»¶
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ è¿è¥ä¼˜åŒ–æ•°æ®æ–‡ä»¶",
                type=["xlsx", "csv"],
                key="upload_task4_new"
            )

            if uploaded_file:
                try:
                    if uploaded_file.name.endswith('.xlsx'):
                        current_data = pd.read_excel(uploaded_file)
                    else:
                        current_data = pd.read_csv(uploaded_file)

                    current_data = clean_numeric_columns(current_data)
                    data_source = f"è‡ªå®šä¹‰æ–‡ä»¶: {uploaded_file.name}"
                    st.success(f"æ•°æ®åŠ è½½æˆåŠŸï¼å…± {len(current_data)} æ¡è®°å½•")
                except Exception as e:
                    st.error(f"æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")
                    return
            else:
                st.info("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶")
                return

    # æ£€æŸ¥å¿…éœ€å­—æ®µï¼ˆè¿è¥ä¼˜åŒ–éœ€è¦çš„æ ¸å¿ƒå­—æ®µï¼‰
    required_columns = ['å•†å“å“ç±»', 'é”€å”®é¢', 'åˆ©æ¶¦', 'å®é™…å”®ä»·', 'é”€å”®æ•°']
    if current_data is not None:
        missing_columns = [col for col in required_columns if col not in current_data.columns]
        if missing_columns:
            st.error(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_columns)}")
            st.info(f"è¿è¥ä¼˜åŒ–åˆ†æéœ€è¦çš„å­—æ®µ: {', '.join(required_columns)}")
            st.info("æ¨èå­—æ®µ: è¿›è´§ä»·æ ¼, åŒºåŸŸ, å®¢æˆ·æ€§åˆ«, å®¢æˆ·å¹´é¾„, æ—¥æœŸç­‰")
            return

    # æ˜¾ç¤ºæ•°æ®æºä¿¡æ¯
    if current_data is not None:
        st.success(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ - æ•°æ®æº: {data_source}")
        st.info(f"æ•°æ®ç»´åº¦: {len(current_data)} è¡Œ Ã— {len(current_data.columns)} åˆ—")

        # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
        with st.expander("ğŸ“‹ æ•°æ®é¢„è§ˆ"):
            st.dataframe(current_data.head(10))

        # æ˜¾ç¤ºå…³é”®å­—æ®µç»Ÿè®¡
        st.subheader("ğŸ“Š æ•°æ®æ¦‚è§ˆ")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            if 'å•†å“å“ç±»' in current_data.columns:
                st.metric("å•†å“å“ç±»æ•°", current_data['å•†å“å“ç±»'].nunique())
        with col2:
            if 'é”€å”®é¢' in current_data.columns:
                st.metric("æ€»é”€å”®é¢", f"Â¥{current_data['é”€å”®é¢'].sum():,.0f}")
        with col3:
            if 'åˆ©æ¶¦' in current_data.columns:
                st.metric("æ€»åˆ©æ¶¦", f"Â¥{current_data['åˆ©æ¶¦'].sum():,.0f}")
        with col4:
            if 'é”€å”®æ•°' in current_data.columns:
                st.metric("æ€»é”€å”®æ•°", f"{current_data['é”€å”®æ•°'].sum():,}")
    else:
        return
    # ============================================================================
    # ç»“æŸæ•°æ®å¯¼å…¥éƒ¨åˆ†
    # ============================================================================

    # è‡ªåŠ¨æ£€æµ‹å­—æ®µç±»å‹
    column_types = auto_detect_column_types(current_data)

    # åˆ†æé…ç½®
    st.subheader("âš™ï¸ åˆ†æé…ç½®")
    analysis_options = st.multiselect(
        "é€‰æ‹©åˆ†ææ¨¡å—:",
        [
            "ABCåˆ†ç±»åˆ†æ",
            "ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ",
            "ç”¨æˆ·åˆ†å±‚åˆ†æ",
            "åœºæ™¯ä»·æ ¼åˆ†æ",
            "ç»¼åˆæ¨¡å‹èåˆ"
        ],
        default=[
            "ABCåˆ†ç±»åˆ†æ",
            "ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ",
            "ç”¨æˆ·åˆ†å±‚åˆ†æ",
            "åœºæ™¯ä»·æ ¼åˆ†æ",
            "ç»¼åˆæ¨¡å‹èåˆ"
        ]
    )

    # æ‰§è¡Œåˆ†æ
    if st.button("ğŸš€ æ‰§è¡Œè¿è¥ä¼˜åŒ–åˆ†æ", type="primary"):
        with st.spinner("æ‰§è¡Œè¿è¥ä¼˜åŒ–åˆ†æä¸­..."):
            optimizer = Task4Optimizer(current_data, column_types)

            # æ ¹æ®é€‰æ‹©çš„æ¨¡å—æ‰§è¡Œåˆ†æ
            result_files = {}
            progress_log = []

            if "ABCåˆ†ç±»åˆ†æ" in analysis_options:
                if optimizer.abc_classification_analysis():
                    progress_log.append("âœ… ABCåˆ†ç±»åˆ†æå®Œæˆ")
                    result_files['01_ABCåˆ†ç±»ç»“æœ.xlsx'] = optimizer.results['abc_classification']
                else:
                    progress_log.append("âŒ ABCåˆ†ç±»åˆ†æå¤±è´¥")

            if "ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ" in analysis_options:
                if optimizer.price_sensitivity_analysis():
                    progress_log.append("âœ… ä»·æ ¼æ•æ„Ÿåº¦åˆ†æå®Œæˆ")
                    result_files['02_ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ.xlsx'] = optimizer.results['price_sensitivity']
                else:
                    progress_log.append("âŒ ä»·æ ¼æ•æ„Ÿåº¦åˆ†æå¤±è´¥")

            if "ç”¨æˆ·åˆ†å±‚åˆ†æ" in analysis_options:
                if optimizer.user_segmentation_analysis():
                    progress_log.append("âœ… ç”¨æˆ·åˆ†å±‚åˆ†æå®Œæˆ")
                    result_files['03_ç”¨æˆ·åˆ†å±‚åˆ†æ.xlsx'] = optimizer.results['user_segmentation']
                else:
                    progress_log.append("âŒ ç”¨æˆ·åˆ†å±‚åˆ†æå¤±è´¥")

            if "åœºæ™¯ä»·æ ¼åˆ†æ" in analysis_options:
                if optimizer.scenario_price_analysis():
                    progress_log.append("âœ… åœºæ™¯ä»·æ ¼åˆ†æå®Œæˆ")
                    result_files['04_åœºæ™¯ä»·æ ¼åˆ†æ.xlsx'] = optimizer.results['scenario_analysis']
                else:
                    progress_log.append("âŒ åœºæ™¯ä»·æ ¼åˆ†æå¤±è´¥")

            if "ç»¼åˆæ¨¡å‹èåˆ" in analysis_options:
                if optimizer.comprehensive_model_fusion():
                    progress_log.append("âœ… ç»¼åˆæ¨¡å‹èåˆå®Œæˆ")
                    result_files['05_ç»¼åˆæ•æ„Ÿåº¦è¯„ä¼°.xlsx'] = optimizer.results['comprehensive_fusion']
                    result_files['06_è¿è¥ç­–ç•¥æ¨è.xlsx'] = optimizer.results['operation_strategies']
                else:
                    progress_log.append("âŒ ç»¼åˆæ¨¡å‹èåˆå¤±è´¥")

            if result_files:
                st.session_state.task4_results = optimizer.results
                st.session_state.task4_completed = True
                st.success("âœ… è¿è¥ä¼˜åŒ–åˆ†æå®Œæˆï¼")

                # æ˜¾ç¤ºåˆ†æç»“æœ
                display_task4_results(optimizer.results, result_files, progress_log)
            else:
                st.error("è¿è¥ä¼˜åŒ–åˆ†æå¤±è´¥")
                for log in progress_log:
                    st.error(log)

    else:
        # æ˜¾ç¤ºåŠŸèƒ½è¯´æ˜
        show_task4_instructions()

def display_task4_results(results, result_files, progress_log):
    """æ˜¾ç¤ºä»»åŠ¡4åˆ†æç»“æœ"""

    # 1. æ˜¾ç¤ºåˆ†ææ—¥å¿—
    st.subheader("ğŸ“ åˆ†ææ‰§è¡Œæ—¥å¿—")
    for log in progress_log:
        st.write(f"â–ªï¸ {log}")

    # 2. ABCåˆ†ç±»åˆ†æç»“æœ
    if 'abc_classification' in results:
        st.subheader("ğŸ“Š ABCåˆ†ç±»åˆ†æ")

        col1, col2 = st.columns(2)

        with col1:
            st.dataframe(results['abc_classification'][['å•†å“å“ç±»', 'é”€å”®é¢å æ¯”%', 'åˆ©æ¶¦å æ¯”%', 'ABCåˆ†ç±»ï¼ˆé”€å”®é¢ï¼‰']])

        with col2:
            if 'abc_visualizations' in results:
                st.pyplot(results['abc_visualizations']['sales_distribution'])

        # æ˜¾ç¤ºå…¶ä»–å›¾è¡¨
        col1, col2 = st.columns(2)
        with col1:
            if 'abc_visualizations' in results:
                st.pyplot(results['abc_visualizations']['cumulative_sales'])
        with col2:
            if 'abc_visualizations' in results:
                st.pyplot(results['abc_visualizations']['abc_distribution'])

    # 3. ä»·æ ¼æ•æ„Ÿåº¦åˆ†æç»“æœ
    if 'price_sensitivity' in results:
        st.subheader("ğŸ’° ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ")

        st.dataframe(results['price_sensitivity'])

        # æ˜¾ç¤ºæ‹Ÿåˆå›¾è¡¨
        if 'fitting_charts' in results:
            st.subheader("ğŸ“ˆ ä»·æ ¼-é”€é‡å…³ç³»æ‹Ÿåˆå›¾")
            cols = st.columns(2)
            chart_count = 0

            for chart_name, fig in results['fitting_charts'].items():
                with cols[chart_count % 2]:
                    st.pyplot(fig)
                chart_count += 1

    # 4. ç”¨æˆ·åˆ†å±‚åˆ†æç»“æœ
    if 'user_segmentation' in results:
        st.subheader("ğŸ‘¥ ç”¨æˆ·åˆ†å±‚åˆ†æ")
        st.dataframe(results['user_segmentation'])

    # 5. åœºæ™¯ä»·æ ¼åˆ†æç»“æœ
    if 'scenario_analysis' in results:
        st.subheader("ğŸ·ï¸ åœºæ™¯ä»·æ ¼åˆ†æ")
        st.dataframe(results['scenario_analysis'])

    # 6. ç»¼åˆæ¨¡å‹èåˆç»“æœ
    if 'comprehensive_fusion' in results:
        st.subheader("ğŸ¯ ç»¼åˆæ•æ„Ÿåº¦è¯„ä¼°")
        st.dataframe(results['comprehensive_fusion'])

    # 7. è¿è¥ç­–ç•¥æ¨è
    if 'operation_strategies' in results:
        st.subheader("ğŸš€ å¯æ‰§è¡Œè¿è¥ç­–ç•¥")

        # æŒ‰ä¼˜å…ˆçº§ç­›é€‰
        priority_filter = st.selectbox("ç­›é€‰ç­–ç•¥ä¼˜å…ˆçº§:", ["å…¨éƒ¨", "é«˜", "ä¸­"])

        if priority_filter != "å…¨éƒ¨":
            filtered_strategies = results['operation_strategies'][
                results['operation_strategies']['ä¼˜å…ˆçº§'] == priority_filter]
        else:
            filtered_strategies = results['operation_strategies']

        st.dataframe(filtered_strategies)

    # 8. æ–‡ä»¶ä¸‹è½½
    st.subheader("ğŸ“¥ åˆ†æç»“æœä¸‹è½½")
    for filename, data in result_files.items():
        excel_bytes = io.BytesIO()
        with pd.ExcelWriter(excel_bytes, engine='openpyxl') as writer:
            data.to_excel(writer, index=False)
        st.download_button(
            label=f"ä¸‹è½½ {filename}",
            data=excel_bytes.getvalue(),
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )


def show_task4_instructions():
    """æ˜¾ç¤ºä»»åŠ¡4åŠŸèƒ½è¯´æ˜"""
    st.info("""
    **ğŸ“‹ è¿è¥ç­–ç•¥ä¼˜åŒ–åŠŸèƒ½è¯´æ˜**

    **æ ¸å¿ƒåˆ†ææ¨¡å—ï¼š**

    **ğŸ“Š ABCåˆ†ç±»åˆ†æ**
    - åŸºäºå¸•ç´¯æ‰˜æ³•åˆ™ï¼ˆ20/80å®šå¾‹ï¼‰å¯¹å•†å“å“ç±»è¿›è¡Œåˆ†ç±»
    - Aç±»ï¼ˆæ ¸å¿ƒï¼‰ï¼šé”€å”®é¢ç´¯è®¡å æ¯”å‰70%
    - Bç±»ï¼ˆæ½œåŠ›ï¼‰ï¼šé”€å”®é¢ç´¯è®¡å æ¯”70%-90%  
    - Cç±»ï¼ˆé•¿å°¾ï¼‰ï¼šå‰©ä½™10%
    - è¾“å‡ºï¼šåˆ†ç±»ç»“æœã€å¯è§†åŒ–å›¾è¡¨ã€èµ„æºåˆ†é…å»ºè®®

    **ğŸ’° ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ**
    - é€šè¿‡"ä»·æ ¼-é”€é‡"å…³ç³»åˆ†æå„å“ç±»çš„ä»·æ ¼å¼¹æ€§
    - ä½¿ç”¨ç­‰é¢‘8åŒºé—´åˆ’åˆ†å’Œçº¿æ€§å›å½’åˆ†æ
    - è®¡ç®—ä»·æ ¼å¼¹æ€§ç³»æ•°Sï¼Œåˆ¤å®šæ•æ„Ÿåº¦ç­‰çº§
    - è¾“å‡ºï¼šæ•æ„Ÿåº¦ç³»æ•°ã€æ‹Ÿåˆå›¾è¡¨ã€å®šä»·å»ºè®®

    **ğŸ‘¥ ç”¨æˆ·åˆ†å±‚åˆ†æ**  
    - åŸºäºå¹´é¾„å’Œæ€§åˆ«å¯¹ç”¨æˆ·è¿›è¡Œåˆ†å±‚
    - è®¡ç®—ä»·æ ¼æ¥å—åº¦(R1)ã€é›†ä¸­åº¦(R2)ã€æ•æ„Ÿå€¾å‘æŒ‡æ•°(R3)
    - å»ºç«‹ç”¨æˆ·ä»·æ ¼åå¥½åˆ¤å®šçŸ©é˜µ
    - è¾“å‡ºï¼šåˆ†å±‚ç»“æœã€ä»·æ ¼åå¥½ç‰¹å¾

    **ğŸ·ï¸ åœºæ™¯ä»·æ ¼åˆ†æ**
    - å°†å•†å“æ˜ å°„åˆ°æ¶ˆè´¹åœºæ™¯ï¼ˆåŠå…¬ã€å®¶å±…ã€å¨æˆ¿ã€æ±½è½¦ï¼‰
    - åˆ†æå„åœºæ™¯çš„ä»·æ ¼å¸¦åˆ†å¸ƒ
    - è®¡ç®—åœºæ™¯ä»·æ ¼æ•æ„Ÿåº¦æŒ‡æ•°(SI)
    - è¾“å‡ºï¼šåœºæ™¯ä»·æ ¼å¸¦ã€æ•æ„Ÿåº¦æŒ‡æ•°

    **ğŸ¯ ç»¼åˆæ¨¡å‹èåˆ**
    - ä½¿ç”¨AHPå±‚æ¬¡åˆ†ææ³•èåˆå¤šç»´åº¦åˆ†æç»“æœ
    - æƒé‡åˆ†é…ï¼šå“ç±»(66%)ã€äººç¾¤(23%)ã€åœºæ™¯(12%)
    - ç”Ÿæˆç»¼åˆæ•æ„Ÿåº¦å¾—åˆ†å’Œç­‰çº§
    - è¾“å‡ºï¼šç»¼åˆè¯„ä¼°ã€è¿è¥ç­–ç•¥æ¨è

    **ğŸš€ ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®å¼€å§‹åˆ†æï¼**
    """)

def show_system_status():
    """ç³»ç»ŸçŠ¶æ€é¡µé¢"""
    st.header("ğŸ”§ ç³»ç»ŸçŠ¶æ€")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ä»»åŠ¡å®ŒæˆçŠ¶æ€")
        tasks = [
            ("æ•°æ®é¢„å¤„ç†", st.session_state.task1_completed),
            ("å¤šç»´ç‰¹å¾åˆ†æ", st.session_state.task2_completed),
            ("é”€å”®é¢„æµ‹", st.session_state.task3_completed),
            ("è¿è¥ä¼˜åŒ–", st.session_state.task4_completed)
        ]
        for task_name, completed in tasks:
            status_class = "status-completed" if completed else "status-pending"
            icon = "âœ…" if completed else "â³"
            st.markdown(f'<div class="{status_class}">{icon} {task_name}</div>', unsafe_allow_html=True)

    with col2:
        st.subheader("æ•°æ®çŠ¶æ€")
        if st.session_state.raw_data is not None:
            df = st.session_state.raw_data
            total_records = len(df)
            total_cols = len(df.columns)
            numeric_cols = len(st.session_state.column_types['numeric']) if st.session_state.column_types else 0
            category_cols = len(st.session_state.column_types['nominal']) + len(
                st.session_state.column_types['ordinal']) if st.session_state.column_types else 0

            st.metric("æ€»è®°å½•æ•°", f"{total_records:,}æ¡")
            st.metric("æ€»å­—æ®µæ•°", f"{total_cols}ä¸ª")
            st.metric("æ•°å€¼å‹å­—æ®µ", f"{numeric_cols}ä¸ª")
            st.metric("åˆ†ç±»å‹å­—æ®µ", f"{category_cols}ä¸ª")
        else:
            st.info("æš‚æ— æ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œ'æ•°æ®é¢„å¤„ç†'")

    # é‡ç½®åŠŸèƒ½
    if st.button("ğŸ”„ é‡ç½®ç³»ç»Ÿ", type="secondary"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        initialize_session_state()
        st.rerun()


# ============================================================================
# å…¶ä»–ç°æœ‰å‡½æ•°ï¼ˆEnhancedTask2Analyzerã€show_python_visualizationsã€show_data_export_interfaceç­‰ï¼‰
# ============================================================================

# åœ¨è¿™é‡Œæ·»åŠ ä¼˜åŒ–åçš„äº¤äº’å¼ä»ªè¡¨æ¿å‡½æ•°
def show_interactive_dashboard_optimized(visualizer_results):
    """ä¼˜åŒ–ç‰ˆçš„äº¤äº’å¼å¯è§†åŒ–ä»ªè¡¨æ¿"""

    # é¡¶éƒ¨æŒ‡æ ‡å¡ç‰‡
    st.markdown("### ğŸ“Š å®æ—¶ä¸šåŠ¡æŒ‡æ ‡")
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("æ€»é”€å”®é¢", "Â¥1,234,567", "+12%")
    with col2:
        st.metric("æ€»åˆ©æ¶¦", "Â¥456,789", "+8%")
    with col3:
        st.metric("è®¢å•æ•°é‡", "12,345", "+5%")
    with col4:
        st.metric("å®¢æˆ·æ•°é‡", "8,765", "+15%")

    # ä¸»è¦åˆ†æåŒºåŸŸ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ é”€å”®åˆ†æ", "ğŸ‘¥ å®¢æˆ·åˆ†æ", "ğŸ—ºï¸ åœ°åŸŸåˆ†æ", "ğŸ” é«˜çº§åˆ†æ"])

    with tab1:
        col_sales1, col_sales2 = st.columns(2)
        with col_sales1:
            if 'interactive_dashboard' in visualizer_results and 'sales_trend' in visualizer_results[
                'interactive_dashboard']:
                st.plotly_chart(visualizer_results['interactive_dashboard']['sales_trend'],
                                use_container_width=True)
        with col_sales2:
            if 'interactive_dashboard' in visualizer_results and 'category_bar' in visualizer_results[
                'interactive_dashboard']:
                st.plotly_chart(visualizer_results['interactive_dashboard']['category_bar'],
                                use_container_width=True)

    with tab2:
        col_cust1, col_cust2 = st.columns(2)
        with col_cust1:
            if 'interactive_dashboard' in visualizer_results and 'demographic_scatter' in visualizer_results[
                'interactive_dashboard']:
                st.plotly_chart(visualizer_results['interactive_dashboard']['demographic_scatter'],
                                use_container_width=True)
        with col_cust2:
            if 'customer_segmentation' in visualizer_results and 'customer_clusters' in visualizer_results[
                'customer_segmentation']:
                st.plotly_chart(visualizer_results['customer_segmentation']['customer_clusters'],
                                use_container_width=True)

    with tab3:
        if 'interactive_dashboard' in visualizer_results and 'region_bar' in visualizer_results[
            'interactive_dashboard']:
            st.plotly_chart(visualizer_results['interactive_dashboard']['region_bar'],
                            use_container_width=True)

    with tab4:
        col_adv1, col_adv2 = st.columns(2)
        with col_adv1:
            if 'advanced_analytics' in visualizer_results and 'correlation_heatmap' in visualizer_results[
                'advanced_analytics']:
                st.plotly_chart(visualizer_results['advanced_analytics']['correlation_heatmap'],
                                use_container_width=True)
        with col_adv2:
            if 'advanced_analytics' in visualizer_results and 'box_plot' in visualizer_results['advanced_analytics']:
                st.plotly_chart(visualizer_results['advanced_analytics']['box_plot'],
                                use_container_width=True)


def show_project_overview_optimized():
    """ä¼˜åŒ–ç‰ˆé¡¹ç›®æ¦‚è§ˆé¡µé¢"""
    st.markdown("### ğŸ¯ ç³»ç»ŸåŠŸèƒ½æ¦‚è¿°")

    # åŠŸèƒ½ç‰¹æ€§å¡ç‰‡
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        <div class="feature-card">
            <h3>ğŸ“ æ™ºèƒ½æ•°æ®é¢„å¤„ç†</h3>
            <p>æŒ‰è®ºæ–‡è¦æ±‚è‡ªåŠ¨ç”Ÿæˆ6ä¸ªæ ‡å‡†åŒ–è¾“å‡ºæ–‡ä»¶ï¼Œæ”¯æŒç¼ºå¤±å€¼å¤„ç†ã€å¼‚å¸¸ä¿®æ­£ã€æ ‡å‡†åŒ–ç­‰å®Œæ•´æµç¨‹</p>
            <ul>
                <li>ç¼ºå¤±å€¼ç»Ÿè®¡åˆ†æ</li>
                <li>è¿›è´§ä»·æ ¼å¤„ç†</li>
                <li>åˆ©æ¶¦è‡ªåŠ¨ä¿®æ­£</li>
                <li>å¼‚å¸¸å€¼æ£€æµ‹ä¿®æ­£</li>
                <li>MinMax/ZScoreæ ‡å‡†åŒ–</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div class="feature-card">
            <h3>ğŸ” å¤šç»´ç‰¹å¾åˆ†æ</h3>
            <p>æ”¯æŒå¤šç§æ•°æ®æºï¼Œæä¾›äº¤äº’å¼å¯è§†åŒ–åˆ†æï¼Œæ·±åº¦æŒ–æ˜ä¸šåŠ¡æ´å¯Ÿ</p>
            <ul>
                <li>åœ°ç†åˆ†å¸ƒåˆ†æ</li>
                <li>å®¢æˆ·ç”»åƒåˆ†æ</li>
                <li>æ—¶é—´åºåˆ—åˆ†æ</li>
                <li>äº¤å‰ç»´åº¦çƒ­åŠ›å›¾</li>
                <li>èšç±»åˆ†æ</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        st.markdown("""
        <div class="feature-card">
            <h3>ğŸ“ˆ æ™ºèƒ½é¢„æµ‹ä¼˜åŒ–</h3>
            <p>åŸºäºæœºå™¨å­¦ä¹ çš„æ—¶é—´åºåˆ—é¢„æµ‹å’Œè¿è¥ç­–ç•¥ä¼˜åŒ–</p>
            <ul>
                <li>ARIMA-XGBoostæ··åˆé¢„æµ‹</li>
                <li>ABCåˆ†ç±»åˆ†æ</li>
                <li>ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ</li>
                <li>å¯è½åœ°è¿è¥ç­–ç•¥</li>
                <li>å®æ—¶æŒ‡æ ‡ç›‘æ§</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    # å…³é”®æŒ‡æ ‡
    st.markdown("### ğŸ“Š ç³»ç»ŸæŒ‡æ ‡")
    metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)

    with metric_col1:
        st.markdown("""
        <div class="metric-card">
            <div style="font-size: 2rem;">6</div>
            <div>æ ‡å‡†è¾“å‡ºæ–‡ä»¶</div>
        </div>
        """, unsafe_allow_html=True)

    with metric_col2:
        st.markdown("""
        <div class="metric-card">
            <div style="font-size: 2rem;">4</div>
            <div>åˆ†æä»»åŠ¡</div>
        </div>
        """, unsafe_allow_html=True)

    with metric_col3:
        st.markdown("""
        <div class="metric-card">
            <div style="font-size: 2rem;">ğŸ“Š</div>
            <div>äº¤äº’å¼å¯è§†åŒ–</div>
        </div>
        """, unsafe_allow_html=True)

    with metric_col4:
        st.markdown("""
        <div class="metric-card">
            <div style="font-size: 2rem;">ğŸ¯</div>
            <div>æ™ºèƒ½é¢„æµ‹</div>
        </div>
        """, unsafe_allow_html=True)

    # ä½¿ç”¨æŒ‡å—
    st.markdown("### ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—")

    guide_col1, guide_col2 = st.columns(2)

    with guide_col1:
        st.markdown("""
        **1. æ•°æ®é¢„å¤„ç†**
        - ç‚¹å‡»"æ•°æ®é¢„å¤„ç†"æŒ‰é’®
        - ä¸Šä¼ Excel/CSVæ–‡ä»¶
        - ç³»ç»Ÿè‡ªåŠ¨æ‰§è¡Œ6æ­¥é¢„å¤„ç†
        - ä¸‹è½½æ ‡å‡†åŒ–è¾“å‡ºæ–‡ä»¶

        **2. å¤šç»´ç‰¹å¾åˆ†æ**  
        - é€‰æ‹©é¢„å¤„ç†æ•°æ®æˆ–ä¸Šä¼ æ–°æ–‡ä»¶
        - é€‰æ‹©åˆ†ææ¨¡å¼ï¼ˆå¯è§†åŒ–/å¯¼å‡º/ä»ªè¡¨æ¿ï¼‰
        - æŸ¥çœ‹äº¤äº’å¼åˆ†æç»“æœ
        """)

    with guide_col2:
        st.markdown("""
        **3. é”€å”®é¢„æµ‹åˆ†æ**
        - å¯¼å…¥æ—¶é—´åºåˆ—æ•°æ®
        - æ‰§è¡ŒARIMA-XGBoosté¢„æµ‹
        - æŸ¥çœ‹é¢„æµ‹ç»“æœå’Œç²¾åº¦

        **4. è¿è¥ç­–ç•¥ä¼˜åŒ–**
        - ABCå•†å“åˆ†ç±»åˆ†æ
        - ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ
        - ç”Ÿæˆå¯è½åœ°è¿è¥ç­–ç•¥
        """)


def task1_data_preprocessing_optimized():
    """ä¼˜åŒ–ç‰ˆæ•°æ®é¢„å¤„ç†é¡µé¢"""
    st.markdown("### ğŸ“ ä»»åŠ¡1: æ•°æ®é¢„å¤„ç†")

    # åŠŸèƒ½è¯´æ˜å¡ç‰‡
    st.markdown("""
    <div class="feature-card">
        <h3>ğŸ¯ è®ºæ–‡æ ‡å‡†è¾“å‡º</h3>
        <p>æŒ‰è®ºæ–‡è¦æ±‚è‡ªåŠ¨ç”Ÿæˆ6ä¸ªæ ‡å‡†åŒ–Excelæ–‡ä»¶ï¼Œå®Œæ•´çš„æ•°æ®é¢„å¤„ç†æµç¨‹</p>
    </div>
    """, unsafe_allow_html=True)

    # æ­¥éª¤è¯´æ˜
    steps_col1, steps_col2, steps_col3 = st.columns(3)

    with steps_col1:
        st.markdown("""
        **æ­¥éª¤1-2: æ•°æ®æ¸…æ´—**
        - ç¼ºå¤±å€¼ç»Ÿè®¡åˆ†æ
        - è¿›è´§ä»·æ ¼æ ¼å¼æ ‡å‡†åŒ–
        - æ•°æ®ç±»å‹è‡ªåŠ¨æ£€æµ‹
        """)

    with steps_col2:
        st.markdown("""
        **æ­¥éª¤3-4: ä¸šåŠ¡é€»è¾‘ä¿®æ­£**
        - åˆ©æ¶¦è®¡ç®—é”™è¯¯ä¿®æ­£
        - å¼‚å¸¸å”®ä»·æ£€æµ‹ä¿®å¤
        - åˆ©æ¶¦é‡æ–°è®¡ç®—
        """)

    with steps_col3:
        st.markdown("""
        **æ­¥éª¤5: æ•°æ®æ ‡å‡†åŒ–**
        - MinMaxæ ‡å‡†åŒ–(0-1)
        - ZScoreæ ‡å‡†åŒ–
        - åˆ†ç±»å˜é‡ç¼–ç 
        """)

    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.markdown("### ğŸ“¤ æ•°æ®ä¸Šä¼ ")
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ åŸå§‹æ•°æ®è¡¨ï¼ˆæ”¯æŒExcelæˆ–CSVæ ¼å¼ï¼‰",
        type=["xlsx", "csv"],
        help="å»ºè®®åŒ…å«ï¼šå•†å“å“ç±»ã€åŒºåŸŸã€é”€å”®é¢ã€åˆ©æ¶¦ã€æ—¥æœŸç­‰å­—æ®µ"
    )

    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.xlsx'):
                df = pd.read_excel(uploaded_file)
            else:
                df = pd.read_csv(uploaded_file)

            # æ•°æ®æ¸…æ´—
            df_clean = clean_numeric_columns(df)
            st.session_state.raw_data = df_clean
            st.session_state.current_file = uploaded_file.name

            # æ•°æ®é¢„è§ˆ
            st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼å…± {len(df)} æ¡è®°å½•ï¼Œ{len(df.columns)} ä¸ªå­—æ®µ")

            col_preview1, col_preview2 = st.columns(2)
            with col_preview1:
                st.markdown("**åŸå§‹æ•°æ®é¢„è§ˆ**")
                st.dataframe(df.head(), use_container_width=True)
            with col_preview2:
                st.markdown("**æ¸…æ´—åæ•°æ®é¢„è§ˆ**")
                st.dataframe(df_clean.head(), use_container_width=True)

            # æ‰§è¡Œé¢„å¤„ç†æŒ‰é’®
            st.markdown("### ğŸš€ æ‰§è¡Œé¢„å¤„ç†")
            if st.button("å¼€å§‹æ•°æ®é¢„å¤„ç†ï¼ˆç”Ÿæˆ6ä¸ªæ ‡å‡†æ–‡ä»¶ï¼‰", type="primary", use_container_width=True):
                with st.spinner("æ­£åœ¨æ‰§è¡Œæ•°æ®é¢„å¤„ç†æµç¨‹..."):
                    preprocessor = Task1Preprocessor(df_clean)
                    result_files, progress_log, final_data, encoders, column_types = preprocessor.generate_all_results()

                    if result_files:
                        # ä¿å­˜ç»“æœåˆ°session state
                        st.session_state.step1_missing_data = result_files['ç”µå•† æ­¥éª¤1 ç¼ºå¤±å€¼ç»Ÿè®¡ç»“æœ.xlsx']
                        st.session_state.step2_price_data = result_files['ç”µå•† æ­¥éª¤2 è¿›è´§ä»·æ ¼å¤„ç†åæ•°æ®.xlsx']
                        st.session_state.step3_profit_data = result_files['ç”µå•† æ­¥éª¤3 åˆ©æ¶¦ä¿®æ­£åæ•°æ®.xlsx']
                        st.session_state.step4_abnormal_data = result_files['ç”µå•† æ­¥éª¤4 å¼‚å¸¸ä¿®æ­£åŠåˆ©æ¶¦é‡ç®—åæ•°æ®.xlsx']
                        st.session_state.step5_minmax_data = result_files['ç”µå•† æ­¥éª¤5 MinMaxæ ‡å‡†åŒ–åæ•°æ®.xlsx']
                        st.session_state.step5_zscore_data = result_files['ç”µå•† æ­¥éª¤5 ZScoreæ ‡å‡†åŒ–åæ•°æ®.xlsx']
                        st.session_state.processed_data = final_data
                        st.session_state.category_encoder = encoders
                        st.session_state.column_types = column_types
                        st.session_state.task1_completed = True

                        st.success("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼")

                        # ç»“æœæ˜¾ç¤º
                        st.markdown("### ğŸ“Š é¢„å¤„ç†ç»“æœ")

                        # è¿›åº¦æ—¥å¿—
                        st.markdown("**æ‰§è¡Œæ—¥å¿—:**")
                        for log in progress_log:
                            st.write(f"â–ªï¸ {log}")

                        # æ–‡ä»¶ä¸‹è½½
                        st.markdown("### ğŸ“¥ ä¸‹è½½æ ‡å‡†æ–‡ä»¶")
                        download_col1, download_col2 = st.columns(2)

                        with download_col1:
                            for i, (filename, data) in enumerate(list(result_files.items())[:3]):
                                if isinstance(data, pd.DataFrame):
                                    excel_bytes = io.BytesIO()
                                    with pd.ExcelWriter(excel_bytes, engine='openpyxl') as writer:
                                        data.to_excel(writer, index=False)
                                    st.download_button(
                                        label=f"ä¸‹è½½ {filename}",
                                        data=excel_bytes.getvalue(),
                                        file_name=filename,
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                        use_container_width=True
                                    )

                        with download_col2:
                            for i, (filename, data) in enumerate(list(result_files.items())[3:]):
                                if isinstance(data, pd.DataFrame):
                                    excel_bytes = io.BytesIO()
                                    with pd.ExcelWriter(excel_bytes, engine='openpyxl') as writer:
                                        data.to_excel(writer, index=False)
                                    st.download_button(
                                        label=f"ä¸‹è½½ {filename}",
                                        data=excel_bytes.getvalue(),
                                        file_name=filename,
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                        use_container_width=True
                                    )

        except Exception as e:
            st.error(f"âŒ æ–‡ä»¶å¤„ç†é”™è¯¯: {str(e)}")
    else:
        st.info("ğŸ“ è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶å¼€å§‹é¢„å¤„ç†æµç¨‹")


def task3_sales_forecast_optimized():
    """ä¼˜åŒ–ç‰ˆé”€å”®é¢„æµ‹é¡µé¢"""
    st.markdown("### ğŸ“ˆ ä»»åŠ¡3: é”€å”®é¢„æµ‹åˆ†æ")

    # åŠŸèƒ½è¯´æ˜
    st.markdown("""
    <div class="feature-card">
        <h3>ğŸ¯ ARIMA-XGBoostæ··åˆé¢„æµ‹</h3>
        <p>ä½¿ç”¨æ—¶é—´åºåˆ—åˆ†æ+æœºå™¨å­¦ä¹ è¿›è¡Œç²¾å‡†é”€å”®é¢„æµ‹ï¼Œæ”¯æŒå¤šç»´åº¦ç‰¹å¾å·¥ç¨‹</p>
    </div>
    """, unsafe_allow_html=True)

    # é¢„æµ‹æµç¨‹è¯´æ˜
    forecast_col1, forecast_col2 = st.columns(2)

    with forecast_col1:
        st.markdown("""
        **ğŸ“Š é¢„æµ‹æ¨¡å‹ç‰¹ç‚¹**
        - ARIMAæ•æ‰æ—¶é—´åºåˆ—è¶‹åŠ¿
        - XGBoostå­¦ä¹ æ®‹å·®æ¨¡å¼
        - å¤šç»´åº¦ç‰¹å¾å·¥ç¨‹
        - è‡ªåŠ¨å‚æ•°ä¼˜åŒ–
        """)

    with forecast_col2:
        st.markdown("""
        **ğŸ¯ é¢„æµ‹è¾“å‡º**
        - æœªæ¥é”€å”®è¶‹åŠ¿é¢„æµ‹
        - é¢„æµ‹ç²¾åº¦è¯„ä¼°(MAPE)
        - ç‰¹å¾é‡è¦æ€§åˆ†æ
        - å¯è§†åŒ–é¢„æµ‹ç»“æœ
        """)

    if not st.session_state.get('task1_completed', False):
        st.warning("âš ï¸ å»ºè®®å…ˆå®Œæˆæ•°æ®é¢„å¤„ç†ï¼ˆä»»åŠ¡1ï¼‰ä»¥è·å¾—æ›´å¥½çš„æ•°æ®è´¨é‡")

    # æ•°æ®æºé€‰æ‹©
    st.markdown("### ğŸ“ é¢„æµ‹æ•°æ®å‡†å¤‡")
    data_source = st.radio(
        "é€‰æ‹©é¢„æµ‹æ•°æ®æº:",
        ["ä½¿ç”¨é¢„å¤„ç†æ•°æ®", "ä¸Šä¼ æ–°æ•°æ®æ–‡ä»¶"],
        horizontal=True
    )

    df = None
    if data_source == "ä½¿ç”¨é¢„å¤„ç†æ•°æ®" and st.session_state.get('processed_data') is not None:
        df = st.session_state.processed_data
        st.success(f"âœ… ä½¿ç”¨é¢„å¤„ç†æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
    else:
        uploaded_file = st.file_uploader("ä¸Šä¼ é¢„æµ‹æ•°æ®æ–‡ä»¶", type=["xlsx", "csv"])
        if uploaded_file:
            try:
                if uploaded_file.name.endswith('.xlsx'):
                    df = pd.read_excel(uploaded_file)
                else:
                    df = pd.read_csv(uploaded_file)
                df = clean_numeric_columns(df)
                st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼å…± {len(df)} æ¡è®°å½•")
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")

    # æ‰§è¡Œé¢„æµ‹
    if df is not None:
        st.markdown("### ğŸš€ æ‰§è¡Œé”€å”®é¢„æµ‹")

        # é¢„æµ‹å‚æ•°è®¾ç½®
        with st.expander("âš™ï¸ é¢„æµ‹å‚æ•°è®¾ç½®", expanded=False):
            param_col1, param_col2 = st.columns(2)
            with param_col1:
                forecast_days = st.slider("é¢„æµ‹å¤©æ•°", 7, 30, 14)
                confidence_level = st.slider("ç½®ä¿¡æ°´å¹³", 0.8, 0.99, 0.95)
            with param_col2:
                model_type = st.selectbox("æ¨¡å‹ç±»å‹", ["ARIMA-XGBoostæ··åˆ", "çº¯ARIMA", "çº¯XGBoost"])
                include_features = st.multiselect("åŒ…å«ç‰¹å¾", ["é”€å”®é¢", "é”€å”®æ•°", "å­£èŠ‚å› ç´ ", "ä¿ƒé”€æ´»åŠ¨"])

        if st.button("å¼€å§‹é”€å”®é¢„æµ‹", type="primary", use_container_width=True):
            with st.spinner("ğŸ”„ æ­£åœ¨è®­ç»ƒé¢„æµ‹æ¨¡å‹..."):
                column_types = auto_detect_column_types(df)
                forecaster = Task3Forecaster(df, column_types)
                result_files, progress_log = forecaster.generate_all_results()

                if result_files:
                    st.session_state.task3_results = forecaster.results
                    st.session_state.task3_completed = True

                    st.success("âœ… é”€å”®é¢„æµ‹å®Œæˆï¼")

                    # é¢„æµ‹ç»“æœå±•ç¤º
                    st.markdown("### ğŸ“Š é¢„æµ‹ç»“æœ")

                    # å…³é”®æŒ‡æ ‡
                    if 'mape' in forecaster.results:
                        mape = forecaster.results['mape']
                        metric_col1, metric_col2, metric_col3 = st.columns(3)
                        with metric_col1:
                            st.metric("é¢„æµ‹ç²¾åº¦(MAPE)", f"{mape:.2f}%")
                        with metric_col2:
                            best_error = forecaster.results['detailed_results']['ç›¸å¯¹è¯¯å·®(%)'].min()
                            st.metric("æœ€ä½³é¢„æµ‹", f"{best_error:.1f}%")
                        with metric_col3:
                            st.metric("é¢„æµ‹å¤©æ•°", forecast_days)

                    # å¯è§†åŒ–ç»“æœ
                    if 'visualizations' in forecaster.results:
                        viz = forecaster.results['visualizations']
                        tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ é¢„æµ‹å¯¹æ¯”", "ğŸ“Š è¯¯å·®åˆ†æ", "ğŸ” ç‰¹å¾é‡è¦æ€§"])

                        with tab1:
                            st.plotly_chart(viz['main_forecast'], use_container_width=True)
                        with tab2:
                            st.plotly_chart(viz['error_analysis'], use_container_width=True)
                        with tab3:
                            st.plotly_chart(viz['feature_importance'], use_container_width=True)

                    # ä¸‹è½½ç»“æœ
                    st.markdown("### ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ")
                    for filename, data in result_files.items():
                        if isinstance(data, pd.DataFrame):
                            excel_bytes = io.BytesIO()
                            with pd.ExcelWriter(excel_bytes, engine='openpyxl') as writer:
                                data.to_excel(writer, index=False)
                            st.download_button(
                                label=f"ä¸‹è½½ {filename}",
                                data=excel_bytes.getvalue(),
                                file_name=filename,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )


def task4_operation_optimization_optimized():
    """ä¼˜åŒ–ç‰ˆè¿è¥ä¼˜åŒ–é¡µé¢"""
    st.markdown("### ğŸ’¡ ä»»åŠ¡4: è¿è¥ç­–ç•¥ä¼˜åŒ–")

    # åŠŸèƒ½è¯´æ˜
    st.markdown("""
    <div class="feature-card">
        <h3>ğŸ¯ æ•°æ®é©±åŠ¨çš„è¿è¥å†³ç­–</h3>
        <p>åŸºäºæ•°æ®åˆ†æç”Ÿæˆå¯è½åœ°çš„è¿è¥ç­–ç•¥ï¼Œæå‡é”€å”®æ•ˆç‡å’Œåˆ©æ¶¦ç‡</p>
    </div>
    """, unsafe_allow_html=True)

    # åˆ†æç»´åº¦è¯´æ˜
    analysis_col1, analysis_col2, analysis_col3 = st.columns(3)

    with analysis_col1:
        st.markdown("""
        **ğŸ“Š ABCåˆ†ç±»åˆ†æ**
        - å•†å“å“ç±»ä»·å€¼åˆ†çº§
        - åŒºåŸŸé”€å”®è´¡çŒ®åˆ†æ
        - èµ„æºä¼˜åŒ–é…ç½®å»ºè®®
        """)

    with analysis_col2:
        st.markdown("""
        **ğŸ’° ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ**
        - å“ç±»ä»·æ ¼å¼¹æ€§æµ‹ç®—
        - å®¢æˆ·ç¾¤ä½“ä»·æ ¼æ•æ„Ÿåº¦
        - æœ€ä¼˜å®šä»·ç­–ç•¥æ¨è
        """)

    with analysis_col3:
        st.markdown("""
        **ğŸš€ è¿è¥ç­–ç•¥ç”Ÿæˆ**
        - åº“å­˜ç®¡ç†ç­–ç•¥
        - ä¿ƒé”€æ´»åŠ¨å»ºè®®
        - å®¢æˆ·å…³ç³»ä¼˜åŒ–
        """)

    if not st.session_state.get('task1_completed', False):
        st.warning("âš ï¸ å»ºè®®å…ˆå®Œæˆæ•°æ®é¢„å¤„ç†ï¼ˆä»»åŠ¡1ï¼‰")

    # æ•°æ®æºé€‰æ‹©
    st.markdown("### ğŸ“ è¿è¥åˆ†ææ•°æ®")
    data_source = st.radio(
        "é€‰æ‹©åˆ†ææ•°æ®æº:",
        ["ä½¿ç”¨é¢„å¤„ç†æ•°æ®", "ä¸Šä¼ æ–°æ•°æ®æ–‡ä»¶"],
        horizontal=True
    )

    df = None
    if data_source == "ä½¿ç”¨é¢„å¤„ç†æ•°æ®" and st.session_state.get('processed_data') is not None:
        df = st.session_state.processed_data
        st.success(f"âœ… ä½¿ç”¨é¢„å¤„ç†æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
    else:
        uploaded_file = st.file_uploader("ä¸Šä¼ è¿è¥åˆ†ææ•°æ®", type=["xlsx", "csv"])
        if uploaded_file:
            try:
                if uploaded_file.name.endswith('.xlsx'):
                    df = pd.read_excel(uploaded_file)
                else:
                    df = pd.read_csv(uploaded_file)
                df = clean_numeric_columns(df)
                st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼å…± {len(df)} æ¡è®°å½•")
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")

    # æ‰§è¡Œè¿è¥åˆ†æ
    if df is not None:
        st.markdown("### ğŸš€ æ‰§è¡Œè¿è¥ä¼˜åŒ–åˆ†æ")

        # åˆ†æé€‰é¡¹
        with st.expander("âš™ï¸ åˆ†æé€‰é¡¹è®¾ç½®", expanded=False):
            option_col1, option_col2 = st.columns(2)
            with option_col1:
                abc_analysis = st.checkbox("ABCåˆ†ç±»åˆ†æ", value=True)
                price_sensitivity = st.checkbox("ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ", value=True)
            with option_col2:
                customer_segmentation = st.checkbox("å®¢æˆ·åˆ†ç¾¤åˆ†æ")
                strategy_generation = st.checkbox("ç­–ç•¥ç”Ÿæˆ", value=True)

        if st.button("å¼€å§‹è¿è¥ä¼˜åŒ–åˆ†æ", type="primary", use_container_width=True):
            with st.spinner("ğŸ”„ æ­£åœ¨æ‰§è¡Œè¿è¥åˆ†æ..."):
                column_types = auto_detect_column_types(df)
                optimizer = Task4Optimizer(df, column_types)
                result_files, progress_log = optimizer.generate_all_results()

                if result_files:
                    st.session_state.task4_results = optimizer.results
                    st.session_state.task4_completed = True

                    st.success("âœ… è¿è¥ä¼˜åŒ–åˆ†æå®Œæˆï¼")

                    # åˆ†æç»“æœå±•ç¤º
                    st.markdown("### ğŸ“Š åˆ†æç»“æœ")

                    # ABCåˆ†ç±»ç»“æœ
                    if 'category_abc' in optimizer.results:
                        st.markdown("#### ğŸ“ˆ ABCå•†å“åˆ†ç±»")
                        abc_data = optimizer.results['category_abc']

                        col_abc1, col_abc2 = st.columns(2)
                        with col_abc1:
                            # åˆ†ç±»ç»Ÿè®¡
                            abc_counts = abc_data['ABCåˆ†ç±»ï¼ˆæŒ‰é”€å”®é¢ï¼‰'].value_counts()
                            fig_abc = px.pie(
                                values=abc_counts.values,
                                names=abc_counts.index,
                                title="ABCåˆ†ç±»å æ¯”"
                            )
                            st.plotly_chart(fig_abc, use_container_width=True)

                        with col_abc2:
                            st.dataframe(abc_data[['å•†å“å“ç±»', 'é”€å”®é¢', 'åˆ©æ¶¦', 'ABCåˆ†ç±»ï¼ˆæŒ‰é”€å”®é¢ï¼‰']].head(10))

                    # ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ
                    if 'price_sensitivity' in optimizer.results:
                        st.markdown("#### ğŸ’° ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ")
                        sensitivity_data = optimizer.results['price_sensitivity']
                        st.dataframe(sensitivity_data)

                    # è¿è¥ç­–ç•¥
                    if 'operation_strategy' in optimizer.results:
                        st.markdown("#### ğŸš€ è¿è¥ç­–ç•¥æ¨è")
                        strategy_data = optimizer.results['operation_strategy']

                        tab_strategy1, tab_strategy2, tab_strategy3 = st.tabs(["é«˜ä¼˜å…ˆçº§", "ä¸­ä¼˜å…ˆçº§", "ä½ä¼˜å…ˆçº§"])

                        with tab_strategy1:
                            high_priority = strategy_data[strategy_data['ä¼˜å…ˆçº§'] == 'é«˜']
                            for _, row in high_priority.iterrows():
                                st.markdown(f"""
                                <div style='background: #d4edda; padding: 1rem; border-radius: 10px; margin: 0.5rem 0;'>
                                    <strong>{row['ç»´åº¦å€¼']}</strong> - {row.get('å®šä»·ç­–ç•¥', row.get('è¿è¥ç­–ç•¥', ''))}
                                </div>
                                """, unsafe_allow_html=True)

                        with tab_strategy2:
                            mid_priority = strategy_data[strategy_data['ä¼˜å…ˆçº§'] == 'ä¸­']
                            for _, row in mid_priority.iterrows():
                                st.markdown(f"""
                                <div style='background: #fff3cd; padding: 1rem; border-radius: 10px; margin: 0.5rem 0;'>
                                    <strong>{row['ç»´åº¦å€¼']}</strong> - {row.get('å®šä»·ç­–ç•¥', row.get('è¿è¥ç­–ç•¥', ''))}
                                </div>
                                """, unsafe_allow_html=True)

                        with tab_strategy3:
                            low_priority = strategy_data[strategy_data['ä¼˜å…ˆçº§'] == 'ä½']
                            for _, row in low_priority.iterrows():
                                st.markdown(f"""
                                <div style='background: #f8d7da; padding: 1rem; border-radius: 10px; margin: 0.5rem 0;'>
                                    <strong>{row['ç»´åº¦å€¼']}</strong> - {row.get('å®šä»·ç­–ç•¥', row.get('è¿è¥ç­–ç•¥', ''))}
                                </div>
                                """, unsafe_allow_html=True)

                    # ä¸‹è½½ç»“æœ
                    st.markdown("### ğŸ“¥ ä¸‹è½½åˆ†ææŠ¥å‘Š")
                    for filename, data in result_files.items():
                        if isinstance(data, pd.DataFrame):
                            excel_bytes = io.BytesIO()
                            with pd.ExcelWriter(excel_bytes, engine='openpyxl') as writer:
                                data.to_excel(writer, index=False)
                            st.download_button(
                                label=f"ä¸‹è½½ {filename}",
                                data=excel_bytes.getvalue(),
                                file_name=filename,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )


def show_system_status_optimized():
    """ä¼˜åŒ–ç‰ˆç³»ç»ŸçŠ¶æ€é¡µé¢"""
    st.markdown("### âš™ï¸ ç³»ç»ŸçŠ¶æ€")

    # ç³»ç»Ÿæ¦‚è§ˆå¡ç‰‡ - ä¼˜åŒ–æ ·å¼
    st.markdown("""
    <div class="feature-card" style="background: white; color: black;">
        <h3 style="color: black;">ğŸ”§ ç³»ç»Ÿè¿è¡ŒçŠ¶æ€</h3>
        <p style="color: #333;">å®æ—¶ç›‘æ§ç³»ç»Ÿè¿è¡ŒçŠ¶æ€å’Œæ•°æ®å¤„ç†æƒ…å†µï¼Œç¡®ä¿åˆ†ææµç¨‹é¡ºç•…</p>
    </div>
    """, unsafe_allow_html=True)

    # ç³»ç»ŸæŒ‡æ ‡ - ä½¿ç”¨å¡ç‰‡æ ·å¼
    st.markdown("### ğŸ“Š ç³»ç»ŸæŒ‡æ ‡")

    sys_col1, sys_col2, sys_col3, sys_col4 = st.columns(4)

    with sys_col1:
        total_records = len(st.session_state.raw_data) if st.session_state.raw_data is not None else 0
        st.markdown(f"""
        <div style="background: white; padding: 1rem; border-radius: 10px; border-left: 4px solid #007bff; text-align: center;">
            <div style="font-size: 1.2rem; color: #333; font-weight: bold;">æ€»æ•°æ®è®°å½•</div>
            <div style="font-size: 2rem; color: #007bff; font-weight: bold;">{total_records:,}</div>
        </div>
        """, unsafe_allow_html=True)

    with sys_col2:
        total_tasks = sum([
            st.session_state.task1_completed,
            st.session_state.task2_completed,
            st.session_state.task3_completed,
            st.session_state.task4_completed
        ])
        st.markdown(f"""
        <div style="background: white; padding: 1rem; border-radius: 10px; border-left: 4px solid #28a745; text-align: center;">
            <div style="font-size: 1.2rem; color: #333; font-weight: bold;">å®Œæˆä»»åŠ¡æ•°</div>
            <div style="font-size: 2rem; color: #28a745; font-weight: bold;">{total_tasks}/4</div>
        </div>
        """, unsafe_allow_html=True)

    with sys_col3:
        if st.session_state.current_file:
            file_status = "âœ… å·²åŠ è½½"
            color = "#28a745"
        else:
            file_status = "âŒ æœªåŠ è½½"
            color = "#dc3545"
        st.markdown(f"""
        <div style="background: white; padding: 1rem; border-radius: 10px; border-left: 4px solid {color}; text-align: center;">
            <div style="font-size: 1.2rem; color: #333; font-weight: bold;">æ•°æ®æ–‡ä»¶</div>
            <div style="font-size: 1.5rem; color: {color}; font-weight: bold;">{file_status}</div>
        </div>
        """, unsafe_allow_html=True)

    with sys_col4:
        st.markdown("""
        <div style="background: white; padding: 1rem; border-radius: 10px; border-left: 4px solid #6c757d; text-align: center;">
            <div style="font-size: 1.2rem; color: #333; font-weight: bold;">ç³»ç»Ÿç‰ˆæœ¬</div>
            <div style="font-size: 2rem; color: #6c757d; font-weight: bold;">v2.0</div>
        </div>
        """, unsafe_allow_html=True)

    # ä»»åŠ¡è¯¦ç»†çŠ¶æ€ - ä¼˜åŒ–å¸ƒå±€
    st.markdown("### ğŸ“‹ ä»»åŠ¡è¯¦ç»†çŠ¶æ€")

    # ä½¿ç”¨å¡ç‰‡å¸ƒå±€å±•ç¤ºä»»åŠ¡çŠ¶æ€
    task_col1, task_col2 = st.columns(2)

    with task_col1:
        # æ•°æ®é¢„å¤„ç†çŠ¶æ€å¡ç‰‡
        st.markdown("""
        <div style="background: white; padding: 1.5rem; border-radius: 10px; margin-bottom: 1rem; border: 1px solid #e0e0e0;">
            <h4 style="color: black; margin-bottom: 1rem;">ğŸ“ æ•°æ®é¢„å¤„ç†</h4>
        """, unsafe_allow_html=True)

        if st.session_state.task1_completed:
            st.success("âœ… å·²å®Œæˆ")
            if st.session_state.step1_missing_data is not None:
                st.markdown(
                    f"<div style='color: #333;'>â–ªï¸ ç¼ºå¤±å€¼åˆ†æ: {len(st.session_state.step1_missing_data)}ä¸ªå­—æ®µ</div>",
                    unsafe_allow_html=True)
            if st.session_state.processed_data is not None:
                st.markdown(
                    f"<div style='color: #333;'>â–ªï¸ å¤„ç†æ•°æ®: {len(st.session_state.processed_data)}æ¡è®°å½•</div>",
                    unsafe_allow_html=True)
            if st.session_state.column_types is not None:
                numeric_count = len(st.session_state.column_types['numeric'])
                st.markdown(f"<div style='color: #333;'>â–ªï¸ æ•°å€¼å­—æ®µ: {numeric_count}ä¸ª</div>", unsafe_allow_html=True)
        else:
            st.warning("â³ å¾…å®Œæˆ")
            st.markdown("<div style='color: #666;'>ç­‰å¾…æ•°æ®ä¸Šä¼ å’Œé¢„å¤„ç†</div>", unsafe_allow_html=True)

        st.markdown("</div>", unsafe_allow_html=True)

        # å¤šç»´åˆ†æçŠ¶æ€å¡ç‰‡
        st.markdown("""
        <div style="background: white; padding: 1.5rem; border-radius: 10px; margin-bottom: 1rem; border: 1px solid #e0e0e0;">
            <h4 style="color: black; margin-bottom: 1rem;">ğŸ” å¤šç»´ç‰¹å¾åˆ†æ</h4>
        """, unsafe_allow_html=True)

        if st.session_state.task2_completed:
            st.success("âœ… å·²å®Œæˆ")
            if st.session_state.task2_analysis_data:
                analysis_count = sum(1 for data in st.session_state.task2_analysis_data.values() if data is not None)
                st.markdown(f"<div style='color: #333;'>â–ªï¸ åˆ†æç»´åº¦: {analysis_count}ä¸ª</div>", unsafe_allow_html=True)
            if st.session_state.task2_results and 'heatmaps' in st.session_state.task2_results:
                heatmap_count = len(st.session_state.task2_results['heatmaps'])
                st.markdown(f"<div style='color: #333;'>â–ªï¸ çƒ­åŠ›å›¾: {heatmap_count}ä¸ª</div>", unsafe_allow_html=True)
        else:
            st.warning("â³ å¾…å®Œæˆ")
            st.markdown("<div style='color: #666;'>ç­‰å¾…å¤šç»´åˆ†ææ‰§è¡Œ</div>", unsafe_allow_html=True)

        st.markdown("</div>", unsafe_allow_html=True)

    with task_col2:
        # é”€å”®é¢„æµ‹çŠ¶æ€å¡ç‰‡
        st.markdown("""
        <div style="background: white; padding: 1.5rem; border-radius: 10px; margin-bottom: 1rem; border: 1px solid #e0e0e0;">
            <h4 style="color: black; margin-bottom: 1rem;">ğŸ“ˆ é”€å”®é¢„æµ‹</h4>
        """, unsafe_allow_html=True)

        if st.session_state.task3_completed:
            st.success("âœ… å·²å®Œæˆ")
            if st.session_state.task3_results and 'mape' in st.session_state.task3_results:
                mape = st.session_state.task3_results['mape']
                accuracy_color = "#28a745" if mape < 10 else "#ffc107" if mape < 20 else "#dc3545"
                st.markdown(
                    f"<div style='color: #333;'>â–ªï¸ é¢„æµ‹ç²¾åº¦: <span style='color: {accuracy_color}; font-weight: bold;'>{mape:.2f}%</span></div>",
                    unsafe_allow_html=True)
            if st.session_state.task3_results and 'detailed_results' in st.session_state.task3_results:
                pred_count = len(st.session_state.task3_results['detailed_results'])
                st.markdown(f"<div style='color: #333;'>â–ªï¸ é¢„æµ‹å¤©æ•°: {pred_count}å¤©</div>", unsafe_allow_html=True)
        else:
            st.warning("â³ å¾…å®Œæˆ")
            st.markdown("<div style='color: #666;'>ç­‰å¾…é”€å”®é¢„æµ‹æ‰§è¡Œ</div>", unsafe_allow_html=True)

        st.markdown("</div>", unsafe_allow_html=True)

        # è¿è¥ä¼˜åŒ–çŠ¶æ€å¡ç‰‡
        st.markdown("""
        <div style="background: white; padding: 1.5rem; border-radius: 10px; margin-bottom: 1rem; border: 1px solid #e0e0e0;">
            <h4 style="color: black; margin-bottom: 1rem;">ğŸ’¡ è¿è¥ä¼˜åŒ–</h4>
        """, unsafe_allow_html=True)

        if st.session_state.task4_completed:
            st.success("âœ… å·²å®Œæˆ")
            if st.session_state.task4_results and 'operation_strategy' in st.session_state.task4_results:
                strategy_count = len(st.session_state.task4_results['operation_strategy'])
                st.markdown(f"<div style='color: #333;'>â–ªï¸ ç”Ÿæˆç­–ç•¥: {strategy_count}æ¡</div>", unsafe_allow_html=True)
            if st.session_state.task4_results and 'category_abc' in st.session_state.task4_results:
                category_count = len(st.session_state.task4_results['category_abc'])
                st.markdown(f"<div style='color: #333;'>â–ªï¸ åˆ†ç±»å•†å“: {category_count}ä¸ª</div>", unsafe_allow_html=True)
        else:
            st.warning("â³ å¾…å®Œæˆ")
            st.markdown("<div style='color: #666;'>ç­‰å¾…è¿è¥ä¼˜åŒ–åˆ†æ</div>", unsafe_allow_html=True)

        st.markdown("</div>", unsafe_allow_html=True)

    # æ•°æ®ç»Ÿè®¡ - ä¼˜åŒ–æ˜¾ç¤º
    if st.session_state.raw_data is not None:
        st.markdown("### ğŸ“ˆ æ•°æ®ç»Ÿè®¡")
        df = st.session_state.raw_data

        stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)

        with stat_col1:
            numeric_cols = len(df.select_dtypes(include=[np.number]).columns)
            st.markdown(f"""
            <div style="background: white; padding: 1rem; border-radius: 10px; text-align: center; border: 1px solid #e0e0e0;">
                <div style="font-size: 1rem; color: #666;">æ•°å€¼å‹å­—æ®µ</div>
                <div style="font-size: 1.8rem; color: #007bff; font-weight: bold;">{numeric_cols}</div>
            </div>
            """, unsafe_allow_html=True)

        with stat_col2:
            category_cols = len(df.select_dtypes(exclude=[np.number]).columns)
            st.markdown(f"""
            <div style="background: white; padding: 1rem; border-radius: 10px; text-align: center; border: 1px solid #e0e0e0;">
                <div style="font-size: 1rem; color: #666;">åˆ†ç±»å‹å­—æ®µ</div>
                <div style="font-size: 1.8rem; color: #28a745; font-weight: bold;">{category_cols}</div>
            </div>
            """, unsafe_allow_html=True)

        with stat_col3:
            total_cols = len(df.columns)
            st.markdown(f"""
            <div style="background: white; padding: 1rem; border-radius: 10px; text-align: center; border: 1px solid #e0e0e0;">
                <div style="font-size: 1rem; color: #666;">æ€»å­—æ®µæ•°</div>
                <div style="font-size: 1.8rem; color: #6c757d; font-weight: bold;">{total_cols}</div>
            </div>
            """, unsafe_allow_html=True)

        with stat_col4:
            memory_usage = df.memory_usage(deep=True).sum() / 1024 / 1024
            st.markdown(f"""
            <div style="background: white; padding: 1rem; border-radius: 10px; text-align: center; border: 1px solid #e0e0e0;">
                <div style="font-size: 1rem; color: #666;">å†…å­˜å ç”¨</div>
                <div style="font-size: 1.5rem; color: #fd7e14; font-weight: bold;">{memory_usage:.1f} MB</div>
            </div>
            """, unsafe_allow_html=True)

    # ç³»ç»Ÿæ“ä½œ - ä¼˜åŒ–æŒ‰é’®æ ·å¼
    st.markdown("### ğŸ”„ ç³»ç»Ÿæ“ä½œ")

    op_col1, op_col2, op_col3, op_col4 = st.columns(4)

    with op_col1:
        if st.button("ğŸ”„ é‡ç½®ç³»ç»Ÿ", use_container_width=True, type="secondary"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            initialize_session_state()
            st.success("ç³»ç»Ÿå·²é‡ç½®ï¼")
            st.rerun()

    with op_col2:
        if st.button("ğŸ’¾ å¯¼å‡ºé…ç½®", use_container_width=True, type="secondary"):
            st.info("ğŸ“‹ é…ç½®å¯¼å‡ºåŠŸèƒ½å¼€å‘ä¸­...")

    with op_col3:
        if st.button("ğŸ“‹ ç”ŸæˆæŠ¥å‘Š", use_container_width=True, type="secondary"):
            st.info("ğŸ“Š æŠ¥å‘Šç”ŸæˆåŠŸèƒ½å¼€å‘ä¸­...")

    with op_col4:
        if st.button("ğŸ†˜ ä½¿ç”¨å¸®åŠ©", use_container_width=True, type="secondary"):
            st.info("â„¹ï¸ å¸®åŠ©æ–‡æ¡£åŠŸèƒ½å¼€å‘ä¸­...")

    # æ·»åŠ ç³»ç»Ÿä¿¡æ¯
    st.markdown("---")
    st.markdown("""
    <div style="background: #f8f9fa; padding: 1rem; border-radius: 10px;">
        <h5 style="color: #333;">â„¹ï¸ ç³»ç»Ÿä¿¡æ¯</h5>
        <div style="color: #666;">
            <div>â–ªï¸ æœ€åæ›´æ–°: å®æ—¶</div>
            <div>â–ªï¸ æ•°æ®çŠ¶æ€: {}</div>
            <div>â–ªï¸ åˆ†æè¿›åº¦: {}/4 ä¸ªä»»åŠ¡å®Œæˆ</div>
        </div>
    </div>
    """.format(
        "å·²åŠ è½½" if st.session_state.current_file else "æœªåŠ è½½",
        sum([st.session_state.task1_completed, st.session_state.task2_completed,
             st.session_state.task3_completed, st.session_state.task4_completed])
    ), unsafe_allow_html=True)

# ============================================================================
# ä¸»åº”ç”¨å‡½æ•° - ç°ä»£åŒ–ç•Œé¢
# ============================================================================
def main():
    """ä¸»åº”ç”¨å‡½æ•° - ç°ä»£åŒ–ç•Œé¢"""
    # é¡µé¢é…ç½®
    st.set_page_config(
        page_title="ç”µå•†é”€å”®åˆ†æä¸ç­–ç•¥ä¼˜åŒ–ç³»ç»Ÿ",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="collapsed"  # éšè—ä¾§è¾¹æ 
    )

    # ä¸»æ ‡é¢˜
    st.markdown('<div class="main-header">ğŸ“Š ç”µå•†é”€å”®åˆ†æä¸ç­–ç•¥ä¼˜åŒ–ç³»ç»Ÿ</div>',
                unsafe_allow_html=True)

    # é¡¶éƒ¨å¯¼èˆªæ 
    st.markdown("""
    <div class="top-nav">
        <div style="display: flex; justify-content: center; align-items: center; gap: 1rem;">
            <span style="color: white; font-size: 1.2rem; font-weight: bold;">ğŸ“‹ å¯¼èˆªèœå•</span>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # é¡¶éƒ¨å¯¼èˆªæŒ‰é’®
    nav_col1, nav_col2, nav_col3, nav_col4, nav_col5, nav_col6 = st.columns(6)

    with nav_col1:
        project_overview = st.button("ğŸ  é¡¹ç›®æ¦‚è§ˆ", use_container_width=True)
    with nav_col2:
        data_preprocessing = st.button("ğŸ“ æ•°æ®é¢„å¤„ç†", use_container_width=True)
    with nav_col3:
        multi_analysis = st.button("ğŸ” å¤šç»´åˆ†æ", use_container_width=True)
    with nav_col4:
        sales_forecast = st.button("ğŸ“ˆ é”€å”®é¢„æµ‹", use_container_width=True)
    with nav_col5:
        operation_optimize = st.button("ğŸ’¡ è¿è¥ä¼˜åŒ–", use_container_width=True)
    with nav_col6:
        system_status = st.button("âš™ï¸ ç³»ç»ŸçŠ¶æ€", use_container_width=True)

    # ä»»åŠ¡çŠ¶æ€æŒ‡ç¤ºå™¨
    st.markdown("""
    <div class="status-indicator">
        <div class="status-item {}">
            <div style="font-size: 2rem;">ğŸ“</div>
            <div>æ•°æ®é¢„å¤„ç†</div>
            <div style="font-size: 0.8rem; margin-top: 0.5rem;">{}
        </div>
        <div class="status-item {}">
            <div style="font-size: 2rem;">ğŸ”</div>
            <div>å¤šç»´åˆ†æ</div>
            <div style="font-size: 0.8rem; margin-top: 0.5rem;">{}
        </div>
        <div class="status-item {}">
            <div style="font-size: 2rem;">ğŸ“ˆ</div>
            <div>é”€å”®é¢„æµ‹</div>
            <div style="font-size: 0.8rem; margin-top: 0.5rem;">{}
        </div>
        <div class="status-item {}">
            <div style="font-size: 2rem;">ğŸ’¡</div>
            <div>è¿è¥ä¼˜åŒ–</div>
            <div style="font-size: 0.8rem; margin-top: 0.5rem;">{}
        </div>
    </div>
    """.format(
        "completed" if st.session_state.task1_completed else "pending",
        "âœ… å·²å®Œæˆ" if st.session_state.task1_completed else "â³ å¾…å®Œæˆ",
        "completed" if st.session_state.task2_completed else "pending",
        "âœ… å·²å®Œæˆ" if st.session_state.task2_completed else "â³ å¾…å®Œæˆ",
        "completed" if st.session_state.task3_completed else "pending",
        "âœ… å·²å®Œæˆ" if st.session_state.task3_completed else "â³ å¾…å®Œæˆ",
        "completed" if st.session_state.task4_completed else "pending",
        "âœ… å·²å®Œæˆ" if st.session_state.task4_completed else "â³ å¾…å®Œæˆ"
    ), unsafe_allow_html=True)

    # å½“å‰æ–‡ä»¶æ˜¾ç¤º
    if st.session_state.get('current_file'):
        st.info(f"ğŸ“„ å½“å‰æ–‡ä»¶: {st.session_state.current_file}")

    # é¡µé¢è·¯ç”±
    if project_overview:
        st.session_state.current_page = "project_overview"
    elif data_preprocessing:
        st.session_state.current_page = "data_preprocessing"
    elif multi_analysis:
        st.session_state.current_page = "multi_analysis"
    elif sales_forecast:
        st.session_state.current_page = "sales_forecast"
    elif operation_optimize:
        st.session_state.current_page = "operation_optimize"
    elif system_status:
        st.session_state.current_page = "system_status"

    # åˆå§‹åŒ–å½“å‰é¡µé¢
    if 'current_page' not in st.session_state:
        st.session_state.current_page = "project_overview"

    # æ˜¾ç¤ºå¯¹åº”é¡µé¢
    if st.session_state.current_page == "project_overview":
        show_project_overview_optimized()
    elif st.session_state.current_page == "data_preprocessing":
        task1_data_preprocessing_optimized()
    elif st.session_state.current_page == "multi_analysis":
        enhanced_task2_multidimensional_analysis()
    elif st.session_state.current_page == "sales_forecast":
        task3_sales_forecast_optimized()
    elif st.session_state.current_page == "operation_optimize":
        task4_operation_optimization_optimized()
    elif st.session_state.current_page == "system_status":
        show_system_status_optimized()

    # é¡µè„š
    st.markdown("---")
    st.markdown(
        "<div style='text-align: center; color: #666; font-size: 0.9rem;'>"
        "ğŸš€ ç”µå•†é”€å”®åˆ†æä¸ç­–ç•¥ä¼˜åŒ–ç³»ç»Ÿ | ç°ä»£åŒ–æ•°æ®åˆ†æå¹³å° | æ”¯æŒè®ºæ–‡æ ‡å‡†åŒ–è¾“å‡º"
        "</div>",
        unsafe_allow_html=True
    )
# ============================================================================
# è¿è¡Œåº”ç”¨
# ============================================================================
if __name__ == "__main__":
    main()
